{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7章　多値分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib->japanize_matplotlib) (46.0.0.post20200309)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.7/site-packages (from torch->torchviz) (1.18.1)\n"
     ]
    }
   ],
   "source": [
    "# 必要ライブラリの導入\n",
    "\n",
    "!pip install japanize_matplotlib | tail -n 1\n",
    "!pip install torchviz | tail -n 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要ライブラリのインポート\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import japanize_matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch関連ライブラリのインポート\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary\n",
    "from torchviz import make_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# デフォルトフォントサイズ変更\n",
    "plt.rcParams['font.size'] = 14\n",
    "\n",
    "# デフォルトグラフサイズ変更\n",
    "plt.rcParams['figure.figsize'] = (6,6)\n",
    "\n",
    "# デフォルトで方眼表示ON\n",
    "plt.rcParams['axes.grid'] = True\n",
    "\n",
    "# numpyの表示桁数設定\n",
    "np.set_printoptions(suppress=True, precision=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.7 NLLLoss損失関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.],\n",
      "        [ 7.,  8.,  9.],\n",
      "        [10., 11., 12.]])\n",
      "tensor([0, 1, 2, 0])\n"
     ]
    }
   ],
   "source": [
    "# 入力変数の準備\n",
    "\n",
    "# 擬似的な出力データ\n",
    "outputs_np = np.array(range(1, 13)).reshape((4,3))\n",
    "# 擬似的な正解データ\n",
    "labels_np = np.array([0, 1, 2, 0])\n",
    "\n",
    "# Tensor化\n",
    "outputs = torch.tensor(outputs_np).float()\n",
    "labels = torch.tensor(labels_np).long()\n",
    "\n",
    "# 結果確認\n",
    "print(outputs.data)\n",
    "print(labels.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-6.25\n"
     ]
    }
   ],
   "source": [
    "# NLLLoss関数の呼び出し\n",
    "\n",
    "nllloss = nn.NLLLoss()\n",
    "loss = nllloss(outputs, labels)\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.8 データ準備"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データ読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "元データ (150, 4) (150,)\n"
     ]
    }
   ],
   "source": [
    "# 学習用データ準備\n",
    "\n",
    "# ライブラリのインポート\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# データ読み込み\n",
    "iris = load_iris()\n",
    "\n",
    "# 入力データと正解データ取得\n",
    "x_org, y_org = iris.data, iris.target\n",
    "\n",
    "# 結果確認\n",
    "print('元データ', x_org.shape, y_org.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データ絞り込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "元データ (150, 2) (150,)\n"
     ]
    }
   ],
   "source": [
    "# データ絞り込み\n",
    "\n",
    "# 入力データに関しては、sepal length(0)とpetal length(2)のみ抽出\n",
    "x_select = x_org[:,[0,2]]\n",
    "\n",
    "# 結果確認\n",
    "print('元データ', x_select.shape, y_org.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 訓練データ・検証データの分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75, 2) (75, 2) (75,) (75,)\n"
     ]
    }
   ],
   "source": [
    "# 訓練データ、検証データに分割 (シャフルも同時に実施)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x_select, y_org, train_size=75, test_size=75, \n",
    "    random_state=123)\n",
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 訓練データの散布図表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データを正解値ごとに分割\n",
    "\n",
    "x_t0 = x_train[y_train == 0]\n",
    "x_t1 = x_train[y_train == 1]\n",
    "x_t2 = x_train[y_train == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 散布図の表示\n",
    "\n",
    "plt.scatter(x_t0[:,0], x_t0[:,1], marker='x', c='k', s=50, label='0 (setosa)')\n",
    "plt.scatter(x_t1[:,0], x_t1[:,1], marker='o', c='b', s=50, label='1 (versicolour)')\n",
    "plt.scatter(x_t2[:,0], x_t2[:,1], marker='+', c='k', s=50, label='2 (virginica)')\n",
    "plt.xlabel('sepal_length')\n",
    "plt.ylabel('petal_length')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.9 モデル定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_input: 2  n_output: 3\n"
     ]
    }
   ],
   "source": [
    "# 学習用パラメータ設定\n",
    "\n",
    "# 入力次元数\n",
    "n_input = x_train.shape[1]\n",
    "\n",
    "# 出力次元数\n",
    "# 分類先クラス数　今回は3になる\n",
    "n_output = len(list(set(y_train)))\n",
    "\n",
    "# 結果確認\n",
    "print(f'n_input: {n_input}  n_output: {n_output}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの定義\n",
    "# 2入力3出力のロジスティック回帰モデル\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, n_input, n_output):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(n_input, n_output)\n",
    "                \n",
    "        # 初期値を全部1にする\n",
    "        # 「ディープラーニングの数学」と条件を合わせる目的        \n",
    "        self.l1.weight.data.fill_(1.0)\n",
    "        self.l1.bias.data.fill_(1.0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.l1(x)\n",
    "        return x1\n",
    "    \n",
    "# インスタンスの生成\n",
    "net = Net(n_input, n_output)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデル確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('l1.weight', Parameter containing:\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]], requires_grad=True))\n",
      "('l1.bias', Parameter containing:\n",
      "tensor([1., 1., 1.], requires_grad=True))\n"
     ]
    }
   ],
   "source": [
    "# モデル内のパラメータの確認\n",
    "# l1.weightが行列にl1.biasがベクトルになっている\n",
    "\n",
    "for parameter in net.named_parameters():\n",
    "    print(parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (l1): Linear(in_features=2, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# モデルの概要表示\n",
    "\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                    [-1, 3]               9\n",
      "================================================================\n",
      "Total params: 9\n",
      "Trainable params: 9\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.00\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# モデルのサマリー表示\n",
    "\n",
    "summary(net, (2,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 最適化アルゴリズムと損失関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習率\n",
    "lr = 0.01\n",
    "\n",
    "# アルゴリズム: 勾配降下法\n",
    "optimizer = optim.SGD(net.parameters(), lr=lr)\n",
    "\n",
    "# 損失関数： 交差エントロピー関数\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.10 勾配降下法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データのTensor化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 入力変数x_trainと正解値 y_trainのTesor化\n",
    "\n",
    "inputs = torch.tensor(x_train).float()\n",
    "labels = torch.tensor(y_train).long()\n",
    "\n",
    "# 検証用変数のTensor化\n",
    "\n",
    "inputs_test = torch.tensor(x_test).float()\n",
    "labels_test = torch.tensor(y_test).long()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 計算グラフの視覚化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.44.1 (20200629.0846)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"154pt\" height=\"283pt\"\n",
       " viewBox=\"0.00 0.00 153.50 283.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 279)\">\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-279 149.5,-279 149.5,4 -4,4\"/>\n",
       "<!-- 140495803988624 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>140495803988624</title>\n",
       "<polygon fill=\"#caff70\" stroke=\"black\" points=\"119.5,-21 16.5,-21 16.5,0 119.5,0 119.5,-21\"/>\n",
       "<text text-anchor=\"middle\" x=\"68\" y=\"-7.4\" font-family=\"Times,serif\" font-size=\"12.00\">NllLossBackward</text>\n",
       "</g>\n",
       "<!-- 140495803988240 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>140495803988240</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"130.5,-78 5.5,-78 5.5,-57 130.5,-57 130.5,-78\"/>\n",
       "<text text-anchor=\"middle\" x=\"68\" y=\"-64.4\" font-family=\"Times,serif\" font-size=\"12.00\">LogSoftmaxBackward</text>\n",
       "</g>\n",
       "<!-- 140495803988240&#45;&gt;140495803988624 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>140495803988240&#45;&gt;140495803988624</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M68,-56.92C68,-49.91 68,-40.14 68,-31.47\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"71.5,-31.34 68,-21.34 64.5,-31.34 71.5,-31.34\"/>\n",
       "</g>\n",
       "<!-- 140495803986192 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>140495803986192</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"120,-135 16,-135 16,-114 120,-114 120,-135\"/>\n",
       "<text text-anchor=\"middle\" x=\"68\" y=\"-121.4\" font-family=\"Times,serif\" font-size=\"12.00\">AddmmBackward</text>\n",
       "</g>\n",
       "<!-- 140495803986192&#45;&gt;140495803988240 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>140495803986192&#45;&gt;140495803988240</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M68,-113.92C68,-106.91 68,-97.14 68,-88.47\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"71.5,-88.34 68,-78.34 64.5,-88.34 71.5,-88.34\"/>\n",
       "</g>\n",
       "<!-- 140495803988048 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>140495803988048</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"54,-205 0,-205 0,-171 54,-171 54,-205\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-191.4\" font-family=\"Times,serif\" font-size=\"12.00\">l1.bias</text>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-178.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (3)</text>\n",
       "</g>\n",
       "<!-- 140495803988048&#45;&gt;140495803986192 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>140495803988048&#45;&gt;140495803986192</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M37.77,-170.84C43.35,-162.48 50.17,-152.24 55.93,-143.61\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"59,-145.3 61.64,-135.04 53.18,-141.42 59,-145.3\"/>\n",
       "</g>\n",
       "<!-- 140495803986896 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>140495803986896</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"145.5,-198.5 72.5,-198.5 72.5,-177.5 145.5,-177.5 145.5,-198.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"109\" y=\"-184.9\" font-family=\"Times,serif\" font-size=\"12.00\">TBackward</text>\n",
       "</g>\n",
       "<!-- 140495803986896&#45;&gt;140495803986192 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>140495803986896&#45;&gt;140495803986192</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M102.59,-177.39C96.61,-168.42 87.53,-154.79 80.17,-143.75\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"82.96,-141.62 74.5,-135.24 77.13,-145.51 82.96,-141.62\"/>\n",
       "</g>\n",
       "<!-- 140495803986768 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>140495803986768</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"139.5,-275 78.5,-275 78.5,-241 139.5,-241 139.5,-275\"/>\n",
       "<text text-anchor=\"middle\" x=\"109\" y=\"-261.4\" font-family=\"Times,serif\" font-size=\"12.00\">l1.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"109\" y=\"-248.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (3, 2)</text>\n",
       "</g>\n",
       "<!-- 140495803986768&#45;&gt;140495803986896 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>140495803986768&#45;&gt;140495803986896</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M109,-240.88C109,-231.31 109,-219.09 109,-208.91\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"112.5,-208.89 109,-198.89 105.5,-208.89 112.5,-208.89\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7fc7ba7d3a10>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 予測計算\n",
    "outputs = net(inputs)\n",
    "\n",
    "#  損失計算\n",
    "loss = criterion(outputs, labels)\n",
    "\n",
    "# 損失関数の計算グラフ化\n",
    "make_dot(loss, params=dict(net.named_parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 予測ラベル値の取得方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([12.0000, 12.7000,  7.6000, 13.0000, 12.3000,  7.6000,  7.3000, 11.1000,\n",
       "        12.1000, 13.3000,  8.0000,  7.0000, 10.3000,  7.6000, 11.7000, 13.3000,\n",
       "         7.4000, 13.5000,  8.2000,  8.4000, 12.7000,  6.6000,  7.9000, 12.2000,\n",
       "        14.6000, 12.0000, 10.2000, 10.5000,  7.1000,  7.3000, 12.6000, 12.7000,\n",
       "         7.4000,  7.7000, 10.8000, 11.5000, 11.5000, 14.0000, 12.8000, 10.8000,\n",
       "        10.8000, 15.2000,  7.5000,  7.8000, 11.1000, 13.6000, 12.9000, 14.2000,\n",
       "        12.7000,  7.6000, 10.9000,  7.0000, 10.9000, 11.2000,  7.4000, 11.7000,\n",
       "        13.3000, 11.5000, 13.4000, 12.7000,  7.7000, 11.8000,  7.0000, 12.6000,\n",
       "        11.7000, 10.9000,  9.2000, 12.2000, 10.4000, 12.1000,  7.5000,  9.1000,\n",
       "        11.1000, 12.0000, 14.3000], grad_fn=<MaxBackward0>),\n",
       "indices=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.max関数呼び出し\n",
    "# 2つめの引数は軸を意味している。1だと行ごとの集計。\n",
    "torch.max(outputs, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ラベル値の配列を取得\n",
    "torch.max(outputs, 1)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 繰り返し計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習率\n",
    "lr = 0.01\n",
    "\n",
    "# 初期化\n",
    "net = Net(n_input, n_output)\n",
    "\n",
    "# 最適化アルゴリズム: 勾配降下法\n",
    "optimizer = optim.SGD(net.parameters(), lr=lr)\n",
    "\n",
    "# 損失関数： 交差エントロピー関数\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 繰り返し回数\n",
    "num_epochs = 10000\n",
    "\n",
    "# 評価結果記録用\n",
    "history = np.zeros((0,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/10000], loss: 1.09861 acc: 0.30667 val_loss: 1.09263, val_acc: 0.26667\n",
      "Epoch [10/10000], loss: 1.03580 acc: 0.40000 val_loss: 1.06403, val_acc: 0.26667\n",
      "Epoch [20/10000], loss: 1.00477 acc: 0.40000 val_loss: 1.03347, val_acc: 0.26667\n",
      "Epoch [30/10000], loss: 0.97672 acc: 0.40000 val_loss: 1.00264, val_acc: 0.26667\n",
      "Epoch [40/10000], loss: 0.95057 acc: 0.41333 val_loss: 0.97351, val_acc: 0.26667\n",
      "Epoch [50/10000], loss: 0.92616 acc: 0.48000 val_loss: 0.94631, val_acc: 0.38667\n",
      "Epoch [60/10000], loss: 0.90338 acc: 0.69333 val_loss: 0.92098, val_acc: 0.56000\n",
      "Epoch [70/10000], loss: 0.88212 acc: 0.70667 val_loss: 0.89740, val_acc: 0.60000\n",
      "Epoch [80/10000], loss: 0.86227 acc: 0.70667 val_loss: 0.87545, val_acc: 0.61333\n",
      "Epoch [90/10000], loss: 0.84373 acc: 0.70667 val_loss: 0.85500, val_acc: 0.62667\n",
      "Epoch [100/10000], loss: 0.82640 acc: 0.70667 val_loss: 0.83594, val_acc: 0.62667\n",
      "Epoch [110/10000], loss: 0.81019 acc: 0.72000 val_loss: 0.81815, val_acc: 0.62667\n",
      "Epoch [120/10000], loss: 0.79500 acc: 0.72000 val_loss: 0.80153, val_acc: 0.62667\n",
      "Epoch [130/10000], loss: 0.78077 acc: 0.73333 val_loss: 0.78599, val_acc: 0.62667\n",
      "Epoch [140/10000], loss: 0.76741 acc: 0.74667 val_loss: 0.77142, val_acc: 0.64000\n",
      "Epoch [150/10000], loss: 0.75485 acc: 0.74667 val_loss: 0.75777, val_acc: 0.65333\n",
      "Epoch [160/10000], loss: 0.74303 acc: 0.74667 val_loss: 0.74494, val_acc: 0.68000\n",
      "Epoch [170/10000], loss: 0.73189 acc: 0.76000 val_loss: 0.73288, val_acc: 0.70667\n",
      "Epoch [180/10000], loss: 0.72138 acc: 0.77333 val_loss: 0.72151, val_acc: 0.76000\n",
      "Epoch [190/10000], loss: 0.71145 acc: 0.82667 val_loss: 0.71079, val_acc: 0.78667\n",
      "Epoch [200/10000], loss: 0.70205 acc: 0.82667 val_loss: 0.70067, val_acc: 0.78667\n",
      "Epoch [210/10000], loss: 0.69315 acc: 0.84000 val_loss: 0.69109, val_acc: 0.80000\n",
      "Epoch [220/10000], loss: 0.68470 acc: 0.84000 val_loss: 0.68202, val_acc: 0.80000\n",
      "Epoch [230/10000], loss: 0.67667 acc: 0.86667 val_loss: 0.67341, val_acc: 0.81333\n",
      "Epoch [240/10000], loss: 0.66904 acc: 0.86667 val_loss: 0.66524, val_acc: 0.81333\n",
      "Epoch [250/10000], loss: 0.66176 acc: 0.86667 val_loss: 0.65746, val_acc: 0.82667\n",
      "Epoch [260/10000], loss: 0.65483 acc: 0.85333 val_loss: 0.65005, val_acc: 0.82667\n",
      "Epoch [270/10000], loss: 0.64820 acc: 0.85333 val_loss: 0.64299, val_acc: 0.82667\n",
      "Epoch [280/10000], loss: 0.64187 acc: 0.85333 val_loss: 0.63625, val_acc: 0.82667\n",
      "Epoch [290/10000], loss: 0.63581 acc: 0.86667 val_loss: 0.62980, val_acc: 0.82667\n",
      "Epoch [300/10000], loss: 0.63000 acc: 0.88000 val_loss: 0.62363, val_acc: 0.82667\n",
      "Epoch [310/10000], loss: 0.62443 acc: 0.89333 val_loss: 0.61772, val_acc: 0.82667\n",
      "Epoch [320/10000], loss: 0.61909 acc: 0.89333 val_loss: 0.61205, val_acc: 0.82667\n",
      "Epoch [330/10000], loss: 0.61394 acc: 0.89333 val_loss: 0.60661, val_acc: 0.82667\n",
      "Epoch [340/10000], loss: 0.60900 acc: 0.89333 val_loss: 0.60138, val_acc: 0.84000\n",
      "Epoch [350/10000], loss: 0.60423 acc: 0.89333 val_loss: 0.59635, val_acc: 0.84000\n",
      "Epoch [360/10000], loss: 0.59964 acc: 0.90667 val_loss: 0.59150, val_acc: 0.85333\n",
      "Epoch [370/10000], loss: 0.59521 acc: 0.92000 val_loss: 0.58683, val_acc: 0.86667\n",
      "Epoch [380/10000], loss: 0.59093 acc: 0.92000 val_loss: 0.58232, val_acc: 0.86667\n",
      "Epoch [390/10000], loss: 0.58679 acc: 0.92000 val_loss: 0.57797, val_acc: 0.86667\n",
      "Epoch [400/10000], loss: 0.58279 acc: 0.92000 val_loss: 0.57377, val_acc: 0.86667\n",
      "Epoch [410/10000], loss: 0.57891 acc: 0.92000 val_loss: 0.56970, val_acc: 0.86667\n",
      "Epoch [420/10000], loss: 0.57516 acc: 0.92000 val_loss: 0.56576, val_acc: 0.86667\n",
      "Epoch [430/10000], loss: 0.57152 acc: 0.90667 val_loss: 0.56195, val_acc: 0.86667\n",
      "Epoch [440/10000], loss: 0.56799 acc: 0.90667 val_loss: 0.55825, val_acc: 0.86667\n",
      "Epoch [450/10000], loss: 0.56456 acc: 0.90667 val_loss: 0.55466, val_acc: 0.86667\n",
      "Epoch [460/10000], loss: 0.56123 acc: 0.90667 val_loss: 0.55118, val_acc: 0.86667\n",
      "Epoch [470/10000], loss: 0.55799 acc: 0.90667 val_loss: 0.54779, val_acc: 0.88000\n",
      "Epoch [480/10000], loss: 0.55484 acc: 0.90667 val_loss: 0.54451, val_acc: 0.88000\n",
      "Epoch [490/10000], loss: 0.55177 acc: 0.90667 val_loss: 0.54131, val_acc: 0.88000\n",
      "Epoch [500/10000], loss: 0.54878 acc: 0.90667 val_loss: 0.53819, val_acc: 0.88000\n",
      "Epoch [510/10000], loss: 0.54587 acc: 0.90667 val_loss: 0.53516, val_acc: 0.88000\n",
      "Epoch [520/10000], loss: 0.54303 acc: 0.90667 val_loss: 0.53221, val_acc: 0.88000\n",
      "Epoch [530/10000], loss: 0.54026 acc: 0.90667 val_loss: 0.52933, val_acc: 0.88000\n",
      "Epoch [540/10000], loss: 0.53755 acc: 0.90667 val_loss: 0.52652, val_acc: 0.88000\n",
      "Epoch [550/10000], loss: 0.53491 acc: 0.90667 val_loss: 0.52377, val_acc: 0.88000\n",
      "Epoch [560/10000], loss: 0.53233 acc: 0.90667 val_loss: 0.52110, val_acc: 0.88000\n",
      "Epoch [570/10000], loss: 0.52981 acc: 0.90667 val_loss: 0.51848, val_acc: 0.88000\n",
      "Epoch [580/10000], loss: 0.52734 acc: 0.90667 val_loss: 0.51592, val_acc: 0.88000\n",
      "Epoch [590/10000], loss: 0.52493 acc: 0.90667 val_loss: 0.51342, val_acc: 0.88000\n",
      "Epoch [600/10000], loss: 0.52256 acc: 0.90667 val_loss: 0.51098, val_acc: 0.88000\n",
      "Epoch [610/10000], loss: 0.52025 acc: 0.90667 val_loss: 0.50859, val_acc: 0.88000\n",
      "Epoch [620/10000], loss: 0.51798 acc: 0.90667 val_loss: 0.50624, val_acc: 0.88000\n",
      "Epoch [630/10000], loss: 0.51576 acc: 0.90667 val_loss: 0.50395, val_acc: 0.88000\n",
      "Epoch [640/10000], loss: 0.51358 acc: 0.90667 val_loss: 0.50170, val_acc: 0.88000\n",
      "Epoch [650/10000], loss: 0.51144 acc: 0.90667 val_loss: 0.49949, val_acc: 0.88000\n",
      "Epoch [660/10000], loss: 0.50934 acc: 0.90667 val_loss: 0.49733, val_acc: 0.89333\n",
      "Epoch [670/10000], loss: 0.50728 acc: 0.90667 val_loss: 0.49521, val_acc: 0.90667\n",
      "Epoch [680/10000], loss: 0.50526 acc: 0.90667 val_loss: 0.49313, val_acc: 0.90667\n",
      "Epoch [690/10000], loss: 0.50328 acc: 0.90667 val_loss: 0.49109, val_acc: 0.90667\n",
      "Epoch [700/10000], loss: 0.50133 acc: 0.90667 val_loss: 0.48908, val_acc: 0.90667\n",
      "Epoch [710/10000], loss: 0.49941 acc: 0.90667 val_loss: 0.48711, val_acc: 0.90667\n",
      "Epoch [720/10000], loss: 0.49752 acc: 0.90667 val_loss: 0.48517, val_acc: 0.90667\n",
      "Epoch [730/10000], loss: 0.49567 acc: 0.90667 val_loss: 0.48327, val_acc: 0.90667\n",
      "Epoch [740/10000], loss: 0.49385 acc: 0.90667 val_loss: 0.48140, val_acc: 0.90667\n",
      "Epoch [750/10000], loss: 0.49205 acc: 0.90667 val_loss: 0.47956, val_acc: 0.90667\n",
      "Epoch [760/10000], loss: 0.49029 acc: 0.90667 val_loss: 0.47775, val_acc: 0.90667\n",
      "Epoch [770/10000], loss: 0.48855 acc: 0.90667 val_loss: 0.47597, val_acc: 0.90667\n",
      "Epoch [780/10000], loss: 0.48684 acc: 0.90667 val_loss: 0.47422, val_acc: 0.90667\n",
      "Epoch [790/10000], loss: 0.48515 acc: 0.89333 val_loss: 0.47249, val_acc: 0.92000\n",
      "Epoch [800/10000], loss: 0.48349 acc: 0.89333 val_loss: 0.47079, val_acc: 0.92000\n",
      "Epoch [810/10000], loss: 0.48186 acc: 0.89333 val_loss: 0.46912, val_acc: 0.92000\n",
      "Epoch [820/10000], loss: 0.48024 acc: 0.89333 val_loss: 0.46747, val_acc: 0.92000\n",
      "Epoch [830/10000], loss: 0.47865 acc: 0.89333 val_loss: 0.46585, val_acc: 0.92000\n",
      "Epoch [840/10000], loss: 0.47709 acc: 0.89333 val_loss: 0.46425, val_acc: 0.92000\n",
      "Epoch [850/10000], loss: 0.47554 acc: 0.89333 val_loss: 0.46267, val_acc: 0.92000\n",
      "Epoch [860/10000], loss: 0.47402 acc: 0.89333 val_loss: 0.46111, val_acc: 0.92000\n",
      "Epoch [870/10000], loss: 0.47251 acc: 0.89333 val_loss: 0.45958, val_acc: 0.92000\n",
      "Epoch [880/10000], loss: 0.47103 acc: 0.89333 val_loss: 0.45806, val_acc: 0.92000\n",
      "Epoch [890/10000], loss: 0.46956 acc: 0.89333 val_loss: 0.45657, val_acc: 0.92000\n",
      "Epoch [900/10000], loss: 0.46811 acc: 0.89333 val_loss: 0.45509, val_acc: 0.92000\n",
      "Epoch [910/10000], loss: 0.46668 acc: 0.89333 val_loss: 0.45364, val_acc: 0.92000\n",
      "Epoch [920/10000], loss: 0.46527 acc: 0.89333 val_loss: 0.45220, val_acc: 0.92000\n",
      "Epoch [930/10000], loss: 0.46388 acc: 0.89333 val_loss: 0.45078, val_acc: 0.92000\n",
      "Epoch [940/10000], loss: 0.46250 acc: 0.89333 val_loss: 0.44938, val_acc: 0.92000\n",
      "Epoch [950/10000], loss: 0.46114 acc: 0.89333 val_loss: 0.44800, val_acc: 0.92000\n",
      "Epoch [960/10000], loss: 0.45980 acc: 0.89333 val_loss: 0.44663, val_acc: 0.92000\n",
      "Epoch [970/10000], loss: 0.45847 acc: 0.89333 val_loss: 0.44528, val_acc: 0.92000\n",
      "Epoch [980/10000], loss: 0.45716 acc: 0.89333 val_loss: 0.44395, val_acc: 0.92000\n",
      "Epoch [990/10000], loss: 0.45586 acc: 0.89333 val_loss: 0.44263, val_acc: 0.92000\n",
      "Epoch [1000/10000], loss: 0.45458 acc: 0.89333 val_loss: 0.44133, val_acc: 0.92000\n",
      "Epoch [1010/10000], loss: 0.45331 acc: 0.89333 val_loss: 0.44004, val_acc: 0.92000\n",
      "Epoch [1020/10000], loss: 0.45205 acc: 0.89333 val_loss: 0.43877, val_acc: 0.92000\n",
      "Epoch [1030/10000], loss: 0.45081 acc: 0.89333 val_loss: 0.43751, val_acc: 0.92000\n",
      "Epoch [1040/10000], loss: 0.44958 acc: 0.89333 val_loss: 0.43626, val_acc: 0.92000\n",
      "Epoch [1050/10000], loss: 0.44836 acc: 0.89333 val_loss: 0.43503, val_acc: 0.92000\n",
      "Epoch [1060/10000], loss: 0.44716 acc: 0.89333 val_loss: 0.43381, val_acc: 0.92000\n",
      "Epoch [1070/10000], loss: 0.44597 acc: 0.89333 val_loss: 0.43260, val_acc: 0.92000\n",
      "Epoch [1080/10000], loss: 0.44479 acc: 0.89333 val_loss: 0.43141, val_acc: 0.92000\n",
      "Epoch [1090/10000], loss: 0.44363 acc: 0.89333 val_loss: 0.43023, val_acc: 0.92000\n",
      "Epoch [1100/10000], loss: 0.44247 acc: 0.89333 val_loss: 0.42906, val_acc: 0.92000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1110/10000], loss: 0.44133 acc: 0.89333 val_loss: 0.42790, val_acc: 0.92000\n",
      "Epoch [1120/10000], loss: 0.44020 acc: 0.89333 val_loss: 0.42676, val_acc: 0.92000\n",
      "Epoch [1130/10000], loss: 0.43908 acc: 0.89333 val_loss: 0.42562, val_acc: 0.92000\n",
      "Epoch [1140/10000], loss: 0.43797 acc: 0.89333 val_loss: 0.42450, val_acc: 0.92000\n",
      "Epoch [1150/10000], loss: 0.43687 acc: 0.89333 val_loss: 0.42339, val_acc: 0.92000\n",
      "Epoch [1160/10000], loss: 0.43578 acc: 0.89333 val_loss: 0.42229, val_acc: 0.92000\n",
      "Epoch [1170/10000], loss: 0.43470 acc: 0.89333 val_loss: 0.42120, val_acc: 0.92000\n",
      "Epoch [1180/10000], loss: 0.43363 acc: 0.89333 val_loss: 0.42012, val_acc: 0.92000\n",
      "Epoch [1190/10000], loss: 0.43257 acc: 0.89333 val_loss: 0.41905, val_acc: 0.92000\n",
      "Epoch [1200/10000], loss: 0.43152 acc: 0.89333 val_loss: 0.41799, val_acc: 0.92000\n",
      "Epoch [1210/10000], loss: 0.43048 acc: 0.89333 val_loss: 0.41694, val_acc: 0.92000\n",
      "Epoch [1220/10000], loss: 0.42945 acc: 0.89333 val_loss: 0.41590, val_acc: 0.92000\n",
      "Epoch [1230/10000], loss: 0.42843 acc: 0.89333 val_loss: 0.41487, val_acc: 0.92000\n",
      "Epoch [1240/10000], loss: 0.42742 acc: 0.89333 val_loss: 0.41384, val_acc: 0.92000\n",
      "Epoch [1250/10000], loss: 0.42641 acc: 0.89333 val_loss: 0.41283, val_acc: 0.92000\n",
      "Epoch [1260/10000], loss: 0.42542 acc: 0.89333 val_loss: 0.41182, val_acc: 0.92000\n",
      "Epoch [1270/10000], loss: 0.42443 acc: 0.89333 val_loss: 0.41083, val_acc: 0.92000\n",
      "Epoch [1280/10000], loss: 0.42345 acc: 0.89333 val_loss: 0.40984, val_acc: 0.92000\n",
      "Epoch [1290/10000], loss: 0.42248 acc: 0.89333 val_loss: 0.40886, val_acc: 0.92000\n",
      "Epoch [1300/10000], loss: 0.42152 acc: 0.89333 val_loss: 0.40789, val_acc: 0.92000\n",
      "Epoch [1310/10000], loss: 0.42056 acc: 0.89333 val_loss: 0.40693, val_acc: 0.92000\n",
      "Epoch [1320/10000], loss: 0.41962 acc: 0.89333 val_loss: 0.40598, val_acc: 0.92000\n",
      "Epoch [1330/10000], loss: 0.41868 acc: 0.89333 val_loss: 0.40503, val_acc: 0.93333\n",
      "Epoch [1340/10000], loss: 0.41775 acc: 0.89333 val_loss: 0.40409, val_acc: 0.93333\n",
      "Epoch [1350/10000], loss: 0.41682 acc: 0.89333 val_loss: 0.40316, val_acc: 0.93333\n",
      "Epoch [1360/10000], loss: 0.41590 acc: 0.89333 val_loss: 0.40224, val_acc: 0.93333\n",
      "Epoch [1370/10000], loss: 0.41499 acc: 0.89333 val_loss: 0.40132, val_acc: 0.93333\n",
      "Epoch [1380/10000], loss: 0.41409 acc: 0.89333 val_loss: 0.40041, val_acc: 0.93333\n",
      "Epoch [1390/10000], loss: 0.41320 acc: 0.89333 val_loss: 0.39951, val_acc: 0.93333\n",
      "Epoch [1400/10000], loss: 0.41231 acc: 0.89333 val_loss: 0.39861, val_acc: 0.93333\n",
      "Epoch [1410/10000], loss: 0.41143 acc: 0.89333 val_loss: 0.39773, val_acc: 0.93333\n",
      "Epoch [1420/10000], loss: 0.41055 acc: 0.89333 val_loss: 0.39685, val_acc: 0.93333\n",
      "Epoch [1430/10000], loss: 0.40968 acc: 0.89333 val_loss: 0.39597, val_acc: 0.93333\n",
      "Epoch [1440/10000], loss: 0.40882 acc: 0.89333 val_loss: 0.39510, val_acc: 0.93333\n",
      "Epoch [1450/10000], loss: 0.40796 acc: 0.89333 val_loss: 0.39424, val_acc: 0.93333\n",
      "Epoch [1460/10000], loss: 0.40711 acc: 0.89333 val_loss: 0.39339, val_acc: 0.93333\n",
      "Epoch [1470/10000], loss: 0.40627 acc: 0.89333 val_loss: 0.39254, val_acc: 0.93333\n",
      "Epoch [1480/10000], loss: 0.40543 acc: 0.90667 val_loss: 0.39170, val_acc: 0.93333\n",
      "Epoch [1490/10000], loss: 0.40460 acc: 0.90667 val_loss: 0.39086, val_acc: 0.93333\n",
      "Epoch [1500/10000], loss: 0.40378 acc: 0.90667 val_loss: 0.39003, val_acc: 0.93333\n",
      "Epoch [1510/10000], loss: 0.40296 acc: 0.90667 val_loss: 0.38921, val_acc: 0.93333\n",
      "Epoch [1520/10000], loss: 0.40214 acc: 0.90667 val_loss: 0.38839, val_acc: 0.93333\n",
      "Epoch [1530/10000], loss: 0.40134 acc: 0.90667 val_loss: 0.38758, val_acc: 0.93333\n",
      "Epoch [1540/10000], loss: 0.40053 acc: 0.90667 val_loss: 0.38677, val_acc: 0.93333\n",
      "Epoch [1550/10000], loss: 0.39974 acc: 0.90667 val_loss: 0.38597, val_acc: 0.93333\n",
      "Epoch [1560/10000], loss: 0.39894 acc: 0.90667 val_loss: 0.38517, val_acc: 0.94667\n",
      "Epoch [1570/10000], loss: 0.39816 acc: 0.90667 val_loss: 0.38438, val_acc: 0.94667\n",
      "Epoch [1580/10000], loss: 0.39738 acc: 0.90667 val_loss: 0.38360, val_acc: 0.94667\n",
      "Epoch [1590/10000], loss: 0.39660 acc: 0.90667 val_loss: 0.38282, val_acc: 0.94667\n",
      "Epoch [1600/10000], loss: 0.39583 acc: 0.90667 val_loss: 0.38204, val_acc: 0.94667\n",
      "Epoch [1610/10000], loss: 0.39507 acc: 0.90667 val_loss: 0.38128, val_acc: 0.94667\n",
      "Epoch [1620/10000], loss: 0.39431 acc: 0.90667 val_loss: 0.38051, val_acc: 0.94667\n",
      "Epoch [1630/10000], loss: 0.39355 acc: 0.90667 val_loss: 0.37975, val_acc: 0.94667\n",
      "Epoch [1640/10000], loss: 0.39280 acc: 0.90667 val_loss: 0.37900, val_acc: 0.94667\n",
      "Epoch [1650/10000], loss: 0.39206 acc: 0.90667 val_loss: 0.37825, val_acc: 0.94667\n",
      "Epoch [1660/10000], loss: 0.39132 acc: 0.90667 val_loss: 0.37751, val_acc: 0.94667\n",
      "Epoch [1670/10000], loss: 0.39058 acc: 0.90667 val_loss: 0.37677, val_acc: 0.94667\n",
      "Epoch [1680/10000], loss: 0.38985 acc: 0.90667 val_loss: 0.37604, val_acc: 0.94667\n",
      "Epoch [1690/10000], loss: 0.38913 acc: 0.90667 val_loss: 0.37531, val_acc: 0.94667\n",
      "Epoch [1700/10000], loss: 0.38841 acc: 0.90667 val_loss: 0.37458, val_acc: 0.94667\n",
      "Epoch [1710/10000], loss: 0.38769 acc: 0.90667 val_loss: 0.37386, val_acc: 0.94667\n",
      "Epoch [1720/10000], loss: 0.38698 acc: 0.90667 val_loss: 0.37315, val_acc: 0.94667\n",
      "Epoch [1730/10000], loss: 0.38627 acc: 0.90667 val_loss: 0.37243, val_acc: 0.94667\n",
      "Epoch [1740/10000], loss: 0.38557 acc: 0.90667 val_loss: 0.37173, val_acc: 0.94667\n",
      "Epoch [1750/10000], loss: 0.38487 acc: 0.90667 val_loss: 0.37103, val_acc: 0.94667\n",
      "Epoch [1760/10000], loss: 0.38417 acc: 0.90667 val_loss: 0.37033, val_acc: 0.94667\n",
      "Epoch [1770/10000], loss: 0.38348 acc: 0.90667 val_loss: 0.36964, val_acc: 0.94667\n",
      "Epoch [1780/10000], loss: 0.38280 acc: 0.90667 val_loss: 0.36895, val_acc: 0.94667\n",
      "Epoch [1790/10000], loss: 0.38212 acc: 0.90667 val_loss: 0.36826, val_acc: 0.94667\n",
      "Epoch [1800/10000], loss: 0.38144 acc: 0.90667 val_loss: 0.36758, val_acc: 0.94667\n",
      "Epoch [1810/10000], loss: 0.38076 acc: 0.90667 val_loss: 0.36690, val_acc: 0.94667\n",
      "Epoch [1820/10000], loss: 0.38009 acc: 0.90667 val_loss: 0.36623, val_acc: 0.94667\n",
      "Epoch [1830/10000], loss: 0.37943 acc: 0.90667 val_loss: 0.36556, val_acc: 0.94667\n",
      "Epoch [1840/10000], loss: 0.37877 acc: 0.90667 val_loss: 0.36490, val_acc: 0.94667\n",
      "Epoch [1850/10000], loss: 0.37811 acc: 0.90667 val_loss: 0.36424, val_acc: 0.94667\n",
      "Epoch [1860/10000], loss: 0.37746 acc: 0.90667 val_loss: 0.36358, val_acc: 0.94667\n",
      "Epoch [1870/10000], loss: 0.37681 acc: 0.90667 val_loss: 0.36293, val_acc: 0.94667\n",
      "Epoch [1880/10000], loss: 0.37616 acc: 0.90667 val_loss: 0.36228, val_acc: 0.94667\n",
      "Epoch [1890/10000], loss: 0.37552 acc: 0.90667 val_loss: 0.36163, val_acc: 0.94667\n",
      "Epoch [1900/10000], loss: 0.37488 acc: 0.90667 val_loss: 0.36099, val_acc: 0.94667\n",
      "Epoch [1910/10000], loss: 0.37424 acc: 0.90667 val_loss: 0.36035, val_acc: 0.94667\n",
      "Epoch [1920/10000], loss: 0.37361 acc: 0.90667 val_loss: 0.35972, val_acc: 0.94667\n",
      "Epoch [1930/10000], loss: 0.37298 acc: 0.90667 val_loss: 0.35909, val_acc: 0.94667\n",
      "Epoch [1940/10000], loss: 0.37236 acc: 0.90667 val_loss: 0.35846, val_acc: 0.94667\n",
      "Epoch [1950/10000], loss: 0.37174 acc: 0.90667 val_loss: 0.35784, val_acc: 0.94667\n",
      "Epoch [1960/10000], loss: 0.37112 acc: 0.90667 val_loss: 0.35722, val_acc: 0.94667\n",
      "Epoch [1970/10000], loss: 0.37051 acc: 0.90667 val_loss: 0.35660, val_acc: 0.94667\n",
      "Epoch [1980/10000], loss: 0.36990 acc: 0.90667 val_loss: 0.35599, val_acc: 0.94667\n",
      "Epoch [1990/10000], loss: 0.36929 acc: 0.90667 val_loss: 0.35538, val_acc: 0.94667\n",
      "Epoch [2000/10000], loss: 0.36869 acc: 0.90667 val_loss: 0.35477, val_acc: 0.94667\n",
      "Epoch [2010/10000], loss: 0.36809 acc: 0.90667 val_loss: 0.35417, val_acc: 0.94667\n",
      "Epoch [2020/10000], loss: 0.36749 acc: 0.90667 val_loss: 0.35357, val_acc: 0.94667\n",
      "Epoch [2030/10000], loss: 0.36690 acc: 0.90667 val_loss: 0.35298, val_acc: 0.94667\n",
      "Epoch [2040/10000], loss: 0.36631 acc: 0.90667 val_loss: 0.35238, val_acc: 0.94667\n",
      "Epoch [2050/10000], loss: 0.36572 acc: 0.90667 val_loss: 0.35179, val_acc: 0.94667\n",
      "Epoch [2060/10000], loss: 0.36514 acc: 0.90667 val_loss: 0.35121, val_acc: 0.94667\n",
      "Epoch [2070/10000], loss: 0.36455 acc: 0.90667 val_loss: 0.35062, val_acc: 0.94667\n",
      "Epoch [2080/10000], loss: 0.36398 acc: 0.90667 val_loss: 0.35004, val_acc: 0.94667\n",
      "Epoch [2090/10000], loss: 0.36340 acc: 0.90667 val_loss: 0.34947, val_acc: 0.94667\n",
      "Epoch [2100/10000], loss: 0.36283 acc: 0.90667 val_loss: 0.34889, val_acc: 0.94667\n",
      "Epoch [2110/10000], loss: 0.36226 acc: 0.90667 val_loss: 0.34832, val_acc: 0.94667\n",
      "Epoch [2120/10000], loss: 0.36170 acc: 0.90667 val_loss: 0.34775, val_acc: 0.94667\n",
      "Epoch [2130/10000], loss: 0.36114 acc: 0.90667 val_loss: 0.34719, val_acc: 0.94667\n",
      "Epoch [2140/10000], loss: 0.36058 acc: 0.90667 val_loss: 0.34663, val_acc: 0.94667\n",
      "Epoch [2150/10000], loss: 0.36002 acc: 0.90667 val_loss: 0.34607, val_acc: 0.94667\n",
      "Epoch [2160/10000], loss: 0.35947 acc: 0.90667 val_loss: 0.34551, val_acc: 0.94667\n",
      "Epoch [2170/10000], loss: 0.35892 acc: 0.90667 val_loss: 0.34496, val_acc: 0.94667\n",
      "Epoch [2180/10000], loss: 0.35837 acc: 0.90667 val_loss: 0.34441, val_acc: 0.94667\n",
      "Epoch [2190/10000], loss: 0.35782 acc: 0.90667 val_loss: 0.34386, val_acc: 0.94667\n",
      "Epoch [2200/10000], loss: 0.35728 acc: 0.90667 val_loss: 0.34331, val_acc: 0.94667\n",
      "Epoch [2210/10000], loss: 0.35674 acc: 0.90667 val_loss: 0.34277, val_acc: 0.94667\n",
      "Epoch [2220/10000], loss: 0.35620 acc: 0.90667 val_loss: 0.34223, val_acc: 0.94667\n",
      "Epoch [2230/10000], loss: 0.35567 acc: 0.90667 val_loss: 0.34170, val_acc: 0.94667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2240/10000], loss: 0.35514 acc: 0.90667 val_loss: 0.34116, val_acc: 0.94667\n",
      "Epoch [2250/10000], loss: 0.35461 acc: 0.90667 val_loss: 0.34063, val_acc: 0.94667\n",
      "Epoch [2260/10000], loss: 0.35409 acc: 0.90667 val_loss: 0.34010, val_acc: 0.94667\n",
      "Epoch [2270/10000], loss: 0.35356 acc: 0.90667 val_loss: 0.33958, val_acc: 0.94667\n",
      "Epoch [2280/10000], loss: 0.35304 acc: 0.90667 val_loss: 0.33905, val_acc: 0.94667\n",
      "Epoch [2290/10000], loss: 0.35253 acc: 0.90667 val_loss: 0.33853, val_acc: 0.94667\n",
      "Epoch [2300/10000], loss: 0.35201 acc: 0.90667 val_loss: 0.33802, val_acc: 0.94667\n",
      "Epoch [2310/10000], loss: 0.35150 acc: 0.90667 val_loss: 0.33750, val_acc: 0.94667\n",
      "Epoch [2320/10000], loss: 0.35099 acc: 0.90667 val_loss: 0.33699, val_acc: 0.94667\n",
      "Epoch [2330/10000], loss: 0.35048 acc: 0.90667 val_loss: 0.33648, val_acc: 0.94667\n",
      "Epoch [2340/10000], loss: 0.34998 acc: 0.90667 val_loss: 0.33597, val_acc: 0.94667\n",
      "Epoch [2350/10000], loss: 0.34947 acc: 0.90667 val_loss: 0.33546, val_acc: 0.94667\n",
      "Epoch [2360/10000], loss: 0.34897 acc: 0.90667 val_loss: 0.33496, val_acc: 0.94667\n",
      "Epoch [2370/10000], loss: 0.34848 acc: 0.90667 val_loss: 0.33446, val_acc: 0.94667\n",
      "Epoch [2380/10000], loss: 0.34798 acc: 0.90667 val_loss: 0.33396, val_acc: 0.94667\n",
      "Epoch [2390/10000], loss: 0.34749 acc: 0.90667 val_loss: 0.33347, val_acc: 0.94667\n",
      "Epoch [2400/10000], loss: 0.34700 acc: 0.90667 val_loss: 0.33297, val_acc: 0.94667\n",
      "Epoch [2410/10000], loss: 0.34651 acc: 0.90667 val_loss: 0.33248, val_acc: 0.94667\n",
      "Epoch [2420/10000], loss: 0.34602 acc: 0.90667 val_loss: 0.33199, val_acc: 0.94667\n",
      "Epoch [2430/10000], loss: 0.34554 acc: 0.90667 val_loss: 0.33151, val_acc: 0.94667\n",
      "Epoch [2440/10000], loss: 0.34506 acc: 0.90667 val_loss: 0.33102, val_acc: 0.94667\n",
      "Epoch [2450/10000], loss: 0.34458 acc: 0.90667 val_loss: 0.33054, val_acc: 0.94667\n",
      "Epoch [2460/10000], loss: 0.34411 acc: 0.90667 val_loss: 0.33006, val_acc: 0.94667\n",
      "Epoch [2470/10000], loss: 0.34363 acc: 0.90667 val_loss: 0.32959, val_acc: 0.94667\n",
      "Epoch [2480/10000], loss: 0.34316 acc: 0.90667 val_loss: 0.32911, val_acc: 0.94667\n",
      "Epoch [2490/10000], loss: 0.34269 acc: 0.90667 val_loss: 0.32864, val_acc: 0.94667\n",
      "Epoch [2500/10000], loss: 0.34222 acc: 0.90667 val_loss: 0.32817, val_acc: 0.94667\n",
      "Epoch [2510/10000], loss: 0.34176 acc: 0.90667 val_loss: 0.32770, val_acc: 0.94667\n",
      "Epoch [2520/10000], loss: 0.34130 acc: 0.90667 val_loss: 0.32723, val_acc: 0.94667\n",
      "Epoch [2530/10000], loss: 0.34083 acc: 0.90667 val_loss: 0.32677, val_acc: 0.94667\n",
      "Epoch [2540/10000], loss: 0.34038 acc: 0.90667 val_loss: 0.32631, val_acc: 0.94667\n",
      "Epoch [2550/10000], loss: 0.33992 acc: 0.90667 val_loss: 0.32585, val_acc: 0.94667\n",
      "Epoch [2560/10000], loss: 0.33947 acc: 0.90667 val_loss: 0.32539, val_acc: 0.94667\n",
      "Epoch [2570/10000], loss: 0.33901 acc: 0.90667 val_loss: 0.32493, val_acc: 0.94667\n",
      "Epoch [2580/10000], loss: 0.33856 acc: 0.90667 val_loss: 0.32448, val_acc: 0.94667\n",
      "Epoch [2590/10000], loss: 0.33812 acc: 0.90667 val_loss: 0.32403, val_acc: 0.94667\n",
      "Epoch [2600/10000], loss: 0.33767 acc: 0.90667 val_loss: 0.32358, val_acc: 0.94667\n",
      "Epoch [2610/10000], loss: 0.33723 acc: 0.90667 val_loss: 0.32313, val_acc: 0.94667\n",
      "Epoch [2620/10000], loss: 0.33678 acc: 0.90667 val_loss: 0.32269, val_acc: 0.94667\n",
      "Epoch [2630/10000], loss: 0.33634 acc: 0.90667 val_loss: 0.32225, val_acc: 0.94667\n",
      "Epoch [2640/10000], loss: 0.33591 acc: 0.90667 val_loss: 0.32180, val_acc: 0.94667\n",
      "Epoch [2650/10000], loss: 0.33547 acc: 0.90667 val_loss: 0.32136, val_acc: 0.94667\n",
      "Epoch [2660/10000], loss: 0.33504 acc: 0.90667 val_loss: 0.32093, val_acc: 0.94667\n",
      "Epoch [2670/10000], loss: 0.33460 acc: 0.90667 val_loss: 0.32049, val_acc: 0.94667\n",
      "Epoch [2680/10000], loss: 0.33417 acc: 0.90667 val_loss: 0.32006, val_acc: 0.94667\n",
      "Epoch [2690/10000], loss: 0.33375 acc: 0.90667 val_loss: 0.31963, val_acc: 0.94667\n",
      "Epoch [2700/10000], loss: 0.33332 acc: 0.90667 val_loss: 0.31920, val_acc: 0.94667\n",
      "Epoch [2710/10000], loss: 0.33290 acc: 0.90667 val_loss: 0.31877, val_acc: 0.94667\n",
      "Epoch [2720/10000], loss: 0.33247 acc: 0.90667 val_loss: 0.31834, val_acc: 0.94667\n",
      "Epoch [2730/10000], loss: 0.33205 acc: 0.90667 val_loss: 0.31792, val_acc: 0.94667\n",
      "Epoch [2740/10000], loss: 0.33164 acc: 0.90667 val_loss: 0.31750, val_acc: 0.94667\n",
      "Epoch [2750/10000], loss: 0.33122 acc: 0.90667 val_loss: 0.31708, val_acc: 0.94667\n",
      "Epoch [2760/10000], loss: 0.33080 acc: 0.90667 val_loss: 0.31666, val_acc: 0.94667\n",
      "Epoch [2770/10000], loss: 0.33039 acc: 0.90667 val_loss: 0.31624, val_acc: 0.94667\n",
      "Epoch [2780/10000], loss: 0.32998 acc: 0.90667 val_loss: 0.31583, val_acc: 0.94667\n",
      "Epoch [2790/10000], loss: 0.32957 acc: 0.90667 val_loss: 0.31542, val_acc: 0.94667\n",
      "Epoch [2800/10000], loss: 0.32916 acc: 0.90667 val_loss: 0.31500, val_acc: 0.94667\n",
      "Epoch [2810/10000], loss: 0.32876 acc: 0.90667 val_loss: 0.31459, val_acc: 0.94667\n",
      "Epoch [2820/10000], loss: 0.32835 acc: 0.90667 val_loss: 0.31419, val_acc: 0.94667\n",
      "Epoch [2830/10000], loss: 0.32795 acc: 0.90667 val_loss: 0.31378, val_acc: 0.94667\n",
      "Epoch [2840/10000], loss: 0.32755 acc: 0.90667 val_loss: 0.31338, val_acc: 0.94667\n",
      "Epoch [2850/10000], loss: 0.32715 acc: 0.90667 val_loss: 0.31297, val_acc: 0.94667\n",
      "Epoch [2860/10000], loss: 0.32675 acc: 0.90667 val_loss: 0.31257, val_acc: 0.94667\n",
      "Epoch [2870/10000], loss: 0.32636 acc: 0.90667 val_loss: 0.31217, val_acc: 0.94667\n",
      "Epoch [2880/10000], loss: 0.32597 acc: 0.90667 val_loss: 0.31178, val_acc: 0.94667\n",
      "Epoch [2890/10000], loss: 0.32557 acc: 0.90667 val_loss: 0.31138, val_acc: 0.94667\n",
      "Epoch [2900/10000], loss: 0.32518 acc: 0.90667 val_loss: 0.31099, val_acc: 0.94667\n",
      "Epoch [2910/10000], loss: 0.32480 acc: 0.90667 val_loss: 0.31060, val_acc: 0.94667\n",
      "Epoch [2920/10000], loss: 0.32441 acc: 0.90667 val_loss: 0.31020, val_acc: 0.94667\n",
      "Epoch [2930/10000], loss: 0.32402 acc: 0.90667 val_loss: 0.30982, val_acc: 0.94667\n",
      "Epoch [2940/10000], loss: 0.32364 acc: 0.90667 val_loss: 0.30943, val_acc: 0.94667\n",
      "Epoch [2950/10000], loss: 0.32326 acc: 0.90667 val_loss: 0.30904, val_acc: 0.94667\n",
      "Epoch [2960/10000], loss: 0.32288 acc: 0.90667 val_loss: 0.30866, val_acc: 0.94667\n",
      "Epoch [2970/10000], loss: 0.32250 acc: 0.90667 val_loss: 0.30827, val_acc: 0.94667\n",
      "Epoch [2980/10000], loss: 0.32212 acc: 0.90667 val_loss: 0.30789, val_acc: 0.94667\n",
      "Epoch [2990/10000], loss: 0.32175 acc: 0.90667 val_loss: 0.30751, val_acc: 0.94667\n",
      "Epoch [3000/10000], loss: 0.32137 acc: 0.90667 val_loss: 0.30714, val_acc: 0.94667\n",
      "Epoch [3010/10000], loss: 0.32100 acc: 0.90667 val_loss: 0.30676, val_acc: 0.94667\n",
      "Epoch [3020/10000], loss: 0.32063 acc: 0.90667 val_loss: 0.30638, val_acc: 0.94667\n",
      "Epoch [3030/10000], loss: 0.32026 acc: 0.90667 val_loss: 0.30601, val_acc: 0.94667\n",
      "Epoch [3040/10000], loss: 0.31989 acc: 0.90667 val_loss: 0.30564, val_acc: 0.94667\n",
      "Epoch [3050/10000], loss: 0.31952 acc: 0.90667 val_loss: 0.30527, val_acc: 0.94667\n",
      "Epoch [3060/10000], loss: 0.31916 acc: 0.90667 val_loss: 0.30490, val_acc: 0.94667\n",
      "Epoch [3070/10000], loss: 0.31880 acc: 0.90667 val_loss: 0.30453, val_acc: 0.94667\n",
      "Epoch [3080/10000], loss: 0.31844 acc: 0.90667 val_loss: 0.30417, val_acc: 0.94667\n",
      "Epoch [3090/10000], loss: 0.31807 acc: 0.90667 val_loss: 0.30380, val_acc: 0.94667\n",
      "Epoch [3100/10000], loss: 0.31772 acc: 0.90667 val_loss: 0.30344, val_acc: 0.94667\n",
      "Epoch [3110/10000], loss: 0.31736 acc: 0.90667 val_loss: 0.30308, val_acc: 0.94667\n",
      "Epoch [3120/10000], loss: 0.31700 acc: 0.90667 val_loss: 0.30272, val_acc: 0.94667\n",
      "Epoch [3130/10000], loss: 0.31665 acc: 0.90667 val_loss: 0.30236, val_acc: 0.94667\n",
      "Epoch [3140/10000], loss: 0.31630 acc: 0.90667 val_loss: 0.30200, val_acc: 0.94667\n",
      "Epoch [3150/10000], loss: 0.31594 acc: 0.90667 val_loss: 0.30165, val_acc: 0.94667\n",
      "Epoch [3160/10000], loss: 0.31559 acc: 0.90667 val_loss: 0.30129, val_acc: 0.94667\n",
      "Epoch [3170/10000], loss: 0.31525 acc: 0.90667 val_loss: 0.30094, val_acc: 0.94667\n",
      "Epoch [3180/10000], loss: 0.31490 acc: 0.90667 val_loss: 0.30059, val_acc: 0.94667\n",
      "Epoch [3190/10000], loss: 0.31455 acc: 0.90667 val_loss: 0.30024, val_acc: 0.94667\n",
      "Epoch [3200/10000], loss: 0.31421 acc: 0.90667 val_loss: 0.29989, val_acc: 0.94667\n",
      "Epoch [3210/10000], loss: 0.31386 acc: 0.90667 val_loss: 0.29954, val_acc: 0.94667\n",
      "Epoch [3220/10000], loss: 0.31352 acc: 0.90667 val_loss: 0.29920, val_acc: 0.94667\n",
      "Epoch [3230/10000], loss: 0.31318 acc: 0.90667 val_loss: 0.29885, val_acc: 0.94667\n",
      "Epoch [3240/10000], loss: 0.31284 acc: 0.90667 val_loss: 0.29851, val_acc: 0.94667\n",
      "Epoch [3250/10000], loss: 0.31251 acc: 0.90667 val_loss: 0.29816, val_acc: 0.94667\n",
      "Epoch [3260/10000], loss: 0.31217 acc: 0.90667 val_loss: 0.29782, val_acc: 0.94667\n",
      "Epoch [3270/10000], loss: 0.31183 acc: 0.90667 val_loss: 0.29748, val_acc: 0.94667\n",
      "Epoch [3280/10000], loss: 0.31150 acc: 0.90667 val_loss: 0.29715, val_acc: 0.94667\n",
      "Epoch [3290/10000], loss: 0.31117 acc: 0.90667 val_loss: 0.29681, val_acc: 0.94667\n",
      "Epoch [3300/10000], loss: 0.31084 acc: 0.90667 val_loss: 0.29647, val_acc: 0.94667\n",
      "Epoch [3310/10000], loss: 0.31051 acc: 0.90667 val_loss: 0.29614, val_acc: 0.94667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3320/10000], loss: 0.31018 acc: 0.90667 val_loss: 0.29581, val_acc: 0.94667\n",
      "Epoch [3330/10000], loss: 0.30985 acc: 0.90667 val_loss: 0.29548, val_acc: 0.94667\n",
      "Epoch [3340/10000], loss: 0.30953 acc: 0.90667 val_loss: 0.29515, val_acc: 0.94667\n",
      "Epoch [3350/10000], loss: 0.30920 acc: 0.90667 val_loss: 0.29482, val_acc: 0.94667\n",
      "Epoch [3360/10000], loss: 0.30888 acc: 0.90667 val_loss: 0.29449, val_acc: 0.94667\n",
      "Epoch [3370/10000], loss: 0.30856 acc: 0.90667 val_loss: 0.29416, val_acc: 0.94667\n",
      "Epoch [3380/10000], loss: 0.30824 acc: 0.90667 val_loss: 0.29384, val_acc: 0.94667\n",
      "Epoch [3390/10000], loss: 0.30792 acc: 0.90667 val_loss: 0.29351, val_acc: 0.94667\n",
      "Epoch [3400/10000], loss: 0.30760 acc: 0.90667 val_loss: 0.29319, val_acc: 0.94667\n",
      "Epoch [3410/10000], loss: 0.30728 acc: 0.90667 val_loss: 0.29287, val_acc: 0.94667\n",
      "Epoch [3420/10000], loss: 0.30696 acc: 0.90667 val_loss: 0.29255, val_acc: 0.94667\n",
      "Epoch [3430/10000], loss: 0.30665 acc: 0.90667 val_loss: 0.29223, val_acc: 0.94667\n",
      "Epoch [3440/10000], loss: 0.30634 acc: 0.90667 val_loss: 0.29191, val_acc: 0.94667\n",
      "Epoch [3450/10000], loss: 0.30602 acc: 0.90667 val_loss: 0.29159, val_acc: 0.94667\n",
      "Epoch [3460/10000], loss: 0.30571 acc: 0.90667 val_loss: 0.29128, val_acc: 0.94667\n",
      "Epoch [3470/10000], loss: 0.30540 acc: 0.90667 val_loss: 0.29096, val_acc: 0.94667\n",
      "Epoch [3480/10000], loss: 0.30509 acc: 0.90667 val_loss: 0.29065, val_acc: 0.94667\n",
      "Epoch [3490/10000], loss: 0.30479 acc: 0.90667 val_loss: 0.29034, val_acc: 0.94667\n",
      "Epoch [3500/10000], loss: 0.30448 acc: 0.90667 val_loss: 0.29003, val_acc: 0.94667\n",
      "Epoch [3510/10000], loss: 0.30417 acc: 0.90667 val_loss: 0.28972, val_acc: 0.94667\n",
      "Epoch [3520/10000], loss: 0.30387 acc: 0.90667 val_loss: 0.28941, val_acc: 0.94667\n",
      "Epoch [3530/10000], loss: 0.30357 acc: 0.90667 val_loss: 0.28910, val_acc: 0.94667\n",
      "Epoch [3540/10000], loss: 0.30327 acc: 0.90667 val_loss: 0.28879, val_acc: 0.94667\n",
      "Epoch [3550/10000], loss: 0.30297 acc: 0.90667 val_loss: 0.28849, val_acc: 0.94667\n",
      "Epoch [3560/10000], loss: 0.30267 acc: 0.90667 val_loss: 0.28818, val_acc: 0.94667\n",
      "Epoch [3570/10000], loss: 0.30237 acc: 0.90667 val_loss: 0.28788, val_acc: 0.94667\n",
      "Epoch [3580/10000], loss: 0.30207 acc: 0.90667 val_loss: 0.28758, val_acc: 0.94667\n",
      "Epoch [3590/10000], loss: 0.30177 acc: 0.90667 val_loss: 0.28728, val_acc: 0.94667\n",
      "Epoch [3600/10000], loss: 0.30148 acc: 0.90667 val_loss: 0.28698, val_acc: 0.94667\n",
      "Epoch [3610/10000], loss: 0.30119 acc: 0.90667 val_loss: 0.28668, val_acc: 0.94667\n",
      "Epoch [3620/10000], loss: 0.30089 acc: 0.90667 val_loss: 0.28638, val_acc: 0.96000\n",
      "Epoch [3630/10000], loss: 0.30060 acc: 0.90667 val_loss: 0.28608, val_acc: 0.96000\n",
      "Epoch [3640/10000], loss: 0.30031 acc: 0.90667 val_loss: 0.28579, val_acc: 0.96000\n",
      "Epoch [3650/10000], loss: 0.30002 acc: 0.90667 val_loss: 0.28549, val_acc: 0.96000\n",
      "Epoch [3660/10000], loss: 0.29973 acc: 0.90667 val_loss: 0.28520, val_acc: 0.96000\n",
      "Epoch [3670/10000], loss: 0.29944 acc: 0.90667 val_loss: 0.28491, val_acc: 0.96000\n",
      "Epoch [3680/10000], loss: 0.29916 acc: 0.90667 val_loss: 0.28462, val_acc: 0.96000\n",
      "Epoch [3690/10000], loss: 0.29887 acc: 0.90667 val_loss: 0.28433, val_acc: 0.96000\n",
      "Epoch [3700/10000], loss: 0.29859 acc: 0.90667 val_loss: 0.28404, val_acc: 0.96000\n",
      "Epoch [3710/10000], loss: 0.29830 acc: 0.90667 val_loss: 0.28375, val_acc: 0.96000\n",
      "Epoch [3720/10000], loss: 0.29802 acc: 0.90667 val_loss: 0.28346, val_acc: 0.96000\n",
      "Epoch [3730/10000], loss: 0.29774 acc: 0.90667 val_loss: 0.28318, val_acc: 0.96000\n",
      "Epoch [3740/10000], loss: 0.29746 acc: 0.90667 val_loss: 0.28289, val_acc: 0.96000\n",
      "Epoch [3750/10000], loss: 0.29718 acc: 0.90667 val_loss: 0.28261, val_acc: 0.96000\n",
      "Epoch [3760/10000], loss: 0.29690 acc: 0.90667 val_loss: 0.28232, val_acc: 0.96000\n",
      "Epoch [3770/10000], loss: 0.29663 acc: 0.90667 val_loss: 0.28204, val_acc: 0.96000\n",
      "Epoch [3780/10000], loss: 0.29635 acc: 0.90667 val_loss: 0.28176, val_acc: 0.96000\n",
      "Epoch [3790/10000], loss: 0.29607 acc: 0.90667 val_loss: 0.28148, val_acc: 0.96000\n",
      "Epoch [3800/10000], loss: 0.29580 acc: 0.90667 val_loss: 0.28120, val_acc: 0.96000\n",
      "Epoch [3810/10000], loss: 0.29553 acc: 0.90667 val_loss: 0.28092, val_acc: 0.96000\n",
      "Epoch [3820/10000], loss: 0.29525 acc: 0.90667 val_loss: 0.28064, val_acc: 0.96000\n",
      "Epoch [3830/10000], loss: 0.29498 acc: 0.90667 val_loss: 0.28037, val_acc: 0.96000\n",
      "Epoch [3840/10000], loss: 0.29471 acc: 0.90667 val_loss: 0.28009, val_acc: 0.96000\n",
      "Epoch [3850/10000], loss: 0.29444 acc: 0.90667 val_loss: 0.27982, val_acc: 0.96000\n",
      "Epoch [3860/10000], loss: 0.29418 acc: 0.90667 val_loss: 0.27954, val_acc: 0.96000\n",
      "Epoch [3870/10000], loss: 0.29391 acc: 0.90667 val_loss: 0.27927, val_acc: 0.96000\n",
      "Epoch [3880/10000], loss: 0.29364 acc: 0.90667 val_loss: 0.27900, val_acc: 0.96000\n",
      "Epoch [3890/10000], loss: 0.29338 acc: 0.90667 val_loss: 0.27873, val_acc: 0.96000\n",
      "Epoch [3900/10000], loss: 0.29311 acc: 0.90667 val_loss: 0.27846, val_acc: 0.96000\n",
      "Epoch [3910/10000], loss: 0.29285 acc: 0.90667 val_loss: 0.27819, val_acc: 0.96000\n",
      "Epoch [3920/10000], loss: 0.29258 acc: 0.90667 val_loss: 0.27792, val_acc: 0.96000\n",
      "Epoch [3930/10000], loss: 0.29232 acc: 0.90667 val_loss: 0.27766, val_acc: 0.96000\n",
      "Epoch [3940/10000], loss: 0.29206 acc: 0.90667 val_loss: 0.27739, val_acc: 0.96000\n",
      "Epoch [3950/10000], loss: 0.29180 acc: 0.90667 val_loss: 0.27712, val_acc: 0.96000\n",
      "Epoch [3960/10000], loss: 0.29154 acc: 0.90667 val_loss: 0.27686, val_acc: 0.96000\n",
      "Epoch [3970/10000], loss: 0.29128 acc: 0.90667 val_loss: 0.27660, val_acc: 0.96000\n",
      "Epoch [3980/10000], loss: 0.29103 acc: 0.90667 val_loss: 0.27633, val_acc: 0.96000\n",
      "Epoch [3990/10000], loss: 0.29077 acc: 0.90667 val_loss: 0.27607, val_acc: 0.96000\n",
      "Epoch [4000/10000], loss: 0.29052 acc: 0.90667 val_loss: 0.27581, val_acc: 0.96000\n",
      "Epoch [4010/10000], loss: 0.29026 acc: 0.90667 val_loss: 0.27555, val_acc: 0.96000\n",
      "Epoch [4020/10000], loss: 0.29001 acc: 0.90667 val_loss: 0.27529, val_acc: 0.96000\n",
      "Epoch [4030/10000], loss: 0.28975 acc: 0.90667 val_loss: 0.27504, val_acc: 0.96000\n",
      "Epoch [4040/10000], loss: 0.28950 acc: 0.90667 val_loss: 0.27478, val_acc: 0.96000\n",
      "Epoch [4050/10000], loss: 0.28925 acc: 0.90667 val_loss: 0.27452, val_acc: 0.96000\n",
      "Epoch [4060/10000], loss: 0.28900 acc: 0.90667 val_loss: 0.27427, val_acc: 0.96000\n",
      "Epoch [4070/10000], loss: 0.28875 acc: 0.90667 val_loss: 0.27401, val_acc: 0.96000\n",
      "Epoch [4080/10000], loss: 0.28850 acc: 0.90667 val_loss: 0.27376, val_acc: 0.96000\n",
      "Epoch [4090/10000], loss: 0.28826 acc: 0.90667 val_loss: 0.27351, val_acc: 0.96000\n",
      "Epoch [4100/10000], loss: 0.28801 acc: 0.90667 val_loss: 0.27325, val_acc: 0.96000\n",
      "Epoch [4110/10000], loss: 0.28776 acc: 0.90667 val_loss: 0.27300, val_acc: 0.96000\n",
      "Epoch [4120/10000], loss: 0.28752 acc: 0.90667 val_loss: 0.27275, val_acc: 0.96000\n",
      "Epoch [4130/10000], loss: 0.28727 acc: 0.90667 val_loss: 0.27250, val_acc: 0.96000\n",
      "Epoch [4140/10000], loss: 0.28703 acc: 0.90667 val_loss: 0.27225, val_acc: 0.96000\n",
      "Epoch [4150/10000], loss: 0.28679 acc: 0.90667 val_loss: 0.27200, val_acc: 0.96000\n",
      "Epoch [4160/10000], loss: 0.28654 acc: 0.90667 val_loss: 0.27176, val_acc: 0.96000\n",
      "Epoch [4170/10000], loss: 0.28630 acc: 0.90667 val_loss: 0.27151, val_acc: 0.96000\n",
      "Epoch [4180/10000], loss: 0.28606 acc: 0.90667 val_loss: 0.27127, val_acc: 0.96000\n",
      "Epoch [4190/10000], loss: 0.28582 acc: 0.90667 val_loss: 0.27102, val_acc: 0.96000\n",
      "Epoch [4200/10000], loss: 0.28559 acc: 0.90667 val_loss: 0.27078, val_acc: 0.96000\n",
      "Epoch [4210/10000], loss: 0.28535 acc: 0.90667 val_loss: 0.27053, val_acc: 0.96000\n",
      "Epoch [4220/10000], loss: 0.28511 acc: 0.90667 val_loss: 0.27029, val_acc: 0.96000\n",
      "Epoch [4230/10000], loss: 0.28487 acc: 0.90667 val_loss: 0.27005, val_acc: 0.96000\n",
      "Epoch [4240/10000], loss: 0.28464 acc: 0.90667 val_loss: 0.26981, val_acc: 0.96000\n",
      "Epoch [4250/10000], loss: 0.28440 acc: 0.90667 val_loss: 0.26957, val_acc: 0.96000\n",
      "Epoch [4260/10000], loss: 0.28417 acc: 0.90667 val_loss: 0.26933, val_acc: 0.96000\n",
      "Epoch [4270/10000], loss: 0.28394 acc: 0.90667 val_loss: 0.26909, val_acc: 0.96000\n",
      "Epoch [4280/10000], loss: 0.28370 acc: 0.90667 val_loss: 0.26885, val_acc: 0.96000\n",
      "Epoch [4290/10000], loss: 0.28347 acc: 0.90667 val_loss: 0.26862, val_acc: 0.96000\n",
      "Epoch [4300/10000], loss: 0.28324 acc: 0.90667 val_loss: 0.26838, val_acc: 0.96000\n",
      "Epoch [4310/10000], loss: 0.28301 acc: 0.90667 val_loss: 0.26815, val_acc: 0.96000\n",
      "Epoch [4320/10000], loss: 0.28278 acc: 0.90667 val_loss: 0.26791, val_acc: 0.96000\n",
      "Epoch [4330/10000], loss: 0.28255 acc: 0.90667 val_loss: 0.26768, val_acc: 0.96000\n",
      "Epoch [4340/10000], loss: 0.28233 acc: 0.90667 val_loss: 0.26744, val_acc: 0.96000\n",
      "Epoch [4350/10000], loss: 0.28210 acc: 0.90667 val_loss: 0.26721, val_acc: 0.96000\n",
      "Epoch [4360/10000], loss: 0.28187 acc: 0.90667 val_loss: 0.26698, val_acc: 0.96000\n",
      "Epoch [4370/10000], loss: 0.28165 acc: 0.90667 val_loss: 0.26675, val_acc: 0.96000\n",
      "Epoch [4380/10000], loss: 0.28142 acc: 0.90667 val_loss: 0.26652, val_acc: 0.96000\n",
      "Epoch [4390/10000], loss: 0.28120 acc: 0.90667 val_loss: 0.26629, val_acc: 0.96000\n",
      "Epoch [4400/10000], loss: 0.28098 acc: 0.90667 val_loss: 0.26606, val_acc: 0.96000\n",
      "Epoch [4410/10000], loss: 0.28075 acc: 0.90667 val_loss: 0.26583, val_acc: 0.96000\n",
      "Epoch [4420/10000], loss: 0.28053 acc: 0.90667 val_loss: 0.26560, val_acc: 0.96000\n",
      "Epoch [4430/10000], loss: 0.28031 acc: 0.90667 val_loss: 0.26538, val_acc: 0.96000\n",
      "Epoch [4440/10000], loss: 0.28009 acc: 0.90667 val_loss: 0.26515, val_acc: 0.96000\n",
      "Epoch [4450/10000], loss: 0.27987 acc: 0.90667 val_loss: 0.26493, val_acc: 0.96000\n",
      "Epoch [4460/10000], loss: 0.27965 acc: 0.90667 val_loss: 0.26470, val_acc: 0.96000\n",
      "Epoch [4470/10000], loss: 0.27943 acc: 0.90667 val_loss: 0.26448, val_acc: 0.96000\n",
      "Epoch [4480/10000], loss: 0.27922 acc: 0.90667 val_loss: 0.26425, val_acc: 0.96000\n",
      "Epoch [4490/10000], loss: 0.27900 acc: 0.90667 val_loss: 0.26403, val_acc: 0.96000\n",
      "Epoch [4500/10000], loss: 0.27878 acc: 0.90667 val_loss: 0.26381, val_acc: 0.96000\n",
      "Epoch [4510/10000], loss: 0.27857 acc: 0.90667 val_loss: 0.26359, val_acc: 0.96000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4520/10000], loss: 0.27835 acc: 0.90667 val_loss: 0.26337, val_acc: 0.96000\n",
      "Epoch [4530/10000], loss: 0.27814 acc: 0.90667 val_loss: 0.26315, val_acc: 0.96000\n",
      "Epoch [4540/10000], loss: 0.27792 acc: 0.90667 val_loss: 0.26293, val_acc: 0.96000\n",
      "Epoch [4550/10000], loss: 0.27771 acc: 0.90667 val_loss: 0.26271, val_acc: 0.96000\n",
      "Epoch [4560/10000], loss: 0.27750 acc: 0.90667 val_loss: 0.26249, val_acc: 0.96000\n",
      "Epoch [4570/10000], loss: 0.27729 acc: 0.90667 val_loss: 0.26228, val_acc: 0.96000\n",
      "Epoch [4580/10000], loss: 0.27708 acc: 0.90667 val_loss: 0.26206, val_acc: 0.96000\n",
      "Epoch [4590/10000], loss: 0.27687 acc: 0.90667 val_loss: 0.26185, val_acc: 0.96000\n",
      "Epoch [4600/10000], loss: 0.27666 acc: 0.90667 val_loss: 0.26163, val_acc: 0.96000\n",
      "Epoch [4610/10000], loss: 0.27645 acc: 0.90667 val_loss: 0.26142, val_acc: 0.96000\n",
      "Epoch [4620/10000], loss: 0.27624 acc: 0.90667 val_loss: 0.26120, val_acc: 0.96000\n",
      "Epoch [4630/10000], loss: 0.27603 acc: 0.90667 val_loss: 0.26099, val_acc: 0.96000\n",
      "Epoch [4640/10000], loss: 0.27583 acc: 0.90667 val_loss: 0.26078, val_acc: 0.96000\n",
      "Epoch [4650/10000], loss: 0.27562 acc: 0.90667 val_loss: 0.26057, val_acc: 0.96000\n",
      "Epoch [4660/10000], loss: 0.27541 acc: 0.90667 val_loss: 0.26035, val_acc: 0.96000\n",
      "Epoch [4670/10000], loss: 0.27521 acc: 0.90667 val_loss: 0.26014, val_acc: 0.96000\n",
      "Epoch [4680/10000], loss: 0.27500 acc: 0.90667 val_loss: 0.25993, val_acc: 0.96000\n",
      "Epoch [4690/10000], loss: 0.27480 acc: 0.90667 val_loss: 0.25973, val_acc: 0.96000\n",
      "Epoch [4700/10000], loss: 0.27460 acc: 0.90667 val_loss: 0.25952, val_acc: 0.96000\n",
      "Epoch [4710/10000], loss: 0.27440 acc: 0.90667 val_loss: 0.25931, val_acc: 0.96000\n",
      "Epoch [4720/10000], loss: 0.27419 acc: 0.90667 val_loss: 0.25910, val_acc: 0.96000\n",
      "Epoch [4730/10000], loss: 0.27399 acc: 0.90667 val_loss: 0.25889, val_acc: 0.96000\n",
      "Epoch [4740/10000], loss: 0.27379 acc: 0.90667 val_loss: 0.25869, val_acc: 0.96000\n",
      "Epoch [4750/10000], loss: 0.27359 acc: 0.90667 val_loss: 0.25848, val_acc: 0.96000\n",
      "Epoch [4760/10000], loss: 0.27339 acc: 0.90667 val_loss: 0.25828, val_acc: 0.96000\n",
      "Epoch [4770/10000], loss: 0.27319 acc: 0.90667 val_loss: 0.25807, val_acc: 0.96000\n",
      "Epoch [4780/10000], loss: 0.27300 acc: 0.90667 val_loss: 0.25787, val_acc: 0.96000\n",
      "Epoch [4790/10000], loss: 0.27280 acc: 0.90667 val_loss: 0.25767, val_acc: 0.96000\n",
      "Epoch [4800/10000], loss: 0.27260 acc: 0.90667 val_loss: 0.25746, val_acc: 0.96000\n",
      "Epoch [4810/10000], loss: 0.27241 acc: 0.90667 val_loss: 0.25726, val_acc: 0.96000\n",
      "Epoch [4820/10000], loss: 0.27221 acc: 0.90667 val_loss: 0.25706, val_acc: 0.96000\n",
      "Epoch [4830/10000], loss: 0.27202 acc: 0.90667 val_loss: 0.25686, val_acc: 0.96000\n",
      "Epoch [4840/10000], loss: 0.27182 acc: 0.90667 val_loss: 0.25666, val_acc: 0.96000\n",
      "Epoch [4850/10000], loss: 0.27163 acc: 0.90667 val_loss: 0.25646, val_acc: 0.96000\n",
      "Epoch [4860/10000], loss: 0.27143 acc: 0.90667 val_loss: 0.25626, val_acc: 0.96000\n",
      "Epoch [4870/10000], loss: 0.27124 acc: 0.90667 val_loss: 0.25606, val_acc: 0.96000\n",
      "Epoch [4880/10000], loss: 0.27105 acc: 0.90667 val_loss: 0.25587, val_acc: 0.96000\n",
      "Epoch [4890/10000], loss: 0.27086 acc: 0.90667 val_loss: 0.25567, val_acc: 0.96000\n",
      "Epoch [4900/10000], loss: 0.27067 acc: 0.90667 val_loss: 0.25547, val_acc: 0.96000\n",
      "Epoch [4910/10000], loss: 0.27048 acc: 0.90667 val_loss: 0.25528, val_acc: 0.96000\n",
      "Epoch [4920/10000], loss: 0.27029 acc: 0.90667 val_loss: 0.25508, val_acc: 0.96000\n",
      "Epoch [4930/10000], loss: 0.27010 acc: 0.90667 val_loss: 0.25489, val_acc: 0.96000\n",
      "Epoch [4940/10000], loss: 0.26991 acc: 0.90667 val_loss: 0.25469, val_acc: 0.96000\n",
      "Epoch [4950/10000], loss: 0.26972 acc: 0.90667 val_loss: 0.25450, val_acc: 0.96000\n",
      "Epoch [4960/10000], loss: 0.26953 acc: 0.90667 val_loss: 0.25431, val_acc: 0.96000\n",
      "Epoch [4970/10000], loss: 0.26935 acc: 0.90667 val_loss: 0.25411, val_acc: 0.96000\n",
      "Epoch [4980/10000], loss: 0.26916 acc: 0.90667 val_loss: 0.25392, val_acc: 0.96000\n",
      "Epoch [4990/10000], loss: 0.26897 acc: 0.90667 val_loss: 0.25373, val_acc: 0.96000\n",
      "Epoch [5000/10000], loss: 0.26879 acc: 0.90667 val_loss: 0.25354, val_acc: 0.96000\n",
      "Epoch [5010/10000], loss: 0.26860 acc: 0.90667 val_loss: 0.25335, val_acc: 0.96000\n",
      "Epoch [5020/10000], loss: 0.26842 acc: 0.90667 val_loss: 0.25316, val_acc: 0.96000\n",
      "Epoch [5030/10000], loss: 0.26824 acc: 0.90667 val_loss: 0.25297, val_acc: 0.96000\n",
      "Epoch [5040/10000], loss: 0.26805 acc: 0.90667 val_loss: 0.25278, val_acc: 0.96000\n",
      "Epoch [5050/10000], loss: 0.26787 acc: 0.90667 val_loss: 0.25259, val_acc: 0.96000\n",
      "Epoch [5060/10000], loss: 0.26769 acc: 0.90667 val_loss: 0.25240, val_acc: 0.96000\n",
      "Epoch [5070/10000], loss: 0.26751 acc: 0.90667 val_loss: 0.25222, val_acc: 0.96000\n",
      "Epoch [5080/10000], loss: 0.26733 acc: 0.90667 val_loss: 0.25203, val_acc: 0.96000\n",
      "Epoch [5090/10000], loss: 0.26715 acc: 0.90667 val_loss: 0.25184, val_acc: 0.96000\n",
      "Epoch [5100/10000], loss: 0.26697 acc: 0.90667 val_loss: 0.25166, val_acc: 0.96000\n",
      "Epoch [5110/10000], loss: 0.26679 acc: 0.90667 val_loss: 0.25147, val_acc: 0.96000\n",
      "Epoch [5120/10000], loss: 0.26661 acc: 0.90667 val_loss: 0.25129, val_acc: 0.96000\n",
      "Epoch [5130/10000], loss: 0.26643 acc: 0.90667 val_loss: 0.25111, val_acc: 0.96000\n",
      "Epoch [5140/10000], loss: 0.26625 acc: 0.90667 val_loss: 0.25092, val_acc: 0.96000\n",
      "Epoch [5150/10000], loss: 0.26608 acc: 0.90667 val_loss: 0.25074, val_acc: 0.96000\n",
      "Epoch [5160/10000], loss: 0.26590 acc: 0.90667 val_loss: 0.25056, val_acc: 0.96000\n",
      "Epoch [5170/10000], loss: 0.26572 acc: 0.90667 val_loss: 0.25037, val_acc: 0.96000\n",
      "Epoch [5180/10000], loss: 0.26555 acc: 0.90667 val_loss: 0.25019, val_acc: 0.96000\n",
      "Epoch [5190/10000], loss: 0.26537 acc: 0.90667 val_loss: 0.25001, val_acc: 0.96000\n",
      "Epoch [5200/10000], loss: 0.26520 acc: 0.90667 val_loss: 0.24983, val_acc: 0.96000\n",
      "Epoch [5210/10000], loss: 0.26502 acc: 0.90667 val_loss: 0.24965, val_acc: 0.96000\n",
      "Epoch [5220/10000], loss: 0.26485 acc: 0.90667 val_loss: 0.24947, val_acc: 0.96000\n",
      "Epoch [5230/10000], loss: 0.26468 acc: 0.90667 val_loss: 0.24929, val_acc: 0.96000\n",
      "Epoch [5240/10000], loss: 0.26450 acc: 0.90667 val_loss: 0.24912, val_acc: 0.96000\n",
      "Epoch [5250/10000], loss: 0.26433 acc: 0.90667 val_loss: 0.24894, val_acc: 0.96000\n",
      "Epoch [5260/10000], loss: 0.26416 acc: 0.90667 val_loss: 0.24876, val_acc: 0.96000\n",
      "Epoch [5270/10000], loss: 0.26399 acc: 0.90667 val_loss: 0.24858, val_acc: 0.96000\n",
      "Epoch [5280/10000], loss: 0.26382 acc: 0.90667 val_loss: 0.24841, val_acc: 0.96000\n",
      "Epoch [5290/10000], loss: 0.26365 acc: 0.90667 val_loss: 0.24823, val_acc: 0.96000\n",
      "Epoch [5300/10000], loss: 0.26348 acc: 0.90667 val_loss: 0.24806, val_acc: 0.96000\n",
      "Epoch [5310/10000], loss: 0.26331 acc: 0.90667 val_loss: 0.24788, val_acc: 0.96000\n",
      "Epoch [5320/10000], loss: 0.26314 acc: 0.90667 val_loss: 0.24771, val_acc: 0.96000\n",
      "Epoch [5330/10000], loss: 0.26297 acc: 0.90667 val_loss: 0.24753, val_acc: 0.96000\n",
      "Epoch [5340/10000], loss: 0.26280 acc: 0.90667 val_loss: 0.24736, val_acc: 0.96000\n",
      "Epoch [5350/10000], loss: 0.26264 acc: 0.90667 val_loss: 0.24719, val_acc: 0.96000\n",
      "Epoch [5360/10000], loss: 0.26247 acc: 0.90667 val_loss: 0.24701, val_acc: 0.96000\n",
      "Epoch [5370/10000], loss: 0.26230 acc: 0.90667 val_loss: 0.24684, val_acc: 0.96000\n",
      "Epoch [5380/10000], loss: 0.26214 acc: 0.90667 val_loss: 0.24667, val_acc: 0.96000\n",
      "Epoch [5390/10000], loss: 0.26197 acc: 0.90667 val_loss: 0.24650, val_acc: 0.96000\n",
      "Epoch [5400/10000], loss: 0.26181 acc: 0.90667 val_loss: 0.24633, val_acc: 0.96000\n",
      "Epoch [5410/10000], loss: 0.26164 acc: 0.90667 val_loss: 0.24616, val_acc: 0.96000\n",
      "Epoch [5420/10000], loss: 0.26148 acc: 0.90667 val_loss: 0.24599, val_acc: 0.96000\n",
      "Epoch [5430/10000], loss: 0.26131 acc: 0.90667 val_loss: 0.24582, val_acc: 0.96000\n",
      "Epoch [5440/10000], loss: 0.26115 acc: 0.90667 val_loss: 0.24565, val_acc: 0.96000\n",
      "Epoch [5450/10000], loss: 0.26099 acc: 0.90667 val_loss: 0.24548, val_acc: 0.96000\n",
      "Epoch [5460/10000], loss: 0.26083 acc: 0.90667 val_loss: 0.24531, val_acc: 0.96000\n",
      "Epoch [5470/10000], loss: 0.26066 acc: 0.90667 val_loss: 0.24514, val_acc: 0.96000\n",
      "Epoch [5480/10000], loss: 0.26050 acc: 0.90667 val_loss: 0.24498, val_acc: 0.96000\n",
      "Epoch [5490/10000], loss: 0.26034 acc: 0.90667 val_loss: 0.24481, val_acc: 0.96000\n",
      "Epoch [5500/10000], loss: 0.26018 acc: 0.90667 val_loss: 0.24464, val_acc: 0.96000\n",
      "Epoch [5510/10000], loss: 0.26002 acc: 0.90667 val_loss: 0.24448, val_acc: 0.96000\n",
      "Epoch [5520/10000], loss: 0.25986 acc: 0.90667 val_loss: 0.24431, val_acc: 0.96000\n",
      "Epoch [5530/10000], loss: 0.25970 acc: 0.90667 val_loss: 0.24415, val_acc: 0.96000\n",
      "Epoch [5540/10000], loss: 0.25954 acc: 0.90667 val_loss: 0.24398, val_acc: 0.96000\n",
      "Epoch [5550/10000], loss: 0.25939 acc: 0.90667 val_loss: 0.24382, val_acc: 0.96000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5560/10000], loss: 0.25923 acc: 0.90667 val_loss: 0.24366, val_acc: 0.96000\n",
      "Epoch [5570/10000], loss: 0.25907 acc: 0.90667 val_loss: 0.24349, val_acc: 0.96000\n",
      "Epoch [5580/10000], loss: 0.25891 acc: 0.90667 val_loss: 0.24333, val_acc: 0.96000\n",
      "Epoch [5590/10000], loss: 0.25876 acc: 0.90667 val_loss: 0.24317, val_acc: 0.96000\n",
      "Epoch [5600/10000], loss: 0.25860 acc: 0.90667 val_loss: 0.24301, val_acc: 0.96000\n",
      "Epoch [5610/10000], loss: 0.25845 acc: 0.90667 val_loss: 0.24285, val_acc: 0.96000\n",
      "Epoch [5620/10000], loss: 0.25829 acc: 0.90667 val_loss: 0.24268, val_acc: 0.96000\n",
      "Epoch [5630/10000], loss: 0.25814 acc: 0.90667 val_loss: 0.24252, val_acc: 0.96000\n",
      "Epoch [5640/10000], loss: 0.25798 acc: 0.90667 val_loss: 0.24236, val_acc: 0.96000\n",
      "Epoch [5650/10000], loss: 0.25783 acc: 0.90667 val_loss: 0.24220, val_acc: 0.96000\n",
      "Epoch [5660/10000], loss: 0.25767 acc: 0.90667 val_loss: 0.24205, val_acc: 0.96000\n",
      "Epoch [5670/10000], loss: 0.25752 acc: 0.90667 val_loss: 0.24189, val_acc: 0.96000\n",
      "Epoch [5680/10000], loss: 0.25737 acc: 0.90667 val_loss: 0.24173, val_acc: 0.96000\n",
      "Epoch [5690/10000], loss: 0.25722 acc: 0.90667 val_loss: 0.24157, val_acc: 0.96000\n",
      "Epoch [5700/10000], loss: 0.25706 acc: 0.90667 val_loss: 0.24141, val_acc: 0.96000\n",
      "Epoch [5710/10000], loss: 0.25691 acc: 0.90667 val_loss: 0.24126, val_acc: 0.96000\n",
      "Epoch [5720/10000], loss: 0.25676 acc: 0.90667 val_loss: 0.24110, val_acc: 0.96000\n",
      "Epoch [5730/10000], loss: 0.25661 acc: 0.90667 val_loss: 0.24094, val_acc: 0.96000\n",
      "Epoch [5740/10000], loss: 0.25646 acc: 0.90667 val_loss: 0.24079, val_acc: 0.96000\n",
      "Epoch [5750/10000], loss: 0.25631 acc: 0.90667 val_loss: 0.24063, val_acc: 0.96000\n",
      "Epoch [5760/10000], loss: 0.25616 acc: 0.90667 val_loss: 0.24048, val_acc: 0.96000\n",
      "Epoch [5770/10000], loss: 0.25601 acc: 0.90667 val_loss: 0.24032, val_acc: 0.96000\n",
      "Epoch [5780/10000], loss: 0.25586 acc: 0.90667 val_loss: 0.24017, val_acc: 0.96000\n",
      "Epoch [5790/10000], loss: 0.25571 acc: 0.90667 val_loss: 0.24001, val_acc: 0.96000\n",
      "Epoch [5800/10000], loss: 0.25557 acc: 0.90667 val_loss: 0.23986, val_acc: 0.96000\n",
      "Epoch [5810/10000], loss: 0.25542 acc: 0.90667 val_loss: 0.23971, val_acc: 0.96000\n",
      "Epoch [5820/10000], loss: 0.25527 acc: 0.90667 val_loss: 0.23955, val_acc: 0.96000\n",
      "Epoch [5830/10000], loss: 0.25513 acc: 0.90667 val_loss: 0.23940, val_acc: 0.96000\n",
      "Epoch [5840/10000], loss: 0.25498 acc: 0.90667 val_loss: 0.23925, val_acc: 0.96000\n",
      "Epoch [5850/10000], loss: 0.25483 acc: 0.90667 val_loss: 0.23910, val_acc: 0.96000\n",
      "Epoch [5860/10000], loss: 0.25469 acc: 0.90667 val_loss: 0.23895, val_acc: 0.96000\n",
      "Epoch [5870/10000], loss: 0.25454 acc: 0.90667 val_loss: 0.23879, val_acc: 0.96000\n",
      "Epoch [5880/10000], loss: 0.25440 acc: 0.90667 val_loss: 0.23864, val_acc: 0.96000\n",
      "Epoch [5890/10000], loss: 0.25425 acc: 0.90667 val_loss: 0.23849, val_acc: 0.96000\n",
      "Epoch [5900/10000], loss: 0.25411 acc: 0.90667 val_loss: 0.23834, val_acc: 0.96000\n",
      "Epoch [5910/10000], loss: 0.25397 acc: 0.90667 val_loss: 0.23819, val_acc: 0.96000\n",
      "Epoch [5920/10000], loss: 0.25382 acc: 0.90667 val_loss: 0.23805, val_acc: 0.96000\n",
      "Epoch [5930/10000], loss: 0.25368 acc: 0.90667 val_loss: 0.23790, val_acc: 0.96000\n",
      "Epoch [5940/10000], loss: 0.25354 acc: 0.90667 val_loss: 0.23775, val_acc: 0.96000\n",
      "Epoch [5950/10000], loss: 0.25340 acc: 0.90667 val_loss: 0.23760, val_acc: 0.96000\n",
      "Epoch [5960/10000], loss: 0.25325 acc: 0.90667 val_loss: 0.23745, val_acc: 0.96000\n",
      "Epoch [5970/10000], loss: 0.25311 acc: 0.90667 val_loss: 0.23731, val_acc: 0.96000\n",
      "Epoch [5980/10000], loss: 0.25297 acc: 0.90667 val_loss: 0.23716, val_acc: 0.96000\n",
      "Epoch [5990/10000], loss: 0.25283 acc: 0.90667 val_loss: 0.23701, val_acc: 0.96000\n",
      "Epoch [6000/10000], loss: 0.25269 acc: 0.90667 val_loss: 0.23687, val_acc: 0.96000\n",
      "Epoch [6010/10000], loss: 0.25255 acc: 0.90667 val_loss: 0.23672, val_acc: 0.96000\n",
      "Epoch [6020/10000], loss: 0.25241 acc: 0.90667 val_loss: 0.23658, val_acc: 0.96000\n",
      "Epoch [6030/10000], loss: 0.25227 acc: 0.90667 val_loss: 0.23643, val_acc: 0.96000\n",
      "Epoch [6040/10000], loss: 0.25213 acc: 0.90667 val_loss: 0.23629, val_acc: 0.96000\n",
      "Epoch [6050/10000], loss: 0.25199 acc: 0.90667 val_loss: 0.23614, val_acc: 0.96000\n",
      "Epoch [6060/10000], loss: 0.25186 acc: 0.90667 val_loss: 0.23600, val_acc: 0.96000\n",
      "Epoch [6070/10000], loss: 0.25172 acc: 0.90667 val_loss: 0.23586, val_acc: 0.96000\n",
      "Epoch [6080/10000], loss: 0.25158 acc: 0.90667 val_loss: 0.23571, val_acc: 0.96000\n",
      "Epoch [6090/10000], loss: 0.25144 acc: 0.90667 val_loss: 0.23557, val_acc: 0.96000\n",
      "Epoch [6100/10000], loss: 0.25131 acc: 0.90667 val_loss: 0.23543, val_acc: 0.96000\n",
      "Epoch [6110/10000], loss: 0.25117 acc: 0.90667 val_loss: 0.23529, val_acc: 0.96000\n",
      "Epoch [6120/10000], loss: 0.25104 acc: 0.90667 val_loss: 0.23514, val_acc: 0.96000\n",
      "Epoch [6130/10000], loss: 0.25090 acc: 0.90667 val_loss: 0.23500, val_acc: 0.96000\n",
      "Epoch [6140/10000], loss: 0.25076 acc: 0.90667 val_loss: 0.23486, val_acc: 0.96000\n",
      "Epoch [6150/10000], loss: 0.25063 acc: 0.90667 val_loss: 0.23472, val_acc: 0.96000\n",
      "Epoch [6160/10000], loss: 0.25049 acc: 0.90667 val_loss: 0.23458, val_acc: 0.96000\n",
      "Epoch [6170/10000], loss: 0.25036 acc: 0.90667 val_loss: 0.23444, val_acc: 0.96000\n",
      "Epoch [6180/10000], loss: 0.25023 acc: 0.90667 val_loss: 0.23430, val_acc: 0.96000\n",
      "Epoch [6190/10000], loss: 0.25009 acc: 0.90667 val_loss: 0.23416, val_acc: 0.96000\n",
      "Epoch [6200/10000], loss: 0.24996 acc: 0.90667 val_loss: 0.23402, val_acc: 0.96000\n",
      "Epoch [6210/10000], loss: 0.24983 acc: 0.90667 val_loss: 0.23388, val_acc: 0.96000\n",
      "Epoch [6220/10000], loss: 0.24969 acc: 0.90667 val_loss: 0.23375, val_acc: 0.96000\n",
      "Epoch [6230/10000], loss: 0.24956 acc: 0.90667 val_loss: 0.23361, val_acc: 0.96000\n",
      "Epoch [6240/10000], loss: 0.24943 acc: 0.90667 val_loss: 0.23347, val_acc: 0.96000\n",
      "Epoch [6250/10000], loss: 0.24930 acc: 0.90667 val_loss: 0.23333, val_acc: 0.96000\n",
      "Epoch [6260/10000], loss: 0.24917 acc: 0.90667 val_loss: 0.23320, val_acc: 0.96000\n",
      "Epoch [6270/10000], loss: 0.24904 acc: 0.90667 val_loss: 0.23306, val_acc: 0.96000\n",
      "Epoch [6280/10000], loss: 0.24891 acc: 0.90667 val_loss: 0.23292, val_acc: 0.96000\n",
      "Epoch [6290/10000], loss: 0.24878 acc: 0.90667 val_loss: 0.23279, val_acc: 0.96000\n",
      "Epoch [6300/10000], loss: 0.24865 acc: 0.90667 val_loss: 0.23265, val_acc: 0.96000\n",
      "Epoch [6310/10000], loss: 0.24852 acc: 0.90667 val_loss: 0.23252, val_acc: 0.96000\n",
      "Epoch [6320/10000], loss: 0.24839 acc: 0.90667 val_loss: 0.23238, val_acc: 0.96000\n",
      "Epoch [6330/10000], loss: 0.24826 acc: 0.90667 val_loss: 0.23225, val_acc: 0.96000\n",
      "Epoch [6340/10000], loss: 0.24813 acc: 0.90667 val_loss: 0.23211, val_acc: 0.96000\n",
      "Epoch [6350/10000], loss: 0.24800 acc: 0.90667 val_loss: 0.23198, val_acc: 0.96000\n",
      "Epoch [6360/10000], loss: 0.24787 acc: 0.90667 val_loss: 0.23184, val_acc: 0.96000\n",
      "Epoch [6370/10000], loss: 0.24775 acc: 0.90667 val_loss: 0.23171, val_acc: 0.96000\n",
      "Epoch [6380/10000], loss: 0.24762 acc: 0.90667 val_loss: 0.23158, val_acc: 0.96000\n",
      "Epoch [6390/10000], loss: 0.24749 acc: 0.90667 val_loss: 0.23145, val_acc: 0.96000\n",
      "Epoch [6400/10000], loss: 0.24736 acc: 0.90667 val_loss: 0.23131, val_acc: 0.96000\n",
      "Epoch [6410/10000], loss: 0.24724 acc: 0.90667 val_loss: 0.23118, val_acc: 0.96000\n",
      "Epoch [6420/10000], loss: 0.24711 acc: 0.90667 val_loss: 0.23105, val_acc: 0.96000\n",
      "Epoch [6430/10000], loss: 0.24699 acc: 0.90667 val_loss: 0.23092, val_acc: 0.96000\n",
      "Epoch [6440/10000], loss: 0.24686 acc: 0.90667 val_loss: 0.23079, val_acc: 0.96000\n",
      "Epoch [6450/10000], loss: 0.24674 acc: 0.90667 val_loss: 0.23066, val_acc: 0.96000\n",
      "Epoch [6460/10000], loss: 0.24661 acc: 0.90667 val_loss: 0.23053, val_acc: 0.96000\n",
      "Epoch [6470/10000], loss: 0.24649 acc: 0.90667 val_loss: 0.23040, val_acc: 0.96000\n",
      "Epoch [6480/10000], loss: 0.24636 acc: 0.90667 val_loss: 0.23027, val_acc: 0.96000\n",
      "Epoch [6490/10000], loss: 0.24624 acc: 0.90667 val_loss: 0.23014, val_acc: 0.96000\n",
      "Epoch [6500/10000], loss: 0.24611 acc: 0.90667 val_loss: 0.23001, val_acc: 0.96000\n",
      "Epoch [6510/10000], loss: 0.24599 acc: 0.90667 val_loss: 0.22988, val_acc: 0.96000\n",
      "Epoch [6520/10000], loss: 0.24587 acc: 0.90667 val_loss: 0.22975, val_acc: 0.96000\n",
      "Epoch [6530/10000], loss: 0.24575 acc: 0.90667 val_loss: 0.22962, val_acc: 0.96000\n",
      "Epoch [6540/10000], loss: 0.24562 acc: 0.90667 val_loss: 0.22949, val_acc: 0.96000\n",
      "Epoch [6550/10000], loss: 0.24550 acc: 0.90667 val_loss: 0.22936, val_acc: 0.96000\n",
      "Epoch [6560/10000], loss: 0.24538 acc: 0.90667 val_loss: 0.22924, val_acc: 0.96000\n",
      "Epoch [6570/10000], loss: 0.24526 acc: 0.90667 val_loss: 0.22911, val_acc: 0.96000\n",
      "Epoch [6580/10000], loss: 0.24514 acc: 0.90667 val_loss: 0.22898, val_acc: 0.96000\n",
      "Epoch [6590/10000], loss: 0.24502 acc: 0.90667 val_loss: 0.22886, val_acc: 0.96000\n",
      "Epoch [6600/10000], loss: 0.24489 acc: 0.90667 val_loss: 0.22873, val_acc: 0.96000\n",
      "Epoch [6610/10000], loss: 0.24477 acc: 0.90667 val_loss: 0.22860, val_acc: 0.96000\n",
      "Epoch [6620/10000], loss: 0.24465 acc: 0.90667 val_loss: 0.22848, val_acc: 0.96000\n",
      "Epoch [6630/10000], loss: 0.24453 acc: 0.90667 val_loss: 0.22835, val_acc: 0.96000\n",
      "Epoch [6640/10000], loss: 0.24441 acc: 0.90667 val_loss: 0.22823, val_acc: 0.96000\n",
      "Epoch [6650/10000], loss: 0.24430 acc: 0.90667 val_loss: 0.22810, val_acc: 0.96000\n",
      "Epoch [6660/10000], loss: 0.24418 acc: 0.90667 val_loss: 0.22798, val_acc: 0.96000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6670/10000], loss: 0.24406 acc: 0.90667 val_loss: 0.22785, val_acc: 0.96000\n",
      "Epoch [6680/10000], loss: 0.24394 acc: 0.90667 val_loss: 0.22773, val_acc: 0.96000\n",
      "Epoch [6690/10000], loss: 0.24382 acc: 0.90667 val_loss: 0.22761, val_acc: 0.96000\n",
      "Epoch [6700/10000], loss: 0.24370 acc: 0.90667 val_loss: 0.22748, val_acc: 0.96000\n",
      "Epoch [6710/10000], loss: 0.24359 acc: 0.90667 val_loss: 0.22736, val_acc: 0.96000\n",
      "Epoch [6720/10000], loss: 0.24347 acc: 0.90667 val_loss: 0.22724, val_acc: 0.96000\n",
      "Epoch [6730/10000], loss: 0.24335 acc: 0.90667 val_loss: 0.22711, val_acc: 0.96000\n",
      "Epoch [6740/10000], loss: 0.24324 acc: 0.90667 val_loss: 0.22699, val_acc: 0.96000\n",
      "Epoch [6750/10000], loss: 0.24312 acc: 0.90667 val_loss: 0.22687, val_acc: 0.96000\n",
      "Epoch [6760/10000], loss: 0.24300 acc: 0.90667 val_loss: 0.22675, val_acc: 0.96000\n",
      "Epoch [6770/10000], loss: 0.24289 acc: 0.90667 val_loss: 0.22663, val_acc: 0.96000\n",
      "Epoch [6780/10000], loss: 0.24277 acc: 0.90667 val_loss: 0.22651, val_acc: 0.96000\n",
      "Epoch [6790/10000], loss: 0.24266 acc: 0.90667 val_loss: 0.22638, val_acc: 0.96000\n",
      "Epoch [6800/10000], loss: 0.24254 acc: 0.90667 val_loss: 0.22626, val_acc: 0.96000\n",
      "Epoch [6810/10000], loss: 0.24243 acc: 0.90667 val_loss: 0.22614, val_acc: 0.96000\n",
      "Epoch [6820/10000], loss: 0.24231 acc: 0.90667 val_loss: 0.22602, val_acc: 0.96000\n",
      "Epoch [6830/10000], loss: 0.24220 acc: 0.90667 val_loss: 0.22590, val_acc: 0.96000\n",
      "Epoch [6840/10000], loss: 0.24208 acc: 0.90667 val_loss: 0.22578, val_acc: 0.96000\n",
      "Epoch [6850/10000], loss: 0.24197 acc: 0.90667 val_loss: 0.22566, val_acc: 0.96000\n",
      "Epoch [6860/10000], loss: 0.24186 acc: 0.90667 val_loss: 0.22555, val_acc: 0.96000\n",
      "Epoch [6870/10000], loss: 0.24174 acc: 0.90667 val_loss: 0.22543, val_acc: 0.96000\n",
      "Epoch [6880/10000], loss: 0.24163 acc: 0.90667 val_loss: 0.22531, val_acc: 0.96000\n",
      "Epoch [6890/10000], loss: 0.24152 acc: 0.90667 val_loss: 0.22519, val_acc: 0.96000\n",
      "Epoch [6900/10000], loss: 0.24141 acc: 0.90667 val_loss: 0.22507, val_acc: 0.96000\n",
      "Epoch [6910/10000], loss: 0.24129 acc: 0.90667 val_loss: 0.22495, val_acc: 0.96000\n",
      "Epoch [6920/10000], loss: 0.24118 acc: 0.90667 val_loss: 0.22484, val_acc: 0.96000\n",
      "Epoch [6930/10000], loss: 0.24107 acc: 0.90667 val_loss: 0.22472, val_acc: 0.96000\n",
      "Epoch [6940/10000], loss: 0.24096 acc: 0.90667 val_loss: 0.22460, val_acc: 0.96000\n",
      "Epoch [6950/10000], loss: 0.24085 acc: 0.90667 val_loss: 0.22449, val_acc: 0.96000\n",
      "Epoch [6960/10000], loss: 0.24074 acc: 0.90667 val_loss: 0.22437, val_acc: 0.96000\n",
      "Epoch [6970/10000], loss: 0.24063 acc: 0.90667 val_loss: 0.22425, val_acc: 0.96000\n",
      "Epoch [6980/10000], loss: 0.24052 acc: 0.90667 val_loss: 0.22414, val_acc: 0.96000\n",
      "Epoch [6990/10000], loss: 0.24041 acc: 0.90667 val_loss: 0.22402, val_acc: 0.96000\n",
      "Epoch [7000/10000], loss: 0.24030 acc: 0.90667 val_loss: 0.22391, val_acc: 0.96000\n",
      "Epoch [7010/10000], loss: 0.24019 acc: 0.90667 val_loss: 0.22379, val_acc: 0.96000\n",
      "Epoch [7020/10000], loss: 0.24008 acc: 0.90667 val_loss: 0.22368, val_acc: 0.96000\n",
      "Epoch [7030/10000], loss: 0.23997 acc: 0.90667 val_loss: 0.22356, val_acc: 0.96000\n",
      "Epoch [7040/10000], loss: 0.23986 acc: 0.90667 val_loss: 0.22345, val_acc: 0.96000\n",
      "Epoch [7050/10000], loss: 0.23975 acc: 0.90667 val_loss: 0.22333, val_acc: 0.96000\n",
      "Epoch [7060/10000], loss: 0.23964 acc: 0.90667 val_loss: 0.22322, val_acc: 0.96000\n",
      "Epoch [7070/10000], loss: 0.23953 acc: 0.90667 val_loss: 0.22311, val_acc: 0.96000\n",
      "Epoch [7080/10000], loss: 0.23943 acc: 0.90667 val_loss: 0.22299, val_acc: 0.96000\n",
      "Epoch [7090/10000], loss: 0.23932 acc: 0.90667 val_loss: 0.22288, val_acc: 0.96000\n",
      "Epoch [7100/10000], loss: 0.23921 acc: 0.90667 val_loss: 0.22277, val_acc: 0.96000\n",
      "Epoch [7110/10000], loss: 0.23910 acc: 0.90667 val_loss: 0.22265, val_acc: 0.96000\n",
      "Epoch [7120/10000], loss: 0.23900 acc: 0.90667 val_loss: 0.22254, val_acc: 0.96000\n",
      "Epoch [7130/10000], loss: 0.23889 acc: 0.90667 val_loss: 0.22243, val_acc: 0.96000\n",
      "Epoch [7140/10000], loss: 0.23879 acc: 0.90667 val_loss: 0.22232, val_acc: 0.96000\n",
      "Epoch [7150/10000], loss: 0.23868 acc: 0.90667 val_loss: 0.22221, val_acc: 0.96000\n",
      "Epoch [7160/10000], loss: 0.23857 acc: 0.90667 val_loss: 0.22209, val_acc: 0.96000\n",
      "Epoch [7170/10000], loss: 0.23847 acc: 0.90667 val_loss: 0.22198, val_acc: 0.96000\n",
      "Epoch [7180/10000], loss: 0.23836 acc: 0.90667 val_loss: 0.22187, val_acc: 0.96000\n",
      "Epoch [7190/10000], loss: 0.23826 acc: 0.90667 val_loss: 0.22176, val_acc: 0.96000\n",
      "Epoch [7200/10000], loss: 0.23815 acc: 0.90667 val_loss: 0.22165, val_acc: 0.96000\n",
      "Epoch [7210/10000], loss: 0.23805 acc: 0.90667 val_loss: 0.22154, val_acc: 0.96000\n",
      "Epoch [7220/10000], loss: 0.23794 acc: 0.90667 val_loss: 0.22143, val_acc: 0.96000\n",
      "Epoch [7230/10000], loss: 0.23784 acc: 0.90667 val_loss: 0.22132, val_acc: 0.96000\n",
      "Epoch [7240/10000], loss: 0.23773 acc: 0.90667 val_loss: 0.22121, val_acc: 0.96000\n",
      "Epoch [7250/10000], loss: 0.23763 acc: 0.90667 val_loss: 0.22110, val_acc: 0.96000\n",
      "Epoch [7260/10000], loss: 0.23753 acc: 0.90667 val_loss: 0.22099, val_acc: 0.96000\n",
      "Epoch [7270/10000], loss: 0.23742 acc: 0.90667 val_loss: 0.22088, val_acc: 0.96000\n",
      "Epoch [7280/10000], loss: 0.23732 acc: 0.90667 val_loss: 0.22078, val_acc: 0.96000\n",
      "Epoch [7290/10000], loss: 0.23722 acc: 0.90667 val_loss: 0.22067, val_acc: 0.96000\n",
      "Epoch [7300/10000], loss: 0.23712 acc: 0.90667 val_loss: 0.22056, val_acc: 0.96000\n",
      "Epoch [7310/10000], loss: 0.23701 acc: 0.90667 val_loss: 0.22045, val_acc: 0.96000\n",
      "Epoch [7320/10000], loss: 0.23691 acc: 0.90667 val_loss: 0.22034, val_acc: 0.96000\n",
      "Epoch [7330/10000], loss: 0.23681 acc: 0.90667 val_loss: 0.22024, val_acc: 0.96000\n",
      "Epoch [7340/10000], loss: 0.23671 acc: 0.90667 val_loss: 0.22013, val_acc: 0.96000\n",
      "Epoch [7350/10000], loss: 0.23661 acc: 0.90667 val_loss: 0.22002, val_acc: 0.96000\n",
      "Epoch [7360/10000], loss: 0.23651 acc: 0.90667 val_loss: 0.21992, val_acc: 0.96000\n",
      "Epoch [7370/10000], loss: 0.23640 acc: 0.90667 val_loss: 0.21981, val_acc: 0.96000\n",
      "Epoch [7380/10000], loss: 0.23630 acc: 0.90667 val_loss: 0.21970, val_acc: 0.96000\n",
      "Epoch [7390/10000], loss: 0.23620 acc: 0.90667 val_loss: 0.21960, val_acc: 0.96000\n",
      "Epoch [7400/10000], loss: 0.23610 acc: 0.90667 val_loss: 0.21949, val_acc: 0.96000\n",
      "Epoch [7410/10000], loss: 0.23600 acc: 0.90667 val_loss: 0.21939, val_acc: 0.96000\n",
      "Epoch [7420/10000], loss: 0.23590 acc: 0.90667 val_loss: 0.21928, val_acc: 0.96000\n",
      "Epoch [7430/10000], loss: 0.23580 acc: 0.90667 val_loss: 0.21918, val_acc: 0.96000\n",
      "Epoch [7440/10000], loss: 0.23570 acc: 0.90667 val_loss: 0.21907, val_acc: 0.96000\n",
      "Epoch [7450/10000], loss: 0.23560 acc: 0.90667 val_loss: 0.21897, val_acc: 0.96000\n",
      "Epoch [7460/10000], loss: 0.23551 acc: 0.90667 val_loss: 0.21886, val_acc: 0.96000\n",
      "Epoch [7470/10000], loss: 0.23541 acc: 0.90667 val_loss: 0.21876, val_acc: 0.96000\n",
      "Epoch [7480/10000], loss: 0.23531 acc: 0.90667 val_loss: 0.21865, val_acc: 0.96000\n",
      "Epoch [7490/10000], loss: 0.23521 acc: 0.90667 val_loss: 0.21855, val_acc: 0.96000\n",
      "Epoch [7500/10000], loss: 0.23511 acc: 0.90667 val_loss: 0.21845, val_acc: 0.96000\n",
      "Epoch [7510/10000], loss: 0.23501 acc: 0.90667 val_loss: 0.21834, val_acc: 0.96000\n",
      "Epoch [7520/10000], loss: 0.23492 acc: 0.90667 val_loss: 0.21824, val_acc: 0.96000\n",
      "Epoch [7530/10000], loss: 0.23482 acc: 0.90667 val_loss: 0.21814, val_acc: 0.96000\n",
      "Epoch [7540/10000], loss: 0.23472 acc: 0.90667 val_loss: 0.21803, val_acc: 0.96000\n",
      "Epoch [7550/10000], loss: 0.23462 acc: 0.90667 val_loss: 0.21793, val_acc: 0.96000\n",
      "Epoch [7560/10000], loss: 0.23453 acc: 0.90667 val_loss: 0.21783, val_acc: 0.96000\n",
      "Epoch [7570/10000], loss: 0.23443 acc: 0.90667 val_loss: 0.21773, val_acc: 0.96000\n",
      "Epoch [7580/10000], loss: 0.23433 acc: 0.90667 val_loss: 0.21762, val_acc: 0.96000\n",
      "Epoch [7590/10000], loss: 0.23424 acc: 0.90667 val_loss: 0.21752, val_acc: 0.96000\n",
      "Epoch [7600/10000], loss: 0.23414 acc: 0.90667 val_loss: 0.21742, val_acc: 0.96000\n",
      "Epoch [7610/10000], loss: 0.23405 acc: 0.90667 val_loss: 0.21732, val_acc: 0.96000\n",
      "Epoch [7620/10000], loss: 0.23395 acc: 0.90667 val_loss: 0.21722, val_acc: 0.96000\n",
      "Epoch [7630/10000], loss: 0.23385 acc: 0.90667 val_loss: 0.21712, val_acc: 0.96000\n",
      "Epoch [7640/10000], loss: 0.23376 acc: 0.90667 val_loss: 0.21702, val_acc: 0.96000\n",
      "Epoch [7650/10000], loss: 0.23366 acc: 0.90667 val_loss: 0.21692, val_acc: 0.96000\n",
      "Epoch [7660/10000], loss: 0.23357 acc: 0.90667 val_loss: 0.21682, val_acc: 0.96000\n",
      "Epoch [7670/10000], loss: 0.23348 acc: 0.90667 val_loss: 0.21672, val_acc: 0.96000\n",
      "Epoch [7680/10000], loss: 0.23338 acc: 0.90667 val_loss: 0.21662, val_acc: 0.96000\n",
      "Epoch [7690/10000], loss: 0.23329 acc: 0.90667 val_loss: 0.21652, val_acc: 0.96000\n",
      "Epoch [7700/10000], loss: 0.23319 acc: 0.90667 val_loss: 0.21642, val_acc: 0.96000\n",
      "Epoch [7710/10000], loss: 0.23310 acc: 0.90667 val_loss: 0.21632, val_acc: 0.96000\n",
      "Epoch [7720/10000], loss: 0.23301 acc: 0.90667 val_loss: 0.21622, val_acc: 0.96000\n",
      "Epoch [7730/10000], loss: 0.23291 acc: 0.90667 val_loss: 0.21612, val_acc: 0.96000\n",
      "Epoch [7740/10000], loss: 0.23282 acc: 0.90667 val_loss: 0.21602, val_acc: 0.96000\n",
      "Epoch [7750/10000], loss: 0.23273 acc: 0.90667 val_loss: 0.21592, val_acc: 0.96000\n",
      "Epoch [7760/10000], loss: 0.23263 acc: 0.90667 val_loss: 0.21582, val_acc: 0.96000\n",
      "Epoch [7770/10000], loss: 0.23254 acc: 0.90667 val_loss: 0.21573, val_acc: 0.96000\n",
      "Epoch [7780/10000], loss: 0.23245 acc: 0.90667 val_loss: 0.21563, val_acc: 0.96000\n",
      "Epoch [7790/10000], loss: 0.23236 acc: 0.90667 val_loss: 0.21553, val_acc: 0.96000\n",
      "Epoch [7800/10000], loss: 0.23226 acc: 0.90667 val_loss: 0.21543, val_acc: 0.96000\n",
      "Epoch [7810/10000], loss: 0.23217 acc: 0.90667 val_loss: 0.21534, val_acc: 0.96000\n",
      "Epoch [7820/10000], loss: 0.23208 acc: 0.90667 val_loss: 0.21524, val_acc: 0.96000\n",
      "Epoch [7830/10000], loss: 0.23199 acc: 0.90667 val_loss: 0.21514, val_acc: 0.96000\n",
      "Epoch [7840/10000], loss: 0.23190 acc: 0.90667 val_loss: 0.21505, val_acc: 0.96000\n",
      "Epoch [7850/10000], loss: 0.23181 acc: 0.90667 val_loss: 0.21495, val_acc: 0.96000\n",
      "Epoch [7860/10000], loss: 0.23172 acc: 0.90667 val_loss: 0.21485, val_acc: 0.96000\n",
      "Epoch [7870/10000], loss: 0.23162 acc: 0.90667 val_loss: 0.21476, val_acc: 0.96000\n",
      "Epoch [7880/10000], loss: 0.23153 acc: 0.90667 val_loss: 0.21466, val_acc: 0.96000\n",
      "Epoch [7890/10000], loss: 0.23144 acc: 0.90667 val_loss: 0.21457, val_acc: 0.96000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7900/10000], loss: 0.23135 acc: 0.90667 val_loss: 0.21447, val_acc: 0.96000\n",
      "Epoch [7910/10000], loss: 0.23126 acc: 0.90667 val_loss: 0.21437, val_acc: 0.96000\n",
      "Epoch [7920/10000], loss: 0.23117 acc: 0.90667 val_loss: 0.21428, val_acc: 0.96000\n",
      "Epoch [7930/10000], loss: 0.23108 acc: 0.90667 val_loss: 0.21418, val_acc: 0.96000\n",
      "Epoch [7940/10000], loss: 0.23099 acc: 0.90667 val_loss: 0.21409, val_acc: 0.96000\n",
      "Epoch [7950/10000], loss: 0.23091 acc: 0.90667 val_loss: 0.21400, val_acc: 0.96000\n",
      "Epoch [7960/10000], loss: 0.23082 acc: 0.90667 val_loss: 0.21390, val_acc: 0.96000\n",
      "Epoch [7970/10000], loss: 0.23073 acc: 0.90667 val_loss: 0.21381, val_acc: 0.96000\n",
      "Epoch [7980/10000], loss: 0.23064 acc: 0.90667 val_loss: 0.21371, val_acc: 0.96000\n",
      "Epoch [7990/10000], loss: 0.23055 acc: 0.90667 val_loss: 0.21362, val_acc: 0.96000\n",
      "Epoch [8000/10000], loss: 0.23046 acc: 0.90667 val_loss: 0.21353, val_acc: 0.96000\n",
      "Epoch [8010/10000], loss: 0.23037 acc: 0.90667 val_loss: 0.21343, val_acc: 0.96000\n",
      "Epoch [8020/10000], loss: 0.23029 acc: 0.90667 val_loss: 0.21334, val_acc: 0.96000\n",
      "Epoch [8030/10000], loss: 0.23020 acc: 0.90667 val_loss: 0.21325, val_acc: 0.96000\n",
      "Epoch [8040/10000], loss: 0.23011 acc: 0.90667 val_loss: 0.21315, val_acc: 0.96000\n",
      "Epoch [8050/10000], loss: 0.23002 acc: 0.90667 val_loss: 0.21306, val_acc: 0.96000\n",
      "Epoch [8060/10000], loss: 0.22994 acc: 0.90667 val_loss: 0.21297, val_acc: 0.96000\n",
      "Epoch [8070/10000], loss: 0.22985 acc: 0.90667 val_loss: 0.21288, val_acc: 0.96000\n",
      "Epoch [8080/10000], loss: 0.22976 acc: 0.90667 val_loss: 0.21278, val_acc: 0.96000\n",
      "Epoch [8090/10000], loss: 0.22968 acc: 0.90667 val_loss: 0.21269, val_acc: 0.96000\n",
      "Epoch [8100/10000], loss: 0.22959 acc: 0.90667 val_loss: 0.21260, val_acc: 0.96000\n",
      "Epoch [8110/10000], loss: 0.22950 acc: 0.90667 val_loss: 0.21251, val_acc: 0.96000\n",
      "Epoch [8120/10000], loss: 0.22942 acc: 0.90667 val_loss: 0.21242, val_acc: 0.96000\n",
      "Epoch [8130/10000], loss: 0.22933 acc: 0.90667 val_loss: 0.21233, val_acc: 0.96000\n",
      "Epoch [8140/10000], loss: 0.22925 acc: 0.90667 val_loss: 0.21223, val_acc: 0.96000\n",
      "Epoch [8150/10000], loss: 0.22916 acc: 0.90667 val_loss: 0.21214, val_acc: 0.96000\n",
      "Epoch [8160/10000], loss: 0.22907 acc: 0.90667 val_loss: 0.21205, val_acc: 0.96000\n",
      "Epoch [8170/10000], loss: 0.22899 acc: 0.90667 val_loss: 0.21196, val_acc: 0.96000\n",
      "Epoch [8180/10000], loss: 0.22890 acc: 0.90667 val_loss: 0.21187, val_acc: 0.96000\n",
      "Epoch [8190/10000], loss: 0.22882 acc: 0.90667 val_loss: 0.21178, val_acc: 0.96000\n",
      "Epoch [8200/10000], loss: 0.22873 acc: 0.90667 val_loss: 0.21169, val_acc: 0.96000\n",
      "Epoch [8210/10000], loss: 0.22865 acc: 0.90667 val_loss: 0.21160, val_acc: 0.96000\n",
      "Epoch [8220/10000], loss: 0.22857 acc: 0.90667 val_loss: 0.21151, val_acc: 0.96000\n",
      "Epoch [8230/10000], loss: 0.22848 acc: 0.90667 val_loss: 0.21142, val_acc: 0.96000\n",
      "Epoch [8240/10000], loss: 0.22840 acc: 0.90667 val_loss: 0.21133, val_acc: 0.96000\n",
      "Epoch [8250/10000], loss: 0.22831 acc: 0.90667 val_loss: 0.21124, val_acc: 0.96000\n",
      "Epoch [8260/10000], loss: 0.22823 acc: 0.90667 val_loss: 0.21115, val_acc: 0.96000\n",
      "Epoch [8270/10000], loss: 0.22815 acc: 0.90667 val_loss: 0.21107, val_acc: 0.96000\n",
      "Epoch [8280/10000], loss: 0.22806 acc: 0.90667 val_loss: 0.21098, val_acc: 0.96000\n",
      "Epoch [8290/10000], loss: 0.22798 acc: 0.90667 val_loss: 0.21089, val_acc: 0.96000\n",
      "Epoch [8300/10000], loss: 0.22790 acc: 0.90667 val_loss: 0.21080, val_acc: 0.96000\n",
      "Epoch [8310/10000], loss: 0.22781 acc: 0.90667 val_loss: 0.21071, val_acc: 0.96000\n",
      "Epoch [8320/10000], loss: 0.22773 acc: 0.90667 val_loss: 0.21062, val_acc: 0.96000\n",
      "Epoch [8330/10000], loss: 0.22765 acc: 0.90667 val_loss: 0.21054, val_acc: 0.96000\n",
      "Epoch [8340/10000], loss: 0.22757 acc: 0.90667 val_loss: 0.21045, val_acc: 0.96000\n",
      "Epoch [8350/10000], loss: 0.22748 acc: 0.90667 val_loss: 0.21036, val_acc: 0.96000\n",
      "Epoch [8360/10000], loss: 0.22740 acc: 0.90667 val_loss: 0.21027, val_acc: 0.96000\n",
      "Epoch [8370/10000], loss: 0.22732 acc: 0.90667 val_loss: 0.21019, val_acc: 0.96000\n",
      "Epoch [8380/10000], loss: 0.22724 acc: 0.90667 val_loss: 0.21010, val_acc: 0.96000\n",
      "Epoch [8390/10000], loss: 0.22716 acc: 0.90667 val_loss: 0.21001, val_acc: 0.96000\n",
      "Epoch [8400/10000], loss: 0.22707 acc: 0.90667 val_loss: 0.20993, val_acc: 0.96000\n",
      "Epoch [8410/10000], loss: 0.22699 acc: 0.90667 val_loss: 0.20984, val_acc: 0.96000\n",
      "Epoch [8420/10000], loss: 0.22691 acc: 0.90667 val_loss: 0.20975, val_acc: 0.96000\n",
      "Epoch [8430/10000], loss: 0.22683 acc: 0.90667 val_loss: 0.20967, val_acc: 0.96000\n",
      "Epoch [8440/10000], loss: 0.22675 acc: 0.90667 val_loss: 0.20958, val_acc: 0.96000\n",
      "Epoch [8450/10000], loss: 0.22667 acc: 0.90667 val_loss: 0.20950, val_acc: 0.96000\n",
      "Epoch [8460/10000], loss: 0.22659 acc: 0.90667 val_loss: 0.20941, val_acc: 0.96000\n",
      "Epoch [8470/10000], loss: 0.22651 acc: 0.90667 val_loss: 0.20932, val_acc: 0.96000\n",
      "Epoch [8480/10000], loss: 0.22643 acc: 0.90667 val_loss: 0.20924, val_acc: 0.96000\n",
      "Epoch [8490/10000], loss: 0.22635 acc: 0.90667 val_loss: 0.20915, val_acc: 0.96000\n",
      "Epoch [8500/10000], loss: 0.22627 acc: 0.90667 val_loss: 0.20907, val_acc: 0.96000\n",
      "Epoch [8510/10000], loss: 0.22619 acc: 0.90667 val_loss: 0.20898, val_acc: 0.96000\n",
      "Epoch [8520/10000], loss: 0.22611 acc: 0.90667 val_loss: 0.20890, val_acc: 0.96000\n",
      "Epoch [8530/10000], loss: 0.22603 acc: 0.90667 val_loss: 0.20881, val_acc: 0.96000\n",
      "Epoch [8540/10000], loss: 0.22595 acc: 0.90667 val_loss: 0.20873, val_acc: 0.96000\n",
      "Epoch [8550/10000], loss: 0.22587 acc: 0.90667 val_loss: 0.20865, val_acc: 0.96000\n",
      "Epoch [8560/10000], loss: 0.22579 acc: 0.90667 val_loss: 0.20856, val_acc: 0.96000\n",
      "Epoch [8570/10000], loss: 0.22572 acc: 0.90667 val_loss: 0.20848, val_acc: 0.96000\n",
      "Epoch [8580/10000], loss: 0.22564 acc: 0.90667 val_loss: 0.20839, val_acc: 0.96000\n",
      "Epoch [8590/10000], loss: 0.22556 acc: 0.90667 val_loss: 0.20831, val_acc: 0.96000\n",
      "Epoch [8600/10000], loss: 0.22548 acc: 0.90667 val_loss: 0.20823, val_acc: 0.96000\n",
      "Epoch [8610/10000], loss: 0.22540 acc: 0.90667 val_loss: 0.20814, val_acc: 0.96000\n",
      "Epoch [8620/10000], loss: 0.22532 acc: 0.90667 val_loss: 0.20806, val_acc: 0.96000\n",
      "Epoch [8630/10000], loss: 0.22525 acc: 0.90667 val_loss: 0.20798, val_acc: 0.96000\n",
      "Epoch [8640/10000], loss: 0.22517 acc: 0.90667 val_loss: 0.20789, val_acc: 0.96000\n",
      "Epoch [8650/10000], loss: 0.22509 acc: 0.90667 val_loss: 0.20781, val_acc: 0.96000\n",
      "Epoch [8660/10000], loss: 0.22501 acc: 0.90667 val_loss: 0.20773, val_acc: 0.96000\n",
      "Epoch [8670/10000], loss: 0.22494 acc: 0.90667 val_loss: 0.20765, val_acc: 0.96000\n",
      "Epoch [8680/10000], loss: 0.22486 acc: 0.90667 val_loss: 0.20756, val_acc: 0.96000\n",
      "Epoch [8690/10000], loss: 0.22478 acc: 0.90667 val_loss: 0.20748, val_acc: 0.96000\n",
      "Epoch [8700/10000], loss: 0.22471 acc: 0.90667 val_loss: 0.20740, val_acc: 0.96000\n",
      "Epoch [8710/10000], loss: 0.22463 acc: 0.90667 val_loss: 0.20732, val_acc: 0.96000\n",
      "Epoch [8720/10000], loss: 0.22455 acc: 0.90667 val_loss: 0.20724, val_acc: 0.96000\n",
      "Epoch [8730/10000], loss: 0.22448 acc: 0.90667 val_loss: 0.20716, val_acc: 0.96000\n",
      "Epoch [8740/10000], loss: 0.22440 acc: 0.90667 val_loss: 0.20707, val_acc: 0.96000\n",
      "Epoch [8750/10000], loss: 0.22432 acc: 0.90667 val_loss: 0.20699, val_acc: 0.96000\n",
      "Epoch [8760/10000], loss: 0.22425 acc: 0.90667 val_loss: 0.20691, val_acc: 0.96000\n",
      "Epoch [8770/10000], loss: 0.22417 acc: 0.90667 val_loss: 0.20683, val_acc: 0.96000\n",
      "Epoch [8780/10000], loss: 0.22410 acc: 0.90667 val_loss: 0.20675, val_acc: 0.96000\n",
      "Epoch [8790/10000], loss: 0.22402 acc: 0.90667 val_loss: 0.20667, val_acc: 0.96000\n",
      "Epoch [8800/10000], loss: 0.22395 acc: 0.90667 val_loss: 0.20659, val_acc: 0.96000\n",
      "Epoch [8810/10000], loss: 0.22387 acc: 0.90667 val_loss: 0.20651, val_acc: 0.96000\n",
      "Epoch [8820/10000], loss: 0.22380 acc: 0.90667 val_loss: 0.20643, val_acc: 0.96000\n",
      "Epoch [8830/10000], loss: 0.22372 acc: 0.90667 val_loss: 0.20635, val_acc: 0.96000\n",
      "Epoch [8840/10000], loss: 0.22365 acc: 0.90667 val_loss: 0.20627, val_acc: 0.96000\n",
      "Epoch [8850/10000], loss: 0.22357 acc: 0.90667 val_loss: 0.20619, val_acc: 0.96000\n",
      "Epoch [8860/10000], loss: 0.22350 acc: 0.90667 val_loss: 0.20611, val_acc: 0.96000\n",
      "Epoch [8870/10000], loss: 0.22342 acc: 0.90667 val_loss: 0.20603, val_acc: 0.96000\n",
      "Epoch [8880/10000], loss: 0.22335 acc: 0.90667 val_loss: 0.20595, val_acc: 0.96000\n",
      "Epoch [8890/10000], loss: 0.22327 acc: 0.90667 val_loss: 0.20587, val_acc: 0.96000\n",
      "Epoch [8900/10000], loss: 0.22320 acc: 0.90667 val_loss: 0.20579, val_acc: 0.96000\n",
      "Epoch [8910/10000], loss: 0.22313 acc: 0.90667 val_loss: 0.20571, val_acc: 0.96000\n",
      "Epoch [8920/10000], loss: 0.22305 acc: 0.90667 val_loss: 0.20563, val_acc: 0.96000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8930/10000], loss: 0.22298 acc: 0.90667 val_loss: 0.20556, val_acc: 0.96000\n",
      "Epoch [8940/10000], loss: 0.22291 acc: 0.90667 val_loss: 0.20548, val_acc: 0.96000\n",
      "Epoch [8950/10000], loss: 0.22283 acc: 0.90667 val_loss: 0.20540, val_acc: 0.96000\n",
      "Epoch [8960/10000], loss: 0.22276 acc: 0.90667 val_loss: 0.20532, val_acc: 0.96000\n",
      "Epoch [8970/10000], loss: 0.22269 acc: 0.90667 val_loss: 0.20524, val_acc: 0.96000\n",
      "Epoch [8980/10000], loss: 0.22261 acc: 0.90667 val_loss: 0.20517, val_acc: 0.96000\n",
      "Epoch [8990/10000], loss: 0.22254 acc: 0.90667 val_loss: 0.20509, val_acc: 0.96000\n",
      "Epoch [9000/10000], loss: 0.22247 acc: 0.90667 val_loss: 0.20501, val_acc: 0.96000\n",
      "Epoch [9010/10000], loss: 0.22240 acc: 0.90667 val_loss: 0.20493, val_acc: 0.96000\n",
      "Epoch [9020/10000], loss: 0.22232 acc: 0.90667 val_loss: 0.20485, val_acc: 0.96000\n",
      "Epoch [9030/10000], loss: 0.22225 acc: 0.90667 val_loss: 0.20478, val_acc: 0.96000\n",
      "Epoch [9040/10000], loss: 0.22218 acc: 0.90667 val_loss: 0.20470, val_acc: 0.96000\n",
      "Epoch [9050/10000], loss: 0.22211 acc: 0.90667 val_loss: 0.20462, val_acc: 0.96000\n",
      "Epoch [9060/10000], loss: 0.22204 acc: 0.90667 val_loss: 0.20455, val_acc: 0.96000\n",
      "Epoch [9070/10000], loss: 0.22196 acc: 0.90667 val_loss: 0.20447, val_acc: 0.96000\n",
      "Epoch [9080/10000], loss: 0.22189 acc: 0.90667 val_loss: 0.20439, val_acc: 0.96000\n",
      "Epoch [9090/10000], loss: 0.22182 acc: 0.90667 val_loss: 0.20432, val_acc: 0.96000\n",
      "Epoch [9100/10000], loss: 0.22175 acc: 0.90667 val_loss: 0.20424, val_acc: 0.96000\n",
      "Epoch [9110/10000], loss: 0.22168 acc: 0.90667 val_loss: 0.20416, val_acc: 0.96000\n",
      "Epoch [9120/10000], loss: 0.22161 acc: 0.90667 val_loss: 0.20409, val_acc: 0.96000\n",
      "Epoch [9130/10000], loss: 0.22154 acc: 0.90667 val_loss: 0.20401, val_acc: 0.96000\n",
      "Epoch [9140/10000], loss: 0.22147 acc: 0.90667 val_loss: 0.20394, val_acc: 0.96000\n",
      "Epoch [9150/10000], loss: 0.22140 acc: 0.90667 val_loss: 0.20386, val_acc: 0.96000\n",
      "Epoch [9160/10000], loss: 0.22133 acc: 0.90667 val_loss: 0.20379, val_acc: 0.96000\n",
      "Epoch [9170/10000], loss: 0.22126 acc: 0.90667 val_loss: 0.20371, val_acc: 0.96000\n",
      "Epoch [9180/10000], loss: 0.22118 acc: 0.90667 val_loss: 0.20364, val_acc: 0.96000\n",
      "Epoch [9190/10000], loss: 0.22111 acc: 0.90667 val_loss: 0.20356, val_acc: 0.96000\n",
      "Epoch [9200/10000], loss: 0.22105 acc: 0.90667 val_loss: 0.20349, val_acc: 0.96000\n",
      "Epoch [9210/10000], loss: 0.22098 acc: 0.90667 val_loss: 0.20341, val_acc: 0.96000\n",
      "Epoch [9220/10000], loss: 0.22091 acc: 0.90667 val_loss: 0.20334, val_acc: 0.96000\n",
      "Epoch [9230/10000], loss: 0.22084 acc: 0.90667 val_loss: 0.20326, val_acc: 0.96000\n",
      "Epoch [9240/10000], loss: 0.22077 acc: 0.90667 val_loss: 0.20319, val_acc: 0.96000\n",
      "Epoch [9250/10000], loss: 0.22070 acc: 0.90667 val_loss: 0.20311, val_acc: 0.96000\n",
      "Epoch [9260/10000], loss: 0.22063 acc: 0.90667 val_loss: 0.20304, val_acc: 0.96000\n",
      "Epoch [9270/10000], loss: 0.22056 acc: 0.90667 val_loss: 0.20296, val_acc: 0.96000\n",
      "Epoch [9280/10000], loss: 0.22049 acc: 0.90667 val_loss: 0.20289, val_acc: 0.96000\n",
      "Epoch [9290/10000], loss: 0.22042 acc: 0.90667 val_loss: 0.20282, val_acc: 0.96000\n",
      "Epoch [9300/10000], loss: 0.22035 acc: 0.90667 val_loss: 0.20274, val_acc: 0.96000\n",
      "Epoch [9310/10000], loss: 0.22028 acc: 0.90667 val_loss: 0.20267, val_acc: 0.96000\n",
      "Epoch [9320/10000], loss: 0.22022 acc: 0.90667 val_loss: 0.20260, val_acc: 0.96000\n",
      "Epoch [9330/10000], loss: 0.22015 acc: 0.90667 val_loss: 0.20252, val_acc: 0.96000\n",
      "Epoch [9340/10000], loss: 0.22008 acc: 0.90667 val_loss: 0.20245, val_acc: 0.96000\n",
      "Epoch [9350/10000], loss: 0.22001 acc: 0.90667 val_loss: 0.20238, val_acc: 0.96000\n",
      "Epoch [9360/10000], loss: 0.21994 acc: 0.90667 val_loss: 0.20230, val_acc: 0.96000\n",
      "Epoch [9370/10000], loss: 0.21988 acc: 0.90667 val_loss: 0.20223, val_acc: 0.96000\n",
      "Epoch [9380/10000], loss: 0.21981 acc: 0.90667 val_loss: 0.20216, val_acc: 0.96000\n",
      "Epoch [9390/10000], loss: 0.21974 acc: 0.90667 val_loss: 0.20209, val_acc: 0.96000\n",
      "Epoch [9400/10000], loss: 0.21967 acc: 0.90667 val_loss: 0.20201, val_acc: 0.96000\n",
      "Epoch [9410/10000], loss: 0.21961 acc: 0.90667 val_loss: 0.20194, val_acc: 0.96000\n",
      "Epoch [9420/10000], loss: 0.21954 acc: 0.90667 val_loss: 0.20187, val_acc: 0.96000\n",
      "Epoch [9430/10000], loss: 0.21947 acc: 0.90667 val_loss: 0.20180, val_acc: 0.96000\n",
      "Epoch [9440/10000], loss: 0.21940 acc: 0.90667 val_loss: 0.20173, val_acc: 0.96000\n",
      "Epoch [9450/10000], loss: 0.21934 acc: 0.90667 val_loss: 0.20165, val_acc: 0.96000\n",
      "Epoch [9460/10000], loss: 0.21927 acc: 0.90667 val_loss: 0.20158, val_acc: 0.96000\n",
      "Epoch [9470/10000], loss: 0.21920 acc: 0.90667 val_loss: 0.20151, val_acc: 0.96000\n",
      "Epoch [9480/10000], loss: 0.21914 acc: 0.90667 val_loss: 0.20144, val_acc: 0.96000\n",
      "Epoch [9490/10000], loss: 0.21907 acc: 0.90667 val_loss: 0.20137, val_acc: 0.96000\n",
      "Epoch [9500/10000], loss: 0.21901 acc: 0.90667 val_loss: 0.20130, val_acc: 0.96000\n",
      "Epoch [9510/10000], loss: 0.21894 acc: 0.90667 val_loss: 0.20123, val_acc: 0.96000\n",
      "Epoch [9520/10000], loss: 0.21887 acc: 0.90667 val_loss: 0.20115, val_acc: 0.96000\n",
      "Epoch [9530/10000], loss: 0.21881 acc: 0.90667 val_loss: 0.20108, val_acc: 0.96000\n",
      "Epoch [9540/10000], loss: 0.21874 acc: 0.90667 val_loss: 0.20101, val_acc: 0.96000\n",
      "Epoch [9550/10000], loss: 0.21868 acc: 0.90667 val_loss: 0.20094, val_acc: 0.96000\n",
      "Epoch [9560/10000], loss: 0.21861 acc: 0.90667 val_loss: 0.20087, val_acc: 0.96000\n",
      "Epoch [9570/10000], loss: 0.21854 acc: 0.90667 val_loss: 0.20080, val_acc: 0.96000\n",
      "Epoch [9580/10000], loss: 0.21848 acc: 0.90667 val_loss: 0.20073, val_acc: 0.96000\n",
      "Epoch [9590/10000], loss: 0.21841 acc: 0.90667 val_loss: 0.20066, val_acc: 0.96000\n",
      "Epoch [9600/10000], loss: 0.21835 acc: 0.90667 val_loss: 0.20059, val_acc: 0.96000\n",
      "Epoch [9610/10000], loss: 0.21828 acc: 0.90667 val_loss: 0.20052, val_acc: 0.96000\n",
      "Epoch [9620/10000], loss: 0.21822 acc: 0.90667 val_loss: 0.20045, val_acc: 0.96000\n",
      "Epoch [9630/10000], loss: 0.21815 acc: 0.90667 val_loss: 0.20038, val_acc: 0.96000\n",
      "Epoch [9640/10000], loss: 0.21809 acc: 0.90667 val_loss: 0.20031, val_acc: 0.96000\n",
      "Epoch [9650/10000], loss: 0.21803 acc: 0.90667 val_loss: 0.20024, val_acc: 0.96000\n",
      "Epoch [9660/10000], loss: 0.21796 acc: 0.90667 val_loss: 0.20017, val_acc: 0.96000\n",
      "Epoch [9670/10000], loss: 0.21790 acc: 0.90667 val_loss: 0.20010, val_acc: 0.96000\n",
      "Epoch [9680/10000], loss: 0.21783 acc: 0.90667 val_loss: 0.20004, val_acc: 0.96000\n",
      "Epoch [9690/10000], loss: 0.21777 acc: 0.90667 val_loss: 0.19997, val_acc: 0.96000\n",
      "Epoch [9700/10000], loss: 0.21770 acc: 0.90667 val_loss: 0.19990, val_acc: 0.96000\n",
      "Epoch [9710/10000], loss: 0.21764 acc: 0.90667 val_loss: 0.19983, val_acc: 0.96000\n",
      "Epoch [9720/10000], loss: 0.21758 acc: 0.90667 val_loss: 0.19976, val_acc: 0.96000\n",
      "Epoch [9730/10000], loss: 0.21751 acc: 0.90667 val_loss: 0.19969, val_acc: 0.96000\n",
      "Epoch [9740/10000], loss: 0.21745 acc: 0.90667 val_loss: 0.19962, val_acc: 0.96000\n",
      "Epoch [9750/10000], loss: 0.21739 acc: 0.90667 val_loss: 0.19956, val_acc: 0.96000\n",
      "Epoch [9760/10000], loss: 0.21732 acc: 0.90667 val_loss: 0.19949, val_acc: 0.96000\n",
      "Epoch [9770/10000], loss: 0.21726 acc: 0.90667 val_loss: 0.19942, val_acc: 0.96000\n",
      "Epoch [9780/10000], loss: 0.21720 acc: 0.90667 val_loss: 0.19935, val_acc: 0.96000\n",
      "Epoch [9790/10000], loss: 0.21713 acc: 0.90667 val_loss: 0.19928, val_acc: 0.96000\n",
      "Epoch [9800/10000], loss: 0.21707 acc: 0.90667 val_loss: 0.19922, val_acc: 0.96000\n",
      "Epoch [9810/10000], loss: 0.21701 acc: 0.90667 val_loss: 0.19915, val_acc: 0.96000\n",
      "Epoch [9820/10000], loss: 0.21695 acc: 0.90667 val_loss: 0.19908, val_acc: 0.96000\n",
      "Epoch [9830/10000], loss: 0.21688 acc: 0.90667 val_loss: 0.19901, val_acc: 0.96000\n",
      "Epoch [9840/10000], loss: 0.21682 acc: 0.90667 val_loss: 0.19895, val_acc: 0.96000\n",
      "Epoch [9850/10000], loss: 0.21676 acc: 0.90667 val_loss: 0.19888, val_acc: 0.96000\n",
      "Epoch [9860/10000], loss: 0.21670 acc: 0.90667 val_loss: 0.19881, val_acc: 0.96000\n",
      "Epoch [9870/10000], loss: 0.21663 acc: 0.90667 val_loss: 0.19874, val_acc: 0.96000\n",
      "Epoch [9880/10000], loss: 0.21657 acc: 0.90667 val_loss: 0.19868, val_acc: 0.96000\n",
      "Epoch [9890/10000], loss: 0.21651 acc: 0.90667 val_loss: 0.19861, val_acc: 0.96000\n",
      "Epoch [9900/10000], loss: 0.21645 acc: 0.90667 val_loss: 0.19854, val_acc: 0.96000\n",
      "Epoch [9910/10000], loss: 0.21639 acc: 0.90667 val_loss: 0.19848, val_acc: 0.96000\n",
      "Epoch [9920/10000], loss: 0.21633 acc: 0.90667 val_loss: 0.19841, val_acc: 0.96000\n",
      "Epoch [9930/10000], loss: 0.21626 acc: 0.90667 val_loss: 0.19835, val_acc: 0.96000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9940/10000], loss: 0.21620 acc: 0.90667 val_loss: 0.19828, val_acc: 0.96000\n",
      "Epoch [9950/10000], loss: 0.21614 acc: 0.90667 val_loss: 0.19821, val_acc: 0.96000\n",
      "Epoch [9960/10000], loss: 0.21608 acc: 0.90667 val_loss: 0.19815, val_acc: 0.96000\n",
      "Epoch [9970/10000], loss: 0.21602 acc: 0.90667 val_loss: 0.19808, val_acc: 0.96000\n",
      "Epoch [9980/10000], loss: 0.21596 acc: 0.90667 val_loss: 0.19802, val_acc: 0.96000\n",
      "Epoch [9990/10000], loss: 0.21590 acc: 0.90667 val_loss: 0.19795, val_acc: 0.96000\n"
     ]
    }
   ],
   "source": [
    "# 繰り返し計算メインループ\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    # 学習フェーズ\n",
    "    \n",
    "    #勾配の初期化\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 順伝搬計算\n",
    "    outputs = net(inputs)\n",
    "\n",
    "    # 誤差計算\n",
    "    loss = criterion(outputs, labels)\n",
    "\n",
    "    # 勾配計算\n",
    "    loss.backward()\n",
    "    \n",
    "    # 重み調整\n",
    "    optimizer.step()\n",
    "\n",
    "    #予測値算出\n",
    "    predicted = torch.max(outputs, 1)[1]\n",
    "\n",
    "    # 訓練データに対する損失と精度の計算\n",
    "    train_loss = loss.item()\n",
    "    train_acc = (predicted == labels).sum()  / len(labels)\n",
    "\n",
    "    #予測フェーズ\n",
    "    with torch.no_grad():\n",
    "\n",
    "        # 順伝搬計算\n",
    "        outputs_test = net(inputs_test)\n",
    "\n",
    "        # 誤差計算\n",
    "        loss_test = criterion(outputs_test, labels_test)\n",
    "\n",
    "        #予測値算出\n",
    "        predicted_test = torch.max(outputs_test, 1)[1]\n",
    "\n",
    "        # 検証データに対する損失と精度の計算\n",
    "        val_loss =  loss_test.item()\n",
    "        val_acc =  (predicted_test == labels_test).sum() / len(labels_test)\n",
    "    \n",
    "    if ( (epoch) % 10 == 0):\n",
    "        print (f'Epoch [{epoch}/{num_epochs}], loss: {train_loss:.5f} acc: {train_acc:.5f} val_loss: {val_loss:.5f}, val_acc: {val_acc:.5f}')\n",
    "        item = np.array([epoch, train_loss, train_acc, val_loss, val_acc])\n",
    "        history = np.vstack((history, item))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.11 結果確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "初期状態: 損失関数: 1.09263 精度: 0.26667\n",
      "最終状態: 損失関数: 0.19795 精度: 0.96000\n"
     ]
    }
   ],
   "source": [
    "#損失関数値と精度の確認\n",
    "\n",
    "print(f'初期状態: 損失関数: {history[0,3]:.5f} 精度: {history[0,4]:.5f}' )\n",
    "print(f'最終状態: 損失関数: {history[-1,3]:.5f} 精度: {history[-1,4]:.5f}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 学習曲線の表示 (損失関数)\n",
    "\n",
    "plt.plot(history[:,0], history[:,1], 'b', label='訓練')\n",
    "plt.plot(history[:,0], history[:,3], 'k', label='検証')\n",
    "plt.xlabel('繰り返し回数')\n",
    "plt.ylabel('損失関数値')\n",
    "plt.title('学習曲線(損失関数)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 学習曲線の表示 (精度)\n",
    "\n",
    "plt.plot(history[:,0], history[:,2], 'b', label='訓練')\n",
    "plt.plot(history[:,0], history[:,4], 'k', label='検証')\n",
    "plt.xlabel('繰り返し回数')\n",
    "plt.ylabel('精度')\n",
    "plt.title('学習曲線(精度)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルへの入力と出力の確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 0, 2])\n"
     ]
    }
   ],
   "source": [
    "# 正解ラベルの0番目、2番目、3番目\n",
    "\n",
    "print(labels[[0,2,3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.3 4.7]\n",
      " [5.  1.6]\n",
      " [6.4 5.6]]\n"
     ]
    }
   ],
   "source": [
    "# 該当する入力値を抽出\n",
    "\n",
    "i3 = inputs[[0,2,3],:]\n",
    "print(i3.data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8.8071 14.1938 12.9986]\n",
      " [12.8262  9.8     0.1734]\n",
      " [ 6.7954 15.0928 17.1111]]\n",
      "[[0.0035 0.765  0.2315]\n",
      " [0.9537 0.0463 0.    ]\n",
      " [0.     0.1173 0.8827]]\n"
     ]
    }
   ],
   "source": [
    "# 出力値にsoftmax関数をかけた結果を取得\n",
    "\n",
    "softmax = torch.nn.Softmax(dim=1)\n",
    "o3 = net(i3)\n",
    "k3 = softmax(o3)\n",
    "print(o3.data.numpy())\n",
    "print(k3.data.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 最終的な重み行列とバイアスの値"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3.0452, -2.5735],\n",
      "        [ 1.3573,  0.8481],\n",
      "        [-1.4026,  4.7253]])\n",
      "tensor([ 1.7178,  1.6563, -0.3741])\n"
     ]
    }
   ],
   "source": [
    "# 重み行列\n",
    "print(net.l1.weight.data)\n",
    "\n",
    "# バイアス\n",
    "print(net.l1.bias.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.11 入力変数の4次元化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75, 4) (75, 4) (75,) (75,)\n"
     ]
    }
   ],
   "source": [
    "# 学習データ、検証データに分割 (シャフルも同時に実施)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x_org, y_org, train_size=75, test_size=75, \n",
    "    random_state=123)\n",
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "# 入力次元数\n",
    "n_input = x_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "入力データ(x)\n",
      "[[6.3 3.3 4.7 1.6]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [5.  3.  1.6 0.2]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [6.3 2.5 5.  1.9]]\n",
      "入力次元数: 4\n"
     ]
    }
   ],
   "source": [
    "print('入力データ(x)')\n",
    "print(x_train[:5,:])\n",
    "print(f'入力次元数: {n_input}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 入力変数x_trainと正解値 y_trainのTesor化\n",
    "inputs = torch.tensor(x_train).float()\n",
    "labels = torch.tensor(y_train).long()\n",
    "\n",
    "# 検証用変数のTensor化\n",
    "inputs_test = torch.tensor(x_test).float()\n",
    "labels_test = torch.tensor(y_test).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習率\n",
    "lr = 0.01\n",
    "\n",
    "# 初期化\n",
    "net = Net(n_input, n_output)\n",
    "\n",
    "# 最適化アルゴリズム: 勾配降下法\n",
    "optimizer = optim.SGD(net.parameters(), lr=lr)\n",
    "\n",
    "# 損失関数： 交差エントロピー関数\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 繰り返し回数\n",
    "num_epochs = 10000\n",
    "\n",
    "# 評価結果記録用\n",
    "history = np.zeros((0,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/10000], loss: 1.09861 acc: 0.30667 val_loss: 1.09158, val_acc: 0.26667\n",
      "Epoch [10/10000], loss: 1.01848 acc: 0.40000 val_loss: 1.04171, val_acc: 0.26667\n",
      "Epoch [20/10000], loss: 0.96854 acc: 0.40000 val_loss: 0.98850, val_acc: 0.26667\n",
      "Epoch [30/10000], loss: 0.92459 acc: 0.65333 val_loss: 0.93996, val_acc: 0.57333\n",
      "Epoch [40/10000], loss: 0.88568 acc: 0.70667 val_loss: 0.89704, val_acc: 0.62667\n",
      "Epoch [50/10000], loss: 0.85120 acc: 0.70667 val_loss: 0.85918, val_acc: 0.62667\n",
      "Epoch [60/10000], loss: 0.82059 acc: 0.70667 val_loss: 0.82572, val_acc: 0.62667\n",
      "Epoch [70/10000], loss: 0.79335 acc: 0.72000 val_loss: 0.79607, val_acc: 0.62667\n",
      "Epoch [80/10000], loss: 0.76900 acc: 0.72000 val_loss: 0.76968, val_acc: 0.65333\n",
      "Epoch [90/10000], loss: 0.74717 acc: 0.72000 val_loss: 0.74610, val_acc: 0.65333\n",
      "Epoch [100/10000], loss: 0.72750 acc: 0.76000 val_loss: 0.72494, val_acc: 0.69333\n",
      "Epoch [110/10000], loss: 0.70970 acc: 0.77333 val_loss: 0.70585, val_acc: 0.74667\n",
      "Epoch [120/10000], loss: 0.69354 acc: 0.81333 val_loss: 0.68856, val_acc: 0.76000\n",
      "Epoch [130/10000], loss: 0.67878 acc: 0.84000 val_loss: 0.67283, val_acc: 0.76000\n",
      "Epoch [140/10000], loss: 0.66526 acc: 0.84000 val_loss: 0.65846, val_acc: 0.78667\n",
      "Epoch [150/10000], loss: 0.65283 acc: 0.86667 val_loss: 0.64528, val_acc: 0.78667\n",
      "Epoch [160/10000], loss: 0.64135 acc: 0.88000 val_loss: 0.63313, val_acc: 0.78667\n",
      "Epoch [170/10000], loss: 0.63070 acc: 0.89333 val_loss: 0.62190, val_acc: 0.81333\n",
      "Epoch [180/10000], loss: 0.62080 acc: 0.90667 val_loss: 0.61149, val_acc: 0.81333\n",
      "Epoch [190/10000], loss: 0.61157 acc: 0.90667 val_loss: 0.60179, val_acc: 0.84000\n",
      "Epoch [200/10000], loss: 0.60292 acc: 0.90667 val_loss: 0.59273, val_acc: 0.84000\n",
      "Epoch [210/10000], loss: 0.59481 acc: 0.90667 val_loss: 0.58425, val_acc: 0.88000\n",
      "Epoch [220/10000], loss: 0.58717 acc: 0.93333 val_loss: 0.57628, val_acc: 0.88000\n",
      "Epoch [230/10000], loss: 0.57996 acc: 0.93333 val_loss: 0.56877, val_acc: 0.89333\n",
      "Epoch [240/10000], loss: 0.57313 acc: 0.93333 val_loss: 0.56169, val_acc: 0.90667\n",
      "Epoch [250/10000], loss: 0.56666 acc: 0.93333 val_loss: 0.55498, val_acc: 0.90667\n",
      "Epoch [260/10000], loss: 0.56051 acc: 0.92000 val_loss: 0.54862, val_acc: 0.90667\n",
      "Epoch [270/10000], loss: 0.55465 acc: 0.92000 val_loss: 0.54257, val_acc: 0.90667\n",
      "Epoch [280/10000], loss: 0.54906 acc: 0.92000 val_loss: 0.53681, val_acc: 0.90667\n",
      "Epoch [290/10000], loss: 0.54371 acc: 0.92000 val_loss: 0.53131, val_acc: 0.90667\n",
      "Epoch [300/10000], loss: 0.53859 acc: 0.93333 val_loss: 0.52605, val_acc: 0.90667\n",
      "Epoch [310/10000], loss: 0.53368 acc: 0.93333 val_loss: 0.52102, val_acc: 0.90667\n",
      "Epoch [320/10000], loss: 0.52896 acc: 0.93333 val_loss: 0.51619, val_acc: 0.90667\n",
      "Epoch [330/10000], loss: 0.52442 acc: 0.93333 val_loss: 0.51155, val_acc: 0.90667\n",
      "Epoch [340/10000], loss: 0.52004 acc: 0.93333 val_loss: 0.50709, val_acc: 0.90667\n",
      "Epoch [350/10000], loss: 0.51582 acc: 0.93333 val_loss: 0.50280, val_acc: 0.90667\n",
      "Epoch [360/10000], loss: 0.51173 acc: 0.93333 val_loss: 0.49865, val_acc: 0.90667\n",
      "Epoch [370/10000], loss: 0.50779 acc: 0.93333 val_loss: 0.49465, val_acc: 0.90667\n",
      "Epoch [380/10000], loss: 0.50397 acc: 0.93333 val_loss: 0.49078, val_acc: 0.90667\n",
      "Epoch [390/10000], loss: 0.50026 acc: 0.93333 val_loss: 0.48703, val_acc: 0.90667\n",
      "Epoch [400/10000], loss: 0.49666 acc: 0.94667 val_loss: 0.48340, val_acc: 0.90667\n",
      "Epoch [410/10000], loss: 0.49317 acc: 0.94667 val_loss: 0.47988, val_acc: 0.90667\n",
      "Epoch [420/10000], loss: 0.48978 acc: 0.94667 val_loss: 0.47647, val_acc: 0.90667\n",
      "Epoch [430/10000], loss: 0.48647 acc: 0.96000 val_loss: 0.47315, val_acc: 0.90667\n",
      "Epoch [440/10000], loss: 0.48326 acc: 0.96000 val_loss: 0.46992, val_acc: 0.90667\n",
      "Epoch [450/10000], loss: 0.48012 acc: 0.96000 val_loss: 0.46678, val_acc: 0.90667\n",
      "Epoch [460/10000], loss: 0.47706 acc: 0.96000 val_loss: 0.46372, val_acc: 0.90667\n",
      "Epoch [470/10000], loss: 0.47408 acc: 0.96000 val_loss: 0.46073, val_acc: 0.90667\n",
      "Epoch [480/10000], loss: 0.47116 acc: 0.96000 val_loss: 0.45783, val_acc: 0.90667\n",
      "Epoch [490/10000], loss: 0.46831 acc: 0.96000 val_loss: 0.45499, val_acc: 0.90667\n",
      "Epoch [500/10000], loss: 0.46553 acc: 0.96000 val_loss: 0.45221, val_acc: 0.90667\n",
      "Epoch [510/10000], loss: 0.46280 acc: 0.96000 val_loss: 0.44951, val_acc: 0.90667\n",
      "Epoch [520/10000], loss: 0.46013 acc: 0.96000 val_loss: 0.44686, val_acc: 0.90667\n",
      "Epoch [530/10000], loss: 0.45752 acc: 0.96000 val_loss: 0.44426, val_acc: 0.90667\n",
      "Epoch [540/10000], loss: 0.45496 acc: 0.96000 val_loss: 0.44173, val_acc: 0.90667\n",
      "Epoch [550/10000], loss: 0.45245 acc: 0.96000 val_loss: 0.43924, val_acc: 0.90667\n",
      "Epoch [560/10000], loss: 0.44998 acc: 0.96000 val_loss: 0.43681, val_acc: 0.90667\n",
      "Epoch [570/10000], loss: 0.44757 acc: 0.96000 val_loss: 0.43442, val_acc: 0.90667\n",
      "Epoch [580/10000], loss: 0.44519 acc: 0.96000 val_loss: 0.43208, val_acc: 0.90667\n",
      "Epoch [590/10000], loss: 0.44286 acc: 0.96000 val_loss: 0.42979, val_acc: 0.92000\n",
      "Epoch [600/10000], loss: 0.44057 acc: 0.96000 val_loss: 0.42753, val_acc: 0.92000\n",
      "Epoch [610/10000], loss: 0.43832 acc: 0.96000 val_loss: 0.42532, val_acc: 0.92000\n",
      "Epoch [620/10000], loss: 0.43611 acc: 0.96000 val_loss: 0.42315, val_acc: 0.92000\n",
      "Epoch [630/10000], loss: 0.43393 acc: 0.96000 val_loss: 0.42101, val_acc: 0.92000\n",
      "Epoch [640/10000], loss: 0.43179 acc: 0.96000 val_loss: 0.41891, val_acc: 0.92000\n",
      "Epoch [650/10000], loss: 0.42968 acc: 0.96000 val_loss: 0.41685, val_acc: 0.92000\n",
      "Epoch [660/10000], loss: 0.42761 acc: 0.96000 val_loss: 0.41482, val_acc: 0.92000\n",
      "Epoch [670/10000], loss: 0.42556 acc: 0.96000 val_loss: 0.41282, val_acc: 0.92000\n",
      "Epoch [680/10000], loss: 0.42355 acc: 0.96000 val_loss: 0.41085, val_acc: 0.92000\n",
      "Epoch [690/10000], loss: 0.42157 acc: 0.96000 val_loss: 0.40892, val_acc: 0.92000\n",
      "Epoch [700/10000], loss: 0.41961 acc: 0.96000 val_loss: 0.40701, val_acc: 0.92000\n",
      "Epoch [710/10000], loss: 0.41768 acc: 0.96000 val_loss: 0.40513, val_acc: 0.92000\n",
      "Epoch [720/10000], loss: 0.41578 acc: 0.96000 val_loss: 0.40329, val_acc: 0.92000\n",
      "Epoch [730/10000], loss: 0.41391 acc: 0.96000 val_loss: 0.40146, val_acc: 0.92000\n",
      "Epoch [740/10000], loss: 0.41206 acc: 0.96000 val_loss: 0.39967, val_acc: 0.92000\n",
      "Epoch [750/10000], loss: 0.41024 acc: 0.96000 val_loss: 0.39789, val_acc: 0.92000\n",
      "Epoch [760/10000], loss: 0.40844 acc: 0.96000 val_loss: 0.39615, val_acc: 0.92000\n",
      "Epoch [770/10000], loss: 0.40666 acc: 0.96000 val_loss: 0.39443, val_acc: 0.93333\n",
      "Epoch [780/10000], loss: 0.40491 acc: 0.96000 val_loss: 0.39273, val_acc: 0.93333\n",
      "Epoch [790/10000], loss: 0.40317 acc: 0.96000 val_loss: 0.39105, val_acc: 0.93333\n",
      "Epoch [800/10000], loss: 0.40146 acc: 0.96000 val_loss: 0.38939, val_acc: 0.93333\n",
      "Epoch [810/10000], loss: 0.39977 acc: 0.96000 val_loss: 0.38776, val_acc: 0.93333\n",
      "Epoch [820/10000], loss: 0.39810 acc: 0.96000 val_loss: 0.38615, val_acc: 0.93333\n",
      "Epoch [830/10000], loss: 0.39645 acc: 0.96000 val_loss: 0.38456, val_acc: 0.93333\n",
      "Epoch [840/10000], loss: 0.39483 acc: 0.96000 val_loss: 0.38298, val_acc: 0.93333\n",
      "Epoch [850/10000], loss: 0.39321 acc: 0.97333 val_loss: 0.38143, val_acc: 0.94667\n",
      "Epoch [860/10000], loss: 0.39162 acc: 0.97333 val_loss: 0.37990, val_acc: 0.94667\n",
      "Epoch [870/10000], loss: 0.39005 acc: 0.97333 val_loss: 0.37838, val_acc: 0.94667\n",
      "Epoch [880/10000], loss: 0.38849 acc: 0.97333 val_loss: 0.37688, val_acc: 0.94667\n",
      "Epoch [890/10000], loss: 0.38695 acc: 0.97333 val_loss: 0.37540, val_acc: 0.94667\n",
      "Epoch [900/10000], loss: 0.38543 acc: 0.97333 val_loss: 0.37394, val_acc: 0.94667\n",
      "Epoch [910/10000], loss: 0.38392 acc: 0.97333 val_loss: 0.37249, val_acc: 0.94667\n",
      "Epoch [920/10000], loss: 0.38243 acc: 0.97333 val_loss: 0.37106, val_acc: 0.94667\n",
      "Epoch [930/10000], loss: 0.38096 acc: 0.97333 val_loss: 0.36965, val_acc: 0.94667\n",
      "Epoch [940/10000], loss: 0.37950 acc: 0.97333 val_loss: 0.36825, val_acc: 0.94667\n",
      "Epoch [950/10000], loss: 0.37806 acc: 0.97333 val_loss: 0.36686, val_acc: 0.94667\n",
      "Epoch [960/10000], loss: 0.37663 acc: 0.97333 val_loss: 0.36550, val_acc: 0.96000\n",
      "Epoch [970/10000], loss: 0.37522 acc: 0.97333 val_loss: 0.36414, val_acc: 0.96000\n",
      "Epoch [980/10000], loss: 0.37382 acc: 0.97333 val_loss: 0.36280, val_acc: 0.96000\n",
      "Epoch [990/10000], loss: 0.37243 acc: 0.97333 val_loss: 0.36148, val_acc: 0.96000\n",
      "Epoch [1000/10000], loss: 0.37106 acc: 0.97333 val_loss: 0.36017, val_acc: 0.96000\n",
      "Epoch [1010/10000], loss: 0.36970 acc: 0.97333 val_loss: 0.35887, val_acc: 0.96000\n",
      "Epoch [1020/10000], loss: 0.36836 acc: 0.97333 val_loss: 0.35758, val_acc: 0.96000\n",
      "Epoch [1030/10000], loss: 0.36703 acc: 0.97333 val_loss: 0.35631, val_acc: 0.96000\n",
      "Epoch [1040/10000], loss: 0.36571 acc: 0.97333 val_loss: 0.35506, val_acc: 0.96000\n",
      "Epoch [1050/10000], loss: 0.36440 acc: 0.97333 val_loss: 0.35381, val_acc: 0.96000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1060/10000], loss: 0.36311 acc: 0.97333 val_loss: 0.35258, val_acc: 0.96000\n",
      "Epoch [1070/10000], loss: 0.36183 acc: 0.97333 val_loss: 0.35135, val_acc: 0.96000\n",
      "Epoch [1080/10000], loss: 0.36056 acc: 0.97333 val_loss: 0.35014, val_acc: 0.96000\n",
      "Epoch [1090/10000], loss: 0.35930 acc: 0.97333 val_loss: 0.34895, val_acc: 0.96000\n",
      "Epoch [1100/10000], loss: 0.35805 acc: 0.97333 val_loss: 0.34776, val_acc: 0.96000\n",
      "Epoch [1110/10000], loss: 0.35682 acc: 0.97333 val_loss: 0.34659, val_acc: 0.96000\n",
      "Epoch [1120/10000], loss: 0.35559 acc: 0.97333 val_loss: 0.34542, val_acc: 0.96000\n",
      "Epoch [1130/10000], loss: 0.35438 acc: 0.97333 val_loss: 0.34427, val_acc: 0.96000\n",
      "Epoch [1140/10000], loss: 0.35318 acc: 0.97333 val_loss: 0.34313, val_acc: 0.96000\n",
      "Epoch [1150/10000], loss: 0.35199 acc: 0.97333 val_loss: 0.34199, val_acc: 0.96000\n",
      "Epoch [1160/10000], loss: 0.35081 acc: 0.97333 val_loss: 0.34087, val_acc: 0.96000\n",
      "Epoch [1170/10000], loss: 0.34964 acc: 0.97333 val_loss: 0.33976, val_acc: 0.96000\n",
      "Epoch [1180/10000], loss: 0.34848 acc: 0.97333 val_loss: 0.33866, val_acc: 0.96000\n",
      "Epoch [1190/10000], loss: 0.34732 acc: 0.97333 val_loss: 0.33757, val_acc: 0.96000\n",
      "Epoch [1200/10000], loss: 0.34618 acc: 0.97333 val_loss: 0.33649, val_acc: 0.96000\n",
      "Epoch [1210/10000], loss: 0.34505 acc: 0.97333 val_loss: 0.33542, val_acc: 0.96000\n",
      "Epoch [1220/10000], loss: 0.34393 acc: 0.97333 val_loss: 0.33435, val_acc: 0.96000\n",
      "Epoch [1230/10000], loss: 0.34282 acc: 0.97333 val_loss: 0.33330, val_acc: 0.96000\n",
      "Epoch [1240/10000], loss: 0.34172 acc: 0.97333 val_loss: 0.33226, val_acc: 0.96000\n",
      "Epoch [1250/10000], loss: 0.34062 acc: 0.97333 val_loss: 0.33122, val_acc: 0.96000\n",
      "Epoch [1260/10000], loss: 0.33954 acc: 0.97333 val_loss: 0.33020, val_acc: 0.96000\n",
      "Epoch [1270/10000], loss: 0.33846 acc: 0.97333 val_loss: 0.32918, val_acc: 0.96000\n",
      "Epoch [1280/10000], loss: 0.33740 acc: 0.97333 val_loss: 0.32817, val_acc: 0.96000\n",
      "Epoch [1290/10000], loss: 0.33634 acc: 0.97333 val_loss: 0.32717, val_acc: 0.96000\n",
      "Epoch [1300/10000], loss: 0.33529 acc: 0.97333 val_loss: 0.32618, val_acc: 0.96000\n",
      "Epoch [1310/10000], loss: 0.33425 acc: 0.97333 val_loss: 0.32520, val_acc: 0.96000\n",
      "Epoch [1320/10000], loss: 0.33321 acc: 0.97333 val_loss: 0.32422, val_acc: 0.96000\n",
      "Epoch [1330/10000], loss: 0.33219 acc: 0.97333 val_loss: 0.32325, val_acc: 0.96000\n",
      "Epoch [1340/10000], loss: 0.33117 acc: 0.97333 val_loss: 0.32229, val_acc: 0.96000\n",
      "Epoch [1350/10000], loss: 0.33016 acc: 0.97333 val_loss: 0.32134, val_acc: 0.96000\n",
      "Epoch [1360/10000], loss: 0.32916 acc: 0.97333 val_loss: 0.32040, val_acc: 0.96000\n",
      "Epoch [1370/10000], loss: 0.32817 acc: 0.97333 val_loss: 0.31946, val_acc: 0.96000\n",
      "Epoch [1380/10000], loss: 0.32719 acc: 0.97333 val_loss: 0.31853, val_acc: 0.96000\n",
      "Epoch [1390/10000], loss: 0.32621 acc: 0.97333 val_loss: 0.31761, val_acc: 0.96000\n",
      "Epoch [1400/10000], loss: 0.32524 acc: 0.97333 val_loss: 0.31670, val_acc: 0.96000\n",
      "Epoch [1410/10000], loss: 0.32428 acc: 0.97333 val_loss: 0.31579, val_acc: 0.96000\n",
      "Epoch [1420/10000], loss: 0.32332 acc: 0.97333 val_loss: 0.31489, val_acc: 0.96000\n",
      "Epoch [1430/10000], loss: 0.32237 acc: 0.97333 val_loss: 0.31400, val_acc: 0.96000\n",
      "Epoch [1440/10000], loss: 0.32143 acc: 0.97333 val_loss: 0.31312, val_acc: 0.96000\n",
      "Epoch [1450/10000], loss: 0.32050 acc: 0.97333 val_loss: 0.31224, val_acc: 0.96000\n",
      "Epoch [1460/10000], loss: 0.31957 acc: 0.97333 val_loss: 0.31137, val_acc: 0.96000\n",
      "Epoch [1470/10000], loss: 0.31865 acc: 0.97333 val_loss: 0.31050, val_acc: 0.96000\n",
      "Epoch [1480/10000], loss: 0.31774 acc: 0.97333 val_loss: 0.30964, val_acc: 0.96000\n",
      "Epoch [1490/10000], loss: 0.31683 acc: 0.97333 val_loss: 0.30879, val_acc: 0.96000\n",
      "Epoch [1500/10000], loss: 0.31593 acc: 0.97333 val_loss: 0.30795, val_acc: 0.96000\n",
      "Epoch [1510/10000], loss: 0.31504 acc: 0.97333 val_loss: 0.30711, val_acc: 0.96000\n",
      "Epoch [1520/10000], loss: 0.31415 acc: 0.97333 val_loss: 0.30628, val_acc: 0.96000\n",
      "Epoch [1530/10000], loss: 0.31327 acc: 0.97333 val_loss: 0.30545, val_acc: 0.96000\n",
      "Epoch [1540/10000], loss: 0.31240 acc: 0.97333 val_loss: 0.30463, val_acc: 0.96000\n",
      "Epoch [1550/10000], loss: 0.31153 acc: 0.97333 val_loss: 0.30382, val_acc: 0.96000\n",
      "Epoch [1560/10000], loss: 0.31067 acc: 0.97333 val_loss: 0.30301, val_acc: 0.96000\n",
      "Epoch [1570/10000], loss: 0.30981 acc: 0.97333 val_loss: 0.30221, val_acc: 0.96000\n",
      "Epoch [1580/10000], loss: 0.30896 acc: 0.97333 val_loss: 0.30141, val_acc: 0.96000\n",
      "Epoch [1590/10000], loss: 0.30812 acc: 0.97333 val_loss: 0.30062, val_acc: 0.96000\n",
      "Epoch [1600/10000], loss: 0.30728 acc: 0.97333 val_loss: 0.29984, val_acc: 0.96000\n",
      "Epoch [1610/10000], loss: 0.30645 acc: 0.97333 val_loss: 0.29906, val_acc: 0.96000\n",
      "Epoch [1620/10000], loss: 0.30562 acc: 0.97333 val_loss: 0.29828, val_acc: 0.96000\n",
      "Epoch [1630/10000], loss: 0.30480 acc: 0.97333 val_loss: 0.29752, val_acc: 0.96000\n",
      "Epoch [1640/10000], loss: 0.30399 acc: 0.97333 val_loss: 0.29675, val_acc: 0.96000\n",
      "Epoch [1650/10000], loss: 0.30318 acc: 0.97333 val_loss: 0.29600, val_acc: 0.96000\n",
      "Epoch [1660/10000], loss: 0.30237 acc: 0.97333 val_loss: 0.29525, val_acc: 0.96000\n",
      "Epoch [1670/10000], loss: 0.30158 acc: 0.97333 val_loss: 0.29450, val_acc: 0.96000\n",
      "Epoch [1680/10000], loss: 0.30078 acc: 0.97333 val_loss: 0.29376, val_acc: 0.96000\n",
      "Epoch [1690/10000], loss: 0.30000 acc: 0.97333 val_loss: 0.29302, val_acc: 0.96000\n",
      "Epoch [1700/10000], loss: 0.29922 acc: 0.97333 val_loss: 0.29229, val_acc: 0.96000\n",
      "Epoch [1710/10000], loss: 0.29844 acc: 0.97333 val_loss: 0.29157, val_acc: 0.96000\n",
      "Epoch [1720/10000], loss: 0.29767 acc: 0.97333 val_loss: 0.29085, val_acc: 0.96000\n",
      "Epoch [1730/10000], loss: 0.29690 acc: 0.97333 val_loss: 0.29013, val_acc: 0.96000\n",
      "Epoch [1740/10000], loss: 0.29614 acc: 0.97333 val_loss: 0.28942, val_acc: 0.96000\n",
      "Epoch [1750/10000], loss: 0.29538 acc: 0.97333 val_loss: 0.28872, val_acc: 0.96000\n",
      "Epoch [1760/10000], loss: 0.29463 acc: 0.97333 val_loss: 0.28801, val_acc: 0.96000\n",
      "Epoch [1770/10000], loss: 0.29389 acc: 0.97333 val_loss: 0.28732, val_acc: 0.96000\n",
      "Epoch [1780/10000], loss: 0.29315 acc: 0.97333 val_loss: 0.28663, val_acc: 0.96000\n",
      "Epoch [1790/10000], loss: 0.29241 acc: 0.97333 val_loss: 0.28594, val_acc: 0.96000\n",
      "Epoch [1800/10000], loss: 0.29168 acc: 0.97333 val_loss: 0.28526, val_acc: 0.96000\n",
      "Epoch [1810/10000], loss: 0.29095 acc: 0.97333 val_loss: 0.28458, val_acc: 0.96000\n",
      "Epoch [1820/10000], loss: 0.29023 acc: 0.97333 val_loss: 0.28391, val_acc: 0.96000\n",
      "Epoch [1830/10000], loss: 0.28951 acc: 0.97333 val_loss: 0.28324, val_acc: 0.96000\n",
      "Epoch [1840/10000], loss: 0.28880 acc: 0.97333 val_loss: 0.28258, val_acc: 0.96000\n",
      "Epoch [1850/10000], loss: 0.28809 acc: 0.97333 val_loss: 0.28192, val_acc: 0.96000\n",
      "Epoch [1860/10000], loss: 0.28739 acc: 0.97333 val_loss: 0.28126, val_acc: 0.96000\n",
      "Epoch [1870/10000], loss: 0.28669 acc: 0.97333 val_loss: 0.28061, val_acc: 0.96000\n",
      "Epoch [1880/10000], loss: 0.28599 acc: 0.97333 val_loss: 0.27996, val_acc: 0.96000\n",
      "Epoch [1890/10000], loss: 0.28530 acc: 0.97333 val_loss: 0.27932, val_acc: 0.96000\n",
      "Epoch [1900/10000], loss: 0.28462 acc: 0.97333 val_loss: 0.27868, val_acc: 0.96000\n",
      "Epoch [1910/10000], loss: 0.28394 acc: 0.97333 val_loss: 0.27805, val_acc: 0.96000\n",
      "Epoch [1920/10000], loss: 0.28326 acc: 0.97333 val_loss: 0.27742, val_acc: 0.96000\n",
      "Epoch [1930/10000], loss: 0.28258 acc: 0.97333 val_loss: 0.27679, val_acc: 0.96000\n",
      "Epoch [1940/10000], loss: 0.28192 acc: 0.97333 val_loss: 0.27617, val_acc: 0.96000\n",
      "Epoch [1950/10000], loss: 0.28125 acc: 0.97333 val_loss: 0.27555, val_acc: 0.96000\n",
      "Epoch [1960/10000], loss: 0.28059 acc: 0.97333 val_loss: 0.27494, val_acc: 0.96000\n",
      "Epoch [1970/10000], loss: 0.27993 acc: 0.97333 val_loss: 0.27433, val_acc: 0.96000\n",
      "Epoch [1980/10000], loss: 0.27928 acc: 0.97333 val_loss: 0.27372, val_acc: 0.96000\n",
      "Epoch [1990/10000], loss: 0.27863 acc: 0.97333 val_loss: 0.27312, val_acc: 0.96000\n",
      "Epoch [2000/10000], loss: 0.27799 acc: 0.97333 val_loss: 0.27252, val_acc: 0.96000\n",
      "Epoch [2010/10000], loss: 0.27735 acc: 0.97333 val_loss: 0.27193, val_acc: 0.96000\n",
      "Epoch [2020/10000], loss: 0.27671 acc: 0.97333 val_loss: 0.27134, val_acc: 0.96000\n",
      "Epoch [2030/10000], loss: 0.27608 acc: 0.97333 val_loss: 0.27075, val_acc: 0.96000\n",
      "Epoch [2040/10000], loss: 0.27545 acc: 0.97333 val_loss: 0.27016, val_acc: 0.96000\n",
      "Epoch [2050/10000], loss: 0.27482 acc: 0.97333 val_loss: 0.26958, val_acc: 0.96000\n",
      "Epoch [2060/10000], loss: 0.27420 acc: 0.97333 val_loss: 0.26901, val_acc: 0.96000\n",
      "Epoch [2070/10000], loss: 0.27358 acc: 0.97333 val_loss: 0.26843, val_acc: 0.96000\n",
      "Epoch [2080/10000], loss: 0.27297 acc: 0.97333 val_loss: 0.26786, val_acc: 0.96000\n",
      "Epoch [2090/10000], loss: 0.27236 acc: 0.97333 val_loss: 0.26730, val_acc: 0.96000\n",
      "Epoch [2100/10000], loss: 0.27175 acc: 0.97333 val_loss: 0.26674, val_acc: 0.96000\n",
      "Epoch [2110/10000], loss: 0.27115 acc: 0.97333 val_loss: 0.26618, val_acc: 0.96000\n",
      "Epoch [2120/10000], loss: 0.27055 acc: 0.97333 val_loss: 0.26562, val_acc: 0.96000\n",
      "Epoch [2130/10000], loss: 0.26995 acc: 0.97333 val_loss: 0.26507, val_acc: 0.96000\n",
      "Epoch [2140/10000], loss: 0.26936 acc: 0.97333 val_loss: 0.26452, val_acc: 0.96000\n",
      "Epoch [2150/10000], loss: 0.26877 acc: 0.97333 val_loss: 0.26397, val_acc: 0.96000\n",
      "Epoch [2160/10000], loss: 0.26818 acc: 0.97333 val_loss: 0.26343, val_acc: 0.96000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2170/10000], loss: 0.26760 acc: 0.97333 val_loss: 0.26289, val_acc: 0.96000\n",
      "Epoch [2180/10000], loss: 0.26702 acc: 0.97333 val_loss: 0.26236, val_acc: 0.96000\n",
      "Epoch [2190/10000], loss: 0.26644 acc: 0.97333 val_loss: 0.26182, val_acc: 0.96000\n",
      "Epoch [2200/10000], loss: 0.26587 acc: 0.97333 val_loss: 0.26129, val_acc: 0.96000\n",
      "Epoch [2210/10000], loss: 0.26530 acc: 0.97333 val_loss: 0.26077, val_acc: 0.96000\n",
      "Epoch [2220/10000], loss: 0.26473 acc: 0.97333 val_loss: 0.26024, val_acc: 0.96000\n",
      "Epoch [2230/10000], loss: 0.26417 acc: 0.97333 val_loss: 0.25972, val_acc: 0.96000\n",
      "Epoch [2240/10000], loss: 0.26361 acc: 0.97333 val_loss: 0.25921, val_acc: 0.96000\n",
      "Epoch [2250/10000], loss: 0.26305 acc: 0.97333 val_loss: 0.25869, val_acc: 0.96000\n",
      "Epoch [2260/10000], loss: 0.26250 acc: 0.97333 val_loss: 0.25818, val_acc: 0.96000\n",
      "Epoch [2270/10000], loss: 0.26195 acc: 0.97333 val_loss: 0.25767, val_acc: 0.96000\n",
      "Epoch [2280/10000], loss: 0.26140 acc: 0.97333 val_loss: 0.25717, val_acc: 0.96000\n",
      "Epoch [2290/10000], loss: 0.26086 acc: 0.97333 val_loss: 0.25666, val_acc: 0.96000\n",
      "Epoch [2300/10000], loss: 0.26032 acc: 0.97333 val_loss: 0.25616, val_acc: 0.96000\n",
      "Epoch [2310/10000], loss: 0.25978 acc: 0.97333 val_loss: 0.25567, val_acc: 0.96000\n",
      "Epoch [2320/10000], loss: 0.25924 acc: 0.97333 val_loss: 0.25517, val_acc: 0.96000\n",
      "Epoch [2330/10000], loss: 0.25871 acc: 0.97333 val_loss: 0.25468, val_acc: 0.96000\n",
      "Epoch [2340/10000], loss: 0.25818 acc: 0.97333 val_loss: 0.25419, val_acc: 0.96000\n",
      "Epoch [2350/10000], loss: 0.25766 acc: 0.97333 val_loss: 0.25371, val_acc: 0.96000\n",
      "Epoch [2360/10000], loss: 0.25713 acc: 0.97333 val_loss: 0.25322, val_acc: 0.96000\n",
      "Epoch [2370/10000], loss: 0.25661 acc: 0.97333 val_loss: 0.25274, val_acc: 0.96000\n",
      "Epoch [2380/10000], loss: 0.25609 acc: 0.97333 val_loss: 0.25227, val_acc: 0.96000\n",
      "Epoch [2390/10000], loss: 0.25558 acc: 0.97333 val_loss: 0.25179, val_acc: 0.96000\n",
      "Epoch [2400/10000], loss: 0.25507 acc: 0.97333 val_loss: 0.25132, val_acc: 0.96000\n",
      "Epoch [2410/10000], loss: 0.25456 acc: 0.97333 val_loss: 0.25085, val_acc: 0.96000\n",
      "Epoch [2420/10000], loss: 0.25405 acc: 0.97333 val_loss: 0.25038, val_acc: 0.96000\n",
      "Epoch [2430/10000], loss: 0.25355 acc: 0.97333 val_loss: 0.24992, val_acc: 0.96000\n",
      "Epoch [2440/10000], loss: 0.25304 acc: 0.97333 val_loss: 0.24946, val_acc: 0.96000\n",
      "Epoch [2450/10000], loss: 0.25255 acc: 0.97333 val_loss: 0.24900, val_acc: 0.96000\n",
      "Epoch [2460/10000], loss: 0.25205 acc: 0.97333 val_loss: 0.24854, val_acc: 0.96000\n",
      "Epoch [2470/10000], loss: 0.25156 acc: 0.97333 val_loss: 0.24809, val_acc: 0.96000\n",
      "Epoch [2480/10000], loss: 0.25107 acc: 0.97333 val_loss: 0.24764, val_acc: 0.96000\n",
      "Epoch [2490/10000], loss: 0.25058 acc: 0.97333 val_loss: 0.24719, val_acc: 0.96000\n",
      "Epoch [2500/10000], loss: 0.25009 acc: 0.97333 val_loss: 0.24674, val_acc: 0.96000\n",
      "Epoch [2510/10000], loss: 0.24961 acc: 0.97333 val_loss: 0.24630, val_acc: 0.96000\n",
      "Epoch [2520/10000], loss: 0.24913 acc: 0.97333 val_loss: 0.24585, val_acc: 0.96000\n",
      "Epoch [2530/10000], loss: 0.24865 acc: 0.97333 val_loss: 0.24541, val_acc: 0.96000\n",
      "Epoch [2540/10000], loss: 0.24818 acc: 0.97333 val_loss: 0.24498, val_acc: 0.96000\n",
      "Epoch [2550/10000], loss: 0.24770 acc: 0.97333 val_loss: 0.24454, val_acc: 0.96000\n",
      "Epoch [2560/10000], loss: 0.24723 acc: 0.97333 val_loss: 0.24411, val_acc: 0.96000\n",
      "Epoch [2570/10000], loss: 0.24676 acc: 0.97333 val_loss: 0.24368, val_acc: 0.96000\n",
      "Epoch [2580/10000], loss: 0.24630 acc: 0.98667 val_loss: 0.24325, val_acc: 0.96000\n",
      "Epoch [2590/10000], loss: 0.24584 acc: 0.98667 val_loss: 0.24283, val_acc: 0.96000\n",
      "Epoch [2600/10000], loss: 0.24537 acc: 0.98667 val_loss: 0.24240, val_acc: 0.96000\n",
      "Epoch [2610/10000], loss: 0.24492 acc: 0.98667 val_loss: 0.24198, val_acc: 0.96000\n",
      "Epoch [2620/10000], loss: 0.24446 acc: 0.98667 val_loss: 0.24156, val_acc: 0.96000\n",
      "Epoch [2630/10000], loss: 0.24401 acc: 0.98667 val_loss: 0.24115, val_acc: 0.96000\n",
      "Epoch [2640/10000], loss: 0.24355 acc: 0.98667 val_loss: 0.24073, val_acc: 0.96000\n",
      "Epoch [2650/10000], loss: 0.24311 acc: 0.98667 val_loss: 0.24032, val_acc: 0.96000\n",
      "Epoch [2660/10000], loss: 0.24266 acc: 0.98667 val_loss: 0.23991, val_acc: 0.96000\n",
      "Epoch [2670/10000], loss: 0.24221 acc: 0.98667 val_loss: 0.23950, val_acc: 0.96000\n",
      "Epoch [2680/10000], loss: 0.24177 acc: 0.98667 val_loss: 0.23909, val_acc: 0.96000\n",
      "Epoch [2690/10000], loss: 0.24133 acc: 0.98667 val_loss: 0.23869, val_acc: 0.96000\n",
      "Epoch [2700/10000], loss: 0.24089 acc: 0.98667 val_loss: 0.23829, val_acc: 0.96000\n",
      "Epoch [2710/10000], loss: 0.24046 acc: 0.98667 val_loss: 0.23789, val_acc: 0.96000\n",
      "Epoch [2720/10000], loss: 0.24002 acc: 0.98667 val_loss: 0.23749, val_acc: 0.96000\n",
      "Epoch [2730/10000], loss: 0.23959 acc: 0.98667 val_loss: 0.23710, val_acc: 0.96000\n",
      "Epoch [2740/10000], loss: 0.23916 acc: 0.98667 val_loss: 0.23670, val_acc: 0.96000\n",
      "Epoch [2750/10000], loss: 0.23874 acc: 0.98667 val_loss: 0.23631, val_acc: 0.96000\n",
      "Epoch [2760/10000], loss: 0.23831 acc: 0.98667 val_loss: 0.23592, val_acc: 0.96000\n",
      "Epoch [2770/10000], loss: 0.23789 acc: 0.98667 val_loss: 0.23553, val_acc: 0.96000\n",
      "Epoch [2780/10000], loss: 0.23747 acc: 0.98667 val_loss: 0.23515, val_acc: 0.96000\n",
      "Epoch [2790/10000], loss: 0.23705 acc: 0.98667 val_loss: 0.23476, val_acc: 0.96000\n",
      "Epoch [2800/10000], loss: 0.23663 acc: 0.98667 val_loss: 0.23438, val_acc: 0.96000\n",
      "Epoch [2810/10000], loss: 0.23622 acc: 0.98667 val_loss: 0.23400, val_acc: 0.96000\n",
      "Epoch [2820/10000], loss: 0.23580 acc: 0.98667 val_loss: 0.23363, val_acc: 0.96000\n",
      "Epoch [2830/10000], loss: 0.23539 acc: 0.98667 val_loss: 0.23325, val_acc: 0.96000\n",
      "Epoch [2840/10000], loss: 0.23498 acc: 0.98667 val_loss: 0.23288, val_acc: 0.96000\n",
      "Epoch [2850/10000], loss: 0.23458 acc: 0.98667 val_loss: 0.23250, val_acc: 0.96000\n",
      "Epoch [2860/10000], loss: 0.23417 acc: 0.98667 val_loss: 0.23213, val_acc: 0.96000\n",
      "Epoch [2870/10000], loss: 0.23377 acc: 0.98667 val_loss: 0.23176, val_acc: 0.96000\n",
      "Epoch [2880/10000], loss: 0.23337 acc: 0.98667 val_loss: 0.23140, val_acc: 0.96000\n",
      "Epoch [2890/10000], loss: 0.23297 acc: 0.98667 val_loss: 0.23103, val_acc: 0.96000\n",
      "Epoch [2900/10000], loss: 0.23257 acc: 0.98667 val_loss: 0.23067, val_acc: 0.96000\n",
      "Epoch [2910/10000], loss: 0.23218 acc: 0.98667 val_loss: 0.23031, val_acc: 0.96000\n",
      "Epoch [2920/10000], loss: 0.23178 acc: 0.98667 val_loss: 0.22995, val_acc: 0.96000\n",
      "Epoch [2930/10000], loss: 0.23139 acc: 0.98667 val_loss: 0.22959, val_acc: 0.96000\n",
      "Epoch [2940/10000], loss: 0.23100 acc: 0.98667 val_loss: 0.22923, val_acc: 0.96000\n",
      "Epoch [2950/10000], loss: 0.23061 acc: 0.98667 val_loss: 0.22888, val_acc: 0.96000\n",
      "Epoch [2960/10000], loss: 0.23023 acc: 0.98667 val_loss: 0.22853, val_acc: 0.96000\n",
      "Epoch [2970/10000], loss: 0.22984 acc: 0.98667 val_loss: 0.22818, val_acc: 0.96000\n",
      "Epoch [2980/10000], loss: 0.22946 acc: 0.98667 val_loss: 0.22783, val_acc: 0.96000\n",
      "Epoch [2990/10000], loss: 0.22908 acc: 0.98667 val_loss: 0.22748, val_acc: 0.96000\n",
      "Epoch [3000/10000], loss: 0.22870 acc: 0.98667 val_loss: 0.22713, val_acc: 0.96000\n",
      "Epoch [3010/10000], loss: 0.22832 acc: 0.98667 val_loss: 0.22679, val_acc: 0.96000\n",
      "Epoch [3020/10000], loss: 0.22795 acc: 0.98667 val_loss: 0.22645, val_acc: 0.96000\n",
      "Epoch [3030/10000], loss: 0.22757 acc: 0.98667 val_loss: 0.22610, val_acc: 0.96000\n",
      "Epoch [3040/10000], loss: 0.22720 acc: 0.98667 val_loss: 0.22577, val_acc: 0.96000\n",
      "Epoch [3050/10000], loss: 0.22683 acc: 0.98667 val_loss: 0.22543, val_acc: 0.96000\n",
      "Epoch [3060/10000], loss: 0.22646 acc: 0.98667 val_loss: 0.22509, val_acc: 0.96000\n",
      "Epoch [3070/10000], loss: 0.22610 acc: 0.98667 val_loss: 0.22476, val_acc: 0.96000\n",
      "Epoch [3080/10000], loss: 0.22573 acc: 0.98667 val_loss: 0.22442, val_acc: 0.96000\n",
      "Epoch [3090/10000], loss: 0.22537 acc: 0.98667 val_loss: 0.22409, val_acc: 0.96000\n",
      "Epoch [3100/10000], loss: 0.22501 acc: 0.98667 val_loss: 0.22376, val_acc: 0.96000\n",
      "Epoch [3110/10000], loss: 0.22465 acc: 0.98667 val_loss: 0.22343, val_acc: 0.96000\n",
      "Epoch [3120/10000], loss: 0.22429 acc: 0.98667 val_loss: 0.22311, val_acc: 0.96000\n",
      "Epoch [3130/10000], loss: 0.22393 acc: 0.98667 val_loss: 0.22278, val_acc: 0.96000\n",
      "Epoch [3140/10000], loss: 0.22357 acc: 0.98667 val_loss: 0.22246, val_acc: 0.96000\n",
      "Epoch [3150/10000], loss: 0.22322 acc: 0.98667 val_loss: 0.22214, val_acc: 0.96000\n",
      "Epoch [3160/10000], loss: 0.22287 acc: 0.98667 val_loss: 0.22181, val_acc: 0.96000\n",
      "Epoch [3170/10000], loss: 0.22252 acc: 0.98667 val_loss: 0.22150, val_acc: 0.96000\n",
      "Epoch [3180/10000], loss: 0.22217 acc: 0.98667 val_loss: 0.22118, val_acc: 0.96000\n",
      "Epoch [3190/10000], loss: 0.22182 acc: 0.98667 val_loss: 0.22086, val_acc: 0.96000\n",
      "Epoch [3200/10000], loss: 0.22148 acc: 0.98667 val_loss: 0.22055, val_acc: 0.96000\n",
      "Epoch [3210/10000], loss: 0.22113 acc: 0.98667 val_loss: 0.22023, val_acc: 0.96000\n",
      "Epoch [3220/10000], loss: 0.22079 acc: 0.98667 val_loss: 0.21992, val_acc: 0.96000\n",
      "Epoch [3230/10000], loss: 0.22045 acc: 0.98667 val_loss: 0.21961, val_acc: 0.96000\n",
      "Epoch [3240/10000], loss: 0.22011 acc: 0.98667 val_loss: 0.21930, val_acc: 0.96000\n",
      "Epoch [3250/10000], loss: 0.21977 acc: 0.98667 val_loss: 0.21899, val_acc: 0.96000\n",
      "Epoch [3260/10000], loss: 0.21943 acc: 0.98667 val_loss: 0.21869, val_acc: 0.96000\n",
      "Epoch [3270/10000], loss: 0.21910 acc: 0.98667 val_loss: 0.21838, val_acc: 0.96000\n",
      "Epoch [3280/10000], loss: 0.21876 acc: 0.98667 val_loss: 0.21808, val_acc: 0.96000\n",
      "Epoch [3290/10000], loss: 0.21843 acc: 0.98667 val_loss: 0.21778, val_acc: 0.96000\n",
      "Epoch [3300/10000], loss: 0.21810 acc: 0.98667 val_loss: 0.21747, val_acc: 0.96000\n",
      "Epoch [3310/10000], loss: 0.21777 acc: 0.98667 val_loss: 0.21717, val_acc: 0.96000\n",
      "Epoch [3320/10000], loss: 0.21744 acc: 0.98667 val_loss: 0.21688, val_acc: 0.96000\n",
      "Epoch [3330/10000], loss: 0.21711 acc: 0.98667 val_loss: 0.21658, val_acc: 0.96000\n",
      "Epoch [3340/10000], loss: 0.21679 acc: 0.98667 val_loss: 0.21628, val_acc: 0.96000\n",
      "Epoch [3350/10000], loss: 0.21646 acc: 0.98667 val_loss: 0.21599, val_acc: 0.96000\n",
      "Epoch [3360/10000], loss: 0.21614 acc: 0.98667 val_loss: 0.21570, val_acc: 0.96000\n",
      "Epoch [3370/10000], loss: 0.21582 acc: 0.98667 val_loss: 0.21540, val_acc: 0.96000\n",
      "Epoch [3380/10000], loss: 0.21550 acc: 0.98667 val_loss: 0.21511, val_acc: 0.96000\n",
      "Epoch [3390/10000], loss: 0.21518 acc: 0.98667 val_loss: 0.21482, val_acc: 0.96000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3400/10000], loss: 0.21487 acc: 0.98667 val_loss: 0.21454, val_acc: 0.96000\n",
      "Epoch [3410/10000], loss: 0.21455 acc: 0.98667 val_loss: 0.21425, val_acc: 0.96000\n",
      "Epoch [3420/10000], loss: 0.21424 acc: 0.98667 val_loss: 0.21397, val_acc: 0.96000\n",
      "Epoch [3430/10000], loss: 0.21392 acc: 0.98667 val_loss: 0.21368, val_acc: 0.96000\n",
      "Epoch [3440/10000], loss: 0.21361 acc: 0.98667 val_loss: 0.21340, val_acc: 0.96000\n",
      "Epoch [3450/10000], loss: 0.21330 acc: 0.98667 val_loss: 0.21312, val_acc: 0.96000\n",
      "Epoch [3460/10000], loss: 0.21299 acc: 0.98667 val_loss: 0.21284, val_acc: 0.96000\n",
      "Epoch [3470/10000], loss: 0.21268 acc: 0.98667 val_loss: 0.21256, val_acc: 0.96000\n",
      "Epoch [3480/10000], loss: 0.21238 acc: 0.98667 val_loss: 0.21228, val_acc: 0.96000\n",
      "Epoch [3490/10000], loss: 0.21207 acc: 0.98667 val_loss: 0.21200, val_acc: 0.96000\n",
      "Epoch [3500/10000], loss: 0.21177 acc: 0.98667 val_loss: 0.21173, val_acc: 0.96000\n",
      "Epoch [3510/10000], loss: 0.21146 acc: 0.98667 val_loss: 0.21145, val_acc: 0.96000\n",
      "Epoch [3520/10000], loss: 0.21116 acc: 0.98667 val_loss: 0.21118, val_acc: 0.96000\n",
      "Epoch [3530/10000], loss: 0.21086 acc: 0.98667 val_loss: 0.21091, val_acc: 0.96000\n",
      "Epoch [3540/10000], loss: 0.21056 acc: 0.98667 val_loss: 0.21064, val_acc: 0.96000\n",
      "Epoch [3550/10000], loss: 0.21026 acc: 0.98667 val_loss: 0.21037, val_acc: 0.96000\n",
      "Epoch [3560/10000], loss: 0.20997 acc: 0.98667 val_loss: 0.21010, val_acc: 0.96000\n",
      "Epoch [3570/10000], loss: 0.20967 acc: 0.98667 val_loss: 0.20983, val_acc: 0.96000\n",
      "Epoch [3580/10000], loss: 0.20938 acc: 0.98667 val_loss: 0.20956, val_acc: 0.96000\n",
      "Epoch [3590/10000], loss: 0.20909 acc: 0.98667 val_loss: 0.20930, val_acc: 0.96000\n",
      "Epoch [3600/10000], loss: 0.20879 acc: 0.98667 val_loss: 0.20903, val_acc: 0.96000\n",
      "Epoch [3610/10000], loss: 0.20850 acc: 0.98667 val_loss: 0.20877, val_acc: 0.96000\n",
      "Epoch [3620/10000], loss: 0.20821 acc: 0.98667 val_loss: 0.20851, val_acc: 0.96000\n",
      "Epoch [3630/10000], loss: 0.20793 acc: 0.98667 val_loss: 0.20825, val_acc: 0.96000\n",
      "Epoch [3640/10000], loss: 0.20764 acc: 0.98667 val_loss: 0.20799, val_acc: 0.96000\n",
      "Epoch [3650/10000], loss: 0.20735 acc: 0.98667 val_loss: 0.20773, val_acc: 0.96000\n",
      "Epoch [3660/10000], loss: 0.20707 acc: 0.98667 val_loss: 0.20747, val_acc: 0.96000\n",
      "Epoch [3670/10000], loss: 0.20678 acc: 0.98667 val_loss: 0.20721, val_acc: 0.96000\n",
      "Epoch [3680/10000], loss: 0.20650 acc: 0.98667 val_loss: 0.20696, val_acc: 0.96000\n",
      "Epoch [3690/10000], loss: 0.20622 acc: 0.98667 val_loss: 0.20670, val_acc: 0.96000\n",
      "Epoch [3700/10000], loss: 0.20594 acc: 0.98667 val_loss: 0.20645, val_acc: 0.96000\n",
      "Epoch [3710/10000], loss: 0.20566 acc: 0.98667 val_loss: 0.20620, val_acc: 0.96000\n",
      "Epoch [3720/10000], loss: 0.20538 acc: 0.98667 val_loss: 0.20595, val_acc: 0.96000\n",
      "Epoch [3730/10000], loss: 0.20511 acc: 0.98667 val_loss: 0.20570, val_acc: 0.96000\n",
      "Epoch [3740/10000], loss: 0.20483 acc: 0.98667 val_loss: 0.20545, val_acc: 0.96000\n",
      "Epoch [3750/10000], loss: 0.20455 acc: 0.98667 val_loss: 0.20520, val_acc: 0.96000\n",
      "Epoch [3760/10000], loss: 0.20428 acc: 0.98667 val_loss: 0.20495, val_acc: 0.96000\n",
      "Epoch [3770/10000], loss: 0.20401 acc: 0.98667 val_loss: 0.20471, val_acc: 0.96000\n",
      "Epoch [3780/10000], loss: 0.20374 acc: 0.98667 val_loss: 0.20446, val_acc: 0.96000\n",
      "Epoch [3790/10000], loss: 0.20347 acc: 0.98667 val_loss: 0.20422, val_acc: 0.96000\n",
      "Epoch [3800/10000], loss: 0.20320 acc: 0.98667 val_loss: 0.20397, val_acc: 0.96000\n",
      "Epoch [3810/10000], loss: 0.20293 acc: 0.98667 val_loss: 0.20373, val_acc: 0.96000\n",
      "Epoch [3820/10000], loss: 0.20266 acc: 0.98667 val_loss: 0.20349, val_acc: 0.96000\n",
      "Epoch [3830/10000], loss: 0.20239 acc: 0.98667 val_loss: 0.20325, val_acc: 0.96000\n",
      "Epoch [3840/10000], loss: 0.20213 acc: 0.98667 val_loss: 0.20301, val_acc: 0.96000\n",
      "Epoch [3850/10000], loss: 0.20186 acc: 0.98667 val_loss: 0.20277, val_acc: 0.96000\n",
      "Epoch [3860/10000], loss: 0.20160 acc: 0.98667 val_loss: 0.20253, val_acc: 0.96000\n",
      "Epoch [3870/10000], loss: 0.20134 acc: 0.98667 val_loss: 0.20230, val_acc: 0.96000\n",
      "Epoch [3880/10000], loss: 0.20108 acc: 0.98667 val_loss: 0.20206, val_acc: 0.96000\n",
      "Epoch [3890/10000], loss: 0.20082 acc: 0.98667 val_loss: 0.20183, val_acc: 0.96000\n",
      "Epoch [3900/10000], loss: 0.20056 acc: 0.98667 val_loss: 0.20159, val_acc: 0.96000\n",
      "Epoch [3910/10000], loss: 0.20030 acc: 0.98667 val_loss: 0.20136, val_acc: 0.96000\n",
      "Epoch [3920/10000], loss: 0.20004 acc: 0.98667 val_loss: 0.20113, val_acc: 0.96000\n",
      "Epoch [3930/10000], loss: 0.19979 acc: 0.98667 val_loss: 0.20090, val_acc: 0.96000\n",
      "Epoch [3940/10000], loss: 0.19953 acc: 0.98667 val_loss: 0.20067, val_acc: 0.96000\n",
      "Epoch [3950/10000], loss: 0.19928 acc: 0.98667 val_loss: 0.20044, val_acc: 0.96000\n",
      "Epoch [3960/10000], loss: 0.19902 acc: 0.98667 val_loss: 0.20021, val_acc: 0.96000\n",
      "Epoch [3970/10000], loss: 0.19877 acc: 0.98667 val_loss: 0.19998, val_acc: 0.96000\n",
      "Epoch [3980/10000], loss: 0.19852 acc: 0.98667 val_loss: 0.19976, val_acc: 0.96000\n",
      "Epoch [3990/10000], loss: 0.19827 acc: 0.98667 val_loss: 0.19953, val_acc: 0.96000\n",
      "Epoch [4000/10000], loss: 0.19802 acc: 0.98667 val_loss: 0.19931, val_acc: 0.96000\n",
      "Epoch [4010/10000], loss: 0.19777 acc: 0.98667 val_loss: 0.19908, val_acc: 0.96000\n",
      "Epoch [4020/10000], loss: 0.19752 acc: 0.98667 val_loss: 0.19886, val_acc: 0.96000\n",
      "Epoch [4030/10000], loss: 0.19728 acc: 0.98667 val_loss: 0.19864, val_acc: 0.96000\n",
      "Epoch [4040/10000], loss: 0.19703 acc: 0.98667 val_loss: 0.19842, val_acc: 0.96000\n",
      "Epoch [4050/10000], loss: 0.19679 acc: 0.98667 val_loss: 0.19820, val_acc: 0.96000\n",
      "Epoch [4060/10000], loss: 0.19654 acc: 0.98667 val_loss: 0.19798, val_acc: 0.96000\n",
      "Epoch [4070/10000], loss: 0.19630 acc: 0.98667 val_loss: 0.19776, val_acc: 0.96000\n",
      "Epoch [4080/10000], loss: 0.19606 acc: 0.98667 val_loss: 0.19754, val_acc: 0.96000\n",
      "Epoch [4090/10000], loss: 0.19582 acc: 0.98667 val_loss: 0.19732, val_acc: 0.96000\n",
      "Epoch [4100/10000], loss: 0.19557 acc: 0.98667 val_loss: 0.19711, val_acc: 0.96000\n",
      "Epoch [4110/10000], loss: 0.19534 acc: 0.98667 val_loss: 0.19689, val_acc: 0.96000\n",
      "Epoch [4120/10000], loss: 0.19510 acc: 0.98667 val_loss: 0.19668, val_acc: 0.96000\n",
      "Epoch [4130/10000], loss: 0.19486 acc: 0.98667 val_loss: 0.19646, val_acc: 0.96000\n",
      "Epoch [4140/10000], loss: 0.19462 acc: 0.98667 val_loss: 0.19625, val_acc: 0.96000\n",
      "Epoch [4150/10000], loss: 0.19439 acc: 0.98667 val_loss: 0.19604, val_acc: 0.96000\n",
      "Epoch [4160/10000], loss: 0.19415 acc: 0.98667 val_loss: 0.19583, val_acc: 0.96000\n",
      "Epoch [4170/10000], loss: 0.19392 acc: 0.98667 val_loss: 0.19562, val_acc: 0.96000\n",
      "Epoch [4180/10000], loss: 0.19368 acc: 0.98667 val_loss: 0.19541, val_acc: 0.96000\n",
      "Epoch [4190/10000], loss: 0.19345 acc: 0.98667 val_loss: 0.19520, val_acc: 0.96000\n",
      "Epoch [4200/10000], loss: 0.19322 acc: 0.98667 val_loss: 0.19499, val_acc: 0.96000\n",
      "Epoch [4210/10000], loss: 0.19299 acc: 0.98667 val_loss: 0.19478, val_acc: 0.96000\n",
      "Epoch [4220/10000], loss: 0.19276 acc: 0.98667 val_loss: 0.19457, val_acc: 0.96000\n",
      "Epoch [4230/10000], loss: 0.19253 acc: 0.98667 val_loss: 0.19437, val_acc: 0.96000\n",
      "Epoch [4240/10000], loss: 0.19230 acc: 0.98667 val_loss: 0.19416, val_acc: 0.96000\n",
      "Epoch [4250/10000], loss: 0.19207 acc: 0.98667 val_loss: 0.19396, val_acc: 0.96000\n",
      "Epoch [4260/10000], loss: 0.19184 acc: 0.98667 val_loss: 0.19376, val_acc: 0.96000\n",
      "Epoch [4270/10000], loss: 0.19162 acc: 0.98667 val_loss: 0.19355, val_acc: 0.96000\n",
      "Epoch [4280/10000], loss: 0.19139 acc: 0.98667 val_loss: 0.19335, val_acc: 0.96000\n",
      "Epoch [4290/10000], loss: 0.19117 acc: 0.98667 val_loss: 0.19315, val_acc: 0.96000\n",
      "Epoch [4300/10000], loss: 0.19094 acc: 0.98667 val_loss: 0.19295, val_acc: 0.96000\n",
      "Epoch [4310/10000], loss: 0.19072 acc: 0.98667 val_loss: 0.19275, val_acc: 0.96000\n",
      "Epoch [4320/10000], loss: 0.19050 acc: 0.98667 val_loss: 0.19255, val_acc: 0.96000\n",
      "Epoch [4330/10000], loss: 0.19028 acc: 0.98667 val_loss: 0.19235, val_acc: 0.96000\n",
      "Epoch [4340/10000], loss: 0.19006 acc: 0.98667 val_loss: 0.19215, val_acc: 0.96000\n",
      "Epoch [4350/10000], loss: 0.18984 acc: 0.98667 val_loss: 0.19196, val_acc: 0.96000\n",
      "Epoch [4360/10000], loss: 0.18962 acc: 0.98667 val_loss: 0.19176, val_acc: 0.96000\n",
      "Epoch [4370/10000], loss: 0.18940 acc: 0.98667 val_loss: 0.19156, val_acc: 0.96000\n",
      "Epoch [4380/10000], loss: 0.18918 acc: 0.98667 val_loss: 0.19137, val_acc: 0.96000\n",
      "Epoch [4390/10000], loss: 0.18897 acc: 0.98667 val_loss: 0.19118, val_acc: 0.96000\n",
      "Epoch [4400/10000], loss: 0.18875 acc: 0.98667 val_loss: 0.19098, val_acc: 0.96000\n",
      "Epoch [4410/10000], loss: 0.18853 acc: 0.98667 val_loss: 0.19079, val_acc: 0.96000\n",
      "Epoch [4420/10000], loss: 0.18832 acc: 0.98667 val_loss: 0.19060, val_acc: 0.96000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4430/10000], loss: 0.18811 acc: 0.98667 val_loss: 0.19041, val_acc: 0.96000\n",
      "Epoch [4440/10000], loss: 0.18789 acc: 0.98667 val_loss: 0.19021, val_acc: 0.96000\n",
      "Epoch [4450/10000], loss: 0.18768 acc: 0.98667 val_loss: 0.19002, val_acc: 0.96000\n",
      "Epoch [4460/10000], loss: 0.18747 acc: 0.98667 val_loss: 0.18984, val_acc: 0.96000\n",
      "Epoch [4470/10000], loss: 0.18726 acc: 0.98667 val_loss: 0.18965, val_acc: 0.96000\n",
      "Epoch [4480/10000], loss: 0.18705 acc: 0.98667 val_loss: 0.18946, val_acc: 0.96000\n",
      "Epoch [4490/10000], loss: 0.18684 acc: 0.98667 val_loss: 0.18927, val_acc: 0.96000\n",
      "Epoch [4500/10000], loss: 0.18663 acc: 0.98667 val_loss: 0.18908, val_acc: 0.96000\n",
      "Epoch [4510/10000], loss: 0.18642 acc: 0.98667 val_loss: 0.18890, val_acc: 0.96000\n",
      "Epoch [4520/10000], loss: 0.18622 acc: 0.98667 val_loss: 0.18871, val_acc: 0.96000\n",
      "Epoch [4530/10000], loss: 0.18601 acc: 0.98667 val_loss: 0.18853, val_acc: 0.96000\n",
      "Epoch [4540/10000], loss: 0.18580 acc: 0.98667 val_loss: 0.18834, val_acc: 0.96000\n",
      "Epoch [4550/10000], loss: 0.18560 acc: 0.98667 val_loss: 0.18816, val_acc: 0.96000\n",
      "Epoch [4560/10000], loss: 0.18539 acc: 0.98667 val_loss: 0.18798, val_acc: 0.96000\n",
      "Epoch [4570/10000], loss: 0.18519 acc: 0.98667 val_loss: 0.18780, val_acc: 0.96000\n",
      "Epoch [4580/10000], loss: 0.18499 acc: 0.98667 val_loss: 0.18761, val_acc: 0.96000\n",
      "Epoch [4590/10000], loss: 0.18478 acc: 0.98667 val_loss: 0.18743, val_acc: 0.96000\n",
      "Epoch [4600/10000], loss: 0.18458 acc: 0.98667 val_loss: 0.18725, val_acc: 0.96000\n",
      "Epoch [4610/10000], loss: 0.18438 acc: 0.98667 val_loss: 0.18707, val_acc: 0.96000\n",
      "Epoch [4620/10000], loss: 0.18418 acc: 0.98667 val_loss: 0.18690, val_acc: 0.96000\n",
      "Epoch [4630/10000], loss: 0.18398 acc: 0.98667 val_loss: 0.18672, val_acc: 0.96000\n",
      "Epoch [4640/10000], loss: 0.18378 acc: 0.98667 val_loss: 0.18654, val_acc: 0.96000\n",
      "Epoch [4650/10000], loss: 0.18358 acc: 0.98667 val_loss: 0.18636, val_acc: 0.96000\n",
      "Epoch [4660/10000], loss: 0.18339 acc: 0.98667 val_loss: 0.18619, val_acc: 0.96000\n",
      "Epoch [4670/10000], loss: 0.18319 acc: 0.98667 val_loss: 0.18601, val_acc: 0.96000\n",
      "Epoch [4680/10000], loss: 0.18299 acc: 0.98667 val_loss: 0.18583, val_acc: 0.96000\n",
      "Epoch [4690/10000], loss: 0.18280 acc: 0.98667 val_loss: 0.18566, val_acc: 0.96000\n",
      "Epoch [4700/10000], loss: 0.18260 acc: 0.98667 val_loss: 0.18549, val_acc: 0.96000\n",
      "Epoch [4710/10000], loss: 0.18241 acc: 0.98667 val_loss: 0.18531, val_acc: 0.96000\n",
      "Epoch [4720/10000], loss: 0.18221 acc: 0.98667 val_loss: 0.18514, val_acc: 0.96000\n",
      "Epoch [4730/10000], loss: 0.18202 acc: 0.98667 val_loss: 0.18497, val_acc: 0.96000\n",
      "Epoch [4740/10000], loss: 0.18183 acc: 0.98667 val_loss: 0.18480, val_acc: 0.96000\n",
      "Epoch [4750/10000], loss: 0.18164 acc: 0.98667 val_loss: 0.18462, val_acc: 0.96000\n",
      "Epoch [4760/10000], loss: 0.18144 acc: 0.98667 val_loss: 0.18445, val_acc: 0.96000\n",
      "Epoch [4770/10000], loss: 0.18125 acc: 0.98667 val_loss: 0.18428, val_acc: 0.96000\n",
      "Epoch [4780/10000], loss: 0.18106 acc: 0.98667 val_loss: 0.18411, val_acc: 0.96000\n",
      "Epoch [4790/10000], loss: 0.18087 acc: 0.98667 val_loss: 0.18395, val_acc: 0.96000\n",
      "Epoch [4800/10000], loss: 0.18068 acc: 0.98667 val_loss: 0.18378, val_acc: 0.96000\n",
      "Epoch [4810/10000], loss: 0.18050 acc: 0.98667 val_loss: 0.18361, val_acc: 0.96000\n",
      "Epoch [4820/10000], loss: 0.18031 acc: 0.98667 val_loss: 0.18344, val_acc: 0.96000\n",
      "Epoch [4830/10000], loss: 0.18012 acc: 0.98667 val_loss: 0.18328, val_acc: 0.96000\n",
      "Epoch [4840/10000], loss: 0.17994 acc: 0.98667 val_loss: 0.18311, val_acc: 0.96000\n",
      "Epoch [4850/10000], loss: 0.17975 acc: 0.98667 val_loss: 0.18294, val_acc: 0.96000\n",
      "Epoch [4860/10000], loss: 0.17956 acc: 0.98667 val_loss: 0.18278, val_acc: 0.96000\n",
      "Epoch [4870/10000], loss: 0.17938 acc: 0.98667 val_loss: 0.18261, val_acc: 0.96000\n",
      "Epoch [4880/10000], loss: 0.17920 acc: 0.98667 val_loss: 0.18245, val_acc: 0.96000\n",
      "Epoch [4890/10000], loss: 0.17901 acc: 0.98667 val_loss: 0.18229, val_acc: 0.96000\n",
      "Epoch [4900/10000], loss: 0.17883 acc: 0.98667 val_loss: 0.18212, val_acc: 0.96000\n",
      "Epoch [4910/10000], loss: 0.17865 acc: 0.98667 val_loss: 0.18196, val_acc: 0.96000\n",
      "Epoch [4920/10000], loss: 0.17846 acc: 0.98667 val_loss: 0.18180, val_acc: 0.96000\n",
      "Epoch [4930/10000], loss: 0.17828 acc: 0.98667 val_loss: 0.18164, val_acc: 0.96000\n",
      "Epoch [4940/10000], loss: 0.17810 acc: 0.98667 val_loss: 0.18148, val_acc: 0.96000\n",
      "Epoch [4950/10000], loss: 0.17792 acc: 0.98667 val_loss: 0.18132, val_acc: 0.96000\n",
      "Epoch [4960/10000], loss: 0.17774 acc: 0.98667 val_loss: 0.18116, val_acc: 0.96000\n",
      "Epoch [4970/10000], loss: 0.17756 acc: 0.98667 val_loss: 0.18100, val_acc: 0.96000\n",
      "Epoch [4980/10000], loss: 0.17739 acc: 0.98667 val_loss: 0.18084, val_acc: 0.96000\n",
      "Epoch [4990/10000], loss: 0.17721 acc: 0.98667 val_loss: 0.18068, val_acc: 0.96000\n",
      "Epoch [5000/10000], loss: 0.17703 acc: 0.98667 val_loss: 0.18053, val_acc: 0.96000\n",
      "Epoch [5010/10000], loss: 0.17685 acc: 0.98667 val_loss: 0.18037, val_acc: 0.96000\n",
      "Epoch [5020/10000], loss: 0.17668 acc: 0.98667 val_loss: 0.18021, val_acc: 0.96000\n",
      "Epoch [5030/10000], loss: 0.17650 acc: 0.98667 val_loss: 0.18006, val_acc: 0.96000\n",
      "Epoch [5040/10000], loss: 0.17633 acc: 0.98667 val_loss: 0.17990, val_acc: 0.96000\n",
      "Epoch [5050/10000], loss: 0.17615 acc: 0.98667 val_loss: 0.17975, val_acc: 0.96000\n",
      "Epoch [5060/10000], loss: 0.17598 acc: 0.98667 val_loss: 0.17959, val_acc: 0.96000\n",
      "Epoch [5070/10000], loss: 0.17581 acc: 0.98667 val_loss: 0.17944, val_acc: 0.96000\n",
      "Epoch [5080/10000], loss: 0.17563 acc: 0.98667 val_loss: 0.17928, val_acc: 0.96000\n",
      "Epoch [5090/10000], loss: 0.17546 acc: 0.98667 val_loss: 0.17913, val_acc: 0.96000\n",
      "Epoch [5100/10000], loss: 0.17529 acc: 0.98667 val_loss: 0.17898, val_acc: 0.96000\n",
      "Epoch [5110/10000], loss: 0.17512 acc: 0.98667 val_loss: 0.17883, val_acc: 0.96000\n",
      "Epoch [5120/10000], loss: 0.17495 acc: 0.98667 val_loss: 0.17867, val_acc: 0.96000\n",
      "Epoch [5130/10000], loss: 0.17478 acc: 0.98667 val_loss: 0.17852, val_acc: 0.96000\n",
      "Epoch [5140/10000], loss: 0.17461 acc: 0.98667 val_loss: 0.17837, val_acc: 0.96000\n",
      "Epoch [5150/10000], loss: 0.17444 acc: 0.98667 val_loss: 0.17822, val_acc: 0.96000\n",
      "Epoch [5160/10000], loss: 0.17427 acc: 0.98667 val_loss: 0.17807, val_acc: 0.96000\n",
      "Epoch [5170/10000], loss: 0.17410 acc: 0.98667 val_loss: 0.17792, val_acc: 0.96000\n",
      "Epoch [5180/10000], loss: 0.17393 acc: 0.98667 val_loss: 0.17778, val_acc: 0.96000\n",
      "Epoch [5190/10000], loss: 0.17377 acc: 0.98667 val_loss: 0.17763, val_acc: 0.96000\n",
      "Epoch [5200/10000], loss: 0.17360 acc: 0.98667 val_loss: 0.17748, val_acc: 0.96000\n",
      "Epoch [5210/10000], loss: 0.17343 acc: 0.98667 val_loss: 0.17733, val_acc: 0.96000\n",
      "Epoch [5220/10000], loss: 0.17327 acc: 0.98667 val_loss: 0.17719, val_acc: 0.96000\n",
      "Epoch [5230/10000], loss: 0.17310 acc: 0.98667 val_loss: 0.17704, val_acc: 0.96000\n",
      "Epoch [5240/10000], loss: 0.17294 acc: 0.98667 val_loss: 0.17689, val_acc: 0.96000\n",
      "Epoch [5250/10000], loss: 0.17277 acc: 0.98667 val_loss: 0.17675, val_acc: 0.96000\n",
      "Epoch [5260/10000], loss: 0.17261 acc: 0.98667 val_loss: 0.17660, val_acc: 0.96000\n",
      "Epoch [5270/10000], loss: 0.17245 acc: 0.98667 val_loss: 0.17646, val_acc: 0.96000\n",
      "Epoch [5280/10000], loss: 0.17229 acc: 0.98667 val_loss: 0.17631, val_acc: 0.96000\n",
      "Epoch [5290/10000], loss: 0.17212 acc: 0.98667 val_loss: 0.17617, val_acc: 0.96000\n",
      "Epoch [5300/10000], loss: 0.17196 acc: 0.98667 val_loss: 0.17603, val_acc: 0.96000\n",
      "Epoch [5310/10000], loss: 0.17180 acc: 0.98667 val_loss: 0.17588, val_acc: 0.96000\n",
      "Epoch [5320/10000], loss: 0.17164 acc: 0.98667 val_loss: 0.17574, val_acc: 0.96000\n",
      "Epoch [5330/10000], loss: 0.17148 acc: 0.98667 val_loss: 0.17560, val_acc: 0.96000\n",
      "Epoch [5340/10000], loss: 0.17132 acc: 0.98667 val_loss: 0.17546, val_acc: 0.96000\n",
      "Epoch [5350/10000], loss: 0.17116 acc: 0.98667 val_loss: 0.17532, val_acc: 0.96000\n",
      "Epoch [5360/10000], loss: 0.17100 acc: 0.98667 val_loss: 0.17518, val_acc: 0.96000\n",
      "Epoch [5370/10000], loss: 0.17084 acc: 0.98667 val_loss: 0.17504, val_acc: 0.96000\n",
      "Epoch [5380/10000], loss: 0.17068 acc: 0.98667 val_loss: 0.17490, val_acc: 0.96000\n",
      "Epoch [5390/10000], loss: 0.17053 acc: 0.98667 val_loss: 0.17476, val_acc: 0.96000\n",
      "Epoch [5400/10000], loss: 0.17037 acc: 0.98667 val_loss: 0.17462, val_acc: 0.96000\n",
      "Epoch [5410/10000], loss: 0.17021 acc: 0.98667 val_loss: 0.17448, val_acc: 0.96000\n",
      "Epoch [5420/10000], loss: 0.17006 acc: 0.98667 val_loss: 0.17434, val_acc: 0.96000\n",
      "Epoch [5430/10000], loss: 0.16990 acc: 0.98667 val_loss: 0.17421, val_acc: 0.96000\n",
      "Epoch [5440/10000], loss: 0.16975 acc: 0.98667 val_loss: 0.17407, val_acc: 0.96000\n",
      "Epoch [5450/10000], loss: 0.16959 acc: 0.98667 val_loss: 0.17393, val_acc: 0.96000\n",
      "Epoch [5460/10000], loss: 0.16944 acc: 0.98667 val_loss: 0.17380, val_acc: 0.96000\n",
      "Epoch [5470/10000], loss: 0.16928 acc: 0.98667 val_loss: 0.17366, val_acc: 0.96000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5480/10000], loss: 0.16913 acc: 0.98667 val_loss: 0.17352, val_acc: 0.96000\n",
      "Epoch [5490/10000], loss: 0.16898 acc: 0.98667 val_loss: 0.17339, val_acc: 0.96000\n",
      "Epoch [5500/10000], loss: 0.16883 acc: 0.98667 val_loss: 0.17325, val_acc: 0.96000\n",
      "Epoch [5510/10000], loss: 0.16867 acc: 0.98667 val_loss: 0.17312, val_acc: 0.96000\n",
      "Epoch [5520/10000], loss: 0.16852 acc: 0.98667 val_loss: 0.17299, val_acc: 0.96000\n",
      "Epoch [5530/10000], loss: 0.16837 acc: 0.98667 val_loss: 0.17285, val_acc: 0.96000\n",
      "Epoch [5540/10000], loss: 0.16822 acc: 0.98667 val_loss: 0.17272, val_acc: 0.96000\n",
      "Epoch [5550/10000], loss: 0.16807 acc: 0.98667 val_loss: 0.17259, val_acc: 0.96000\n",
      "Epoch [5560/10000], loss: 0.16792 acc: 0.98667 val_loss: 0.17246, val_acc: 0.96000\n",
      "Epoch [5570/10000], loss: 0.16777 acc: 0.98667 val_loss: 0.17232, val_acc: 0.96000\n",
      "Epoch [5580/10000], loss: 0.16762 acc: 0.98667 val_loss: 0.17219, val_acc: 0.96000\n",
      "Epoch [5590/10000], loss: 0.16747 acc: 0.98667 val_loss: 0.17206, val_acc: 0.96000\n",
      "Epoch [5600/10000], loss: 0.16732 acc: 0.98667 val_loss: 0.17193, val_acc: 0.96000\n",
      "Epoch [5610/10000], loss: 0.16718 acc: 0.98667 val_loss: 0.17180, val_acc: 0.96000\n",
      "Epoch [5620/10000], loss: 0.16703 acc: 0.98667 val_loss: 0.17167, val_acc: 0.96000\n",
      "Epoch [5630/10000], loss: 0.16688 acc: 0.98667 val_loss: 0.17154, val_acc: 0.96000\n",
      "Epoch [5640/10000], loss: 0.16674 acc: 0.98667 val_loss: 0.17141, val_acc: 0.96000\n",
      "Epoch [5650/10000], loss: 0.16659 acc: 0.98667 val_loss: 0.17128, val_acc: 0.96000\n",
      "Epoch [5660/10000], loss: 0.16644 acc: 0.98667 val_loss: 0.17115, val_acc: 0.96000\n",
      "Epoch [5670/10000], loss: 0.16630 acc: 0.98667 val_loss: 0.17103, val_acc: 0.96000\n",
      "Epoch [5680/10000], loss: 0.16615 acc: 0.98667 val_loss: 0.17090, val_acc: 0.96000\n",
      "Epoch [5690/10000], loss: 0.16601 acc: 0.98667 val_loss: 0.17077, val_acc: 0.96000\n",
      "Epoch [5700/10000], loss: 0.16587 acc: 0.98667 val_loss: 0.17064, val_acc: 0.96000\n",
      "Epoch [5710/10000], loss: 0.16572 acc: 0.98667 val_loss: 0.17052, val_acc: 0.96000\n",
      "Epoch [5720/10000], loss: 0.16558 acc: 0.98667 val_loss: 0.17039, val_acc: 0.96000\n",
      "Epoch [5730/10000], loss: 0.16544 acc: 0.98667 val_loss: 0.17027, val_acc: 0.96000\n",
      "Epoch [5740/10000], loss: 0.16529 acc: 0.98667 val_loss: 0.17014, val_acc: 0.96000\n",
      "Epoch [5750/10000], loss: 0.16515 acc: 0.98667 val_loss: 0.17001, val_acc: 0.96000\n",
      "Epoch [5760/10000], loss: 0.16501 acc: 0.98667 val_loss: 0.16989, val_acc: 0.96000\n",
      "Epoch [5770/10000], loss: 0.16487 acc: 0.98667 val_loss: 0.16977, val_acc: 0.96000\n",
      "Epoch [5780/10000], loss: 0.16473 acc: 0.98667 val_loss: 0.16964, val_acc: 0.96000\n",
      "Epoch [5790/10000], loss: 0.16459 acc: 0.98667 val_loss: 0.16952, val_acc: 0.96000\n",
      "Epoch [5800/10000], loss: 0.16445 acc: 0.98667 val_loss: 0.16940, val_acc: 0.96000\n",
      "Epoch [5810/10000], loss: 0.16431 acc: 0.98667 val_loss: 0.16927, val_acc: 0.96000\n",
      "Epoch [5820/10000], loss: 0.16417 acc: 0.98667 val_loss: 0.16915, val_acc: 0.96000\n",
      "Epoch [5830/10000], loss: 0.16403 acc: 0.98667 val_loss: 0.16903, val_acc: 0.96000\n",
      "Epoch [5840/10000], loss: 0.16389 acc: 0.98667 val_loss: 0.16891, val_acc: 0.96000\n",
      "Epoch [5850/10000], loss: 0.16375 acc: 0.98667 val_loss: 0.16878, val_acc: 0.96000\n",
      "Epoch [5860/10000], loss: 0.16361 acc: 0.98667 val_loss: 0.16866, val_acc: 0.96000\n",
      "Epoch [5870/10000], loss: 0.16348 acc: 0.98667 val_loss: 0.16854, val_acc: 0.96000\n",
      "Epoch [5880/10000], loss: 0.16334 acc: 0.98667 val_loss: 0.16842, val_acc: 0.96000\n",
      "Epoch [5890/10000], loss: 0.16320 acc: 0.98667 val_loss: 0.16830, val_acc: 0.96000\n",
      "Epoch [5900/10000], loss: 0.16307 acc: 0.98667 val_loss: 0.16818, val_acc: 0.96000\n",
      "Epoch [5910/10000], loss: 0.16293 acc: 0.98667 val_loss: 0.16806, val_acc: 0.96000\n",
      "Epoch [5920/10000], loss: 0.16280 acc: 0.98667 val_loss: 0.16794, val_acc: 0.96000\n",
      "Epoch [5930/10000], loss: 0.16266 acc: 0.98667 val_loss: 0.16782, val_acc: 0.96000\n",
      "Epoch [5940/10000], loss: 0.16253 acc: 0.98667 val_loss: 0.16771, val_acc: 0.96000\n",
      "Epoch [5950/10000], loss: 0.16239 acc: 0.98667 val_loss: 0.16759, val_acc: 0.96000\n",
      "Epoch [5960/10000], loss: 0.16226 acc: 0.98667 val_loss: 0.16747, val_acc: 0.96000\n",
      "Epoch [5970/10000], loss: 0.16212 acc: 0.98667 val_loss: 0.16735, val_acc: 0.96000\n",
      "Epoch [5980/10000], loss: 0.16199 acc: 0.98667 val_loss: 0.16724, val_acc: 0.96000\n",
      "Epoch [5990/10000], loss: 0.16186 acc: 0.98667 val_loss: 0.16712, val_acc: 0.96000\n",
      "Epoch [6000/10000], loss: 0.16172 acc: 0.98667 val_loss: 0.16700, val_acc: 0.96000\n",
      "Epoch [6010/10000], loss: 0.16159 acc: 0.98667 val_loss: 0.16689, val_acc: 0.96000\n",
      "Epoch [6020/10000], loss: 0.16146 acc: 0.98667 val_loss: 0.16677, val_acc: 0.96000\n",
      "Epoch [6030/10000], loss: 0.16133 acc: 0.98667 val_loss: 0.16665, val_acc: 0.96000\n",
      "Epoch [6040/10000], loss: 0.16120 acc: 0.98667 val_loss: 0.16654, val_acc: 0.96000\n",
      "Epoch [6050/10000], loss: 0.16107 acc: 0.98667 val_loss: 0.16642, val_acc: 0.96000\n",
      "Epoch [6060/10000], loss: 0.16093 acc: 0.98667 val_loss: 0.16631, val_acc: 0.96000\n",
      "Epoch [6070/10000], loss: 0.16080 acc: 0.98667 val_loss: 0.16620, val_acc: 0.96000\n",
      "Epoch [6080/10000], loss: 0.16067 acc: 0.98667 val_loss: 0.16608, val_acc: 0.96000\n",
      "Epoch [6090/10000], loss: 0.16055 acc: 0.98667 val_loss: 0.16597, val_acc: 0.96000\n",
      "Epoch [6100/10000], loss: 0.16042 acc: 0.98667 val_loss: 0.16585, val_acc: 0.96000\n",
      "Epoch [6110/10000], loss: 0.16029 acc: 0.98667 val_loss: 0.16574, val_acc: 0.96000\n",
      "Epoch [6120/10000], loss: 0.16016 acc: 0.98667 val_loss: 0.16563, val_acc: 0.96000\n",
      "Epoch [6130/10000], loss: 0.16003 acc: 0.98667 val_loss: 0.16552, val_acc: 0.96000\n",
      "Epoch [6140/10000], loss: 0.15990 acc: 0.98667 val_loss: 0.16540, val_acc: 0.96000\n",
      "Epoch [6150/10000], loss: 0.15978 acc: 0.98667 val_loss: 0.16529, val_acc: 0.96000\n",
      "Epoch [6160/10000], loss: 0.15965 acc: 0.98667 val_loss: 0.16518, val_acc: 0.96000\n",
      "Epoch [6170/10000], loss: 0.15952 acc: 0.98667 val_loss: 0.16507, val_acc: 0.96000\n",
      "Epoch [6180/10000], loss: 0.15939 acc: 0.98667 val_loss: 0.16496, val_acc: 0.96000\n",
      "Epoch [6190/10000], loss: 0.15927 acc: 0.98667 val_loss: 0.16485, val_acc: 0.96000\n",
      "Epoch [6200/10000], loss: 0.15914 acc: 0.98667 val_loss: 0.16474, val_acc: 0.96000\n",
      "Epoch [6210/10000], loss: 0.15902 acc: 0.98667 val_loss: 0.16463, val_acc: 0.96000\n",
      "Epoch [6220/10000], loss: 0.15889 acc: 0.98667 val_loss: 0.16452, val_acc: 0.96000\n",
      "Epoch [6230/10000], loss: 0.15877 acc: 0.98667 val_loss: 0.16441, val_acc: 0.96000\n",
      "Epoch [6240/10000], loss: 0.15864 acc: 0.98667 val_loss: 0.16430, val_acc: 0.96000\n",
      "Epoch [6250/10000], loss: 0.15852 acc: 0.98667 val_loss: 0.16419, val_acc: 0.96000\n",
      "Epoch [6260/10000], loss: 0.15839 acc: 0.98667 val_loss: 0.16408, val_acc: 0.96000\n",
      "Epoch [6270/10000], loss: 0.15827 acc: 0.98667 val_loss: 0.16398, val_acc: 0.96000\n",
      "Epoch [6280/10000], loss: 0.15815 acc: 0.98667 val_loss: 0.16387, val_acc: 0.96000\n",
      "Epoch [6290/10000], loss: 0.15802 acc: 0.98667 val_loss: 0.16376, val_acc: 0.96000\n",
      "Epoch [6300/10000], loss: 0.15790 acc: 0.98667 val_loss: 0.16365, val_acc: 0.96000\n",
      "Epoch [6310/10000], loss: 0.15778 acc: 0.98667 val_loss: 0.16355, val_acc: 0.96000\n",
      "Epoch [6320/10000], loss: 0.15766 acc: 0.98667 val_loss: 0.16344, val_acc: 0.96000\n",
      "Epoch [6330/10000], loss: 0.15754 acc: 0.98667 val_loss: 0.16333, val_acc: 0.96000\n",
      "Epoch [6340/10000], loss: 0.15741 acc: 0.98667 val_loss: 0.16323, val_acc: 0.96000\n",
      "Epoch [6350/10000], loss: 0.15729 acc: 0.98667 val_loss: 0.16312, val_acc: 0.96000\n",
      "Epoch [6360/10000], loss: 0.15717 acc: 0.98667 val_loss: 0.16302, val_acc: 0.96000\n",
      "Epoch [6370/10000], loss: 0.15705 acc: 0.98667 val_loss: 0.16291, val_acc: 0.96000\n",
      "Epoch [6380/10000], loss: 0.15693 acc: 0.98667 val_loss: 0.16281, val_acc: 0.96000\n",
      "Epoch [6390/10000], loss: 0.15681 acc: 0.98667 val_loss: 0.16270, val_acc: 0.96000\n",
      "Epoch [6400/10000], loss: 0.15669 acc: 0.98667 val_loss: 0.16260, val_acc: 0.96000\n",
      "Epoch [6410/10000], loss: 0.15657 acc: 0.98667 val_loss: 0.16249, val_acc: 0.96000\n",
      "Epoch [6420/10000], loss: 0.15645 acc: 0.98667 val_loss: 0.16239, val_acc: 0.96000\n",
      "Epoch [6430/10000], loss: 0.15634 acc: 0.98667 val_loss: 0.16228, val_acc: 0.96000\n",
      "Epoch [6440/10000], loss: 0.15622 acc: 0.98667 val_loss: 0.16218, val_acc: 0.96000\n",
      "Epoch [6450/10000], loss: 0.15610 acc: 0.98667 val_loss: 0.16208, val_acc: 0.96000\n",
      "Epoch [6460/10000], loss: 0.15598 acc: 0.98667 val_loss: 0.16198, val_acc: 0.96000\n",
      "Epoch [6470/10000], loss: 0.15586 acc: 0.98667 val_loss: 0.16187, val_acc: 0.96000\n",
      "Epoch [6480/10000], loss: 0.15575 acc: 0.98667 val_loss: 0.16177, val_acc: 0.96000\n",
      "Epoch [6490/10000], loss: 0.15563 acc: 0.98667 val_loss: 0.16167, val_acc: 0.96000\n",
      "Epoch [6500/10000], loss: 0.15551 acc: 0.98667 val_loss: 0.16157, val_acc: 0.96000\n",
      "Epoch [6510/10000], loss: 0.15540 acc: 0.98667 val_loss: 0.16147, val_acc: 0.96000\n",
      "Epoch [6520/10000], loss: 0.15528 acc: 0.98667 val_loss: 0.16136, val_acc: 0.96000\n",
      "Epoch [6530/10000], loss: 0.15516 acc: 0.98667 val_loss: 0.16126, val_acc: 0.96000\n",
      "Epoch [6540/10000], loss: 0.15505 acc: 0.98667 val_loss: 0.16116, val_acc: 0.96000\n",
      "Epoch [6550/10000], loss: 0.15493 acc: 0.98667 val_loss: 0.16106, val_acc: 0.96000\n",
      "Epoch [6560/10000], loss: 0.15482 acc: 0.98667 val_loss: 0.16096, val_acc: 0.96000\n",
      "Epoch [6570/10000], loss: 0.15470 acc: 0.98667 val_loss: 0.16086, val_acc: 0.96000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6580/10000], loss: 0.15459 acc: 0.98667 val_loss: 0.16076, val_acc: 0.96000\n",
      "Epoch [6590/10000], loss: 0.15448 acc: 0.98667 val_loss: 0.16066, val_acc: 0.96000\n",
      "Epoch [6600/10000], loss: 0.15436 acc: 0.98667 val_loss: 0.16056, val_acc: 0.96000\n",
      "Epoch [6610/10000], loss: 0.15425 acc: 0.98667 val_loss: 0.16047, val_acc: 0.96000\n",
      "Epoch [6620/10000], loss: 0.15414 acc: 0.98667 val_loss: 0.16037, val_acc: 0.96000\n",
      "Epoch [6630/10000], loss: 0.15402 acc: 0.98667 val_loss: 0.16027, val_acc: 0.96000\n",
      "Epoch [6640/10000], loss: 0.15391 acc: 0.98667 val_loss: 0.16017, val_acc: 0.96000\n",
      "Epoch [6650/10000], loss: 0.15380 acc: 0.98667 val_loss: 0.16007, val_acc: 0.96000\n",
      "Epoch [6660/10000], loss: 0.15369 acc: 0.98667 val_loss: 0.15998, val_acc: 0.96000\n",
      "Epoch [6670/10000], loss: 0.15357 acc: 0.98667 val_loss: 0.15988, val_acc: 0.96000\n",
      "Epoch [6680/10000], loss: 0.15346 acc: 0.98667 val_loss: 0.15978, val_acc: 0.96000\n",
      "Epoch [6690/10000], loss: 0.15335 acc: 0.98667 val_loss: 0.15968, val_acc: 0.96000\n",
      "Epoch [6700/10000], loss: 0.15324 acc: 0.98667 val_loss: 0.15959, val_acc: 0.96000\n",
      "Epoch [6710/10000], loss: 0.15313 acc: 0.98667 val_loss: 0.15949, val_acc: 0.96000\n",
      "Epoch [6720/10000], loss: 0.15302 acc: 0.98667 val_loss: 0.15939, val_acc: 0.96000\n",
      "Epoch [6730/10000], loss: 0.15291 acc: 0.98667 val_loss: 0.15930, val_acc: 0.96000\n",
      "Epoch [6740/10000], loss: 0.15280 acc: 0.98667 val_loss: 0.15920, val_acc: 0.96000\n",
      "Epoch [6750/10000], loss: 0.15269 acc: 0.98667 val_loss: 0.15911, val_acc: 0.96000\n",
      "Epoch [6760/10000], loss: 0.15258 acc: 0.98667 val_loss: 0.15901, val_acc: 0.96000\n",
      "Epoch [6770/10000], loss: 0.15247 acc: 0.98667 val_loss: 0.15892, val_acc: 0.96000\n",
      "Epoch [6780/10000], loss: 0.15236 acc: 0.98667 val_loss: 0.15882, val_acc: 0.96000\n",
      "Epoch [6790/10000], loss: 0.15225 acc: 0.98667 val_loss: 0.15873, val_acc: 0.96000\n",
      "Epoch [6800/10000], loss: 0.15215 acc: 0.98667 val_loss: 0.15863, val_acc: 0.96000\n",
      "Epoch [6810/10000], loss: 0.15204 acc: 0.98667 val_loss: 0.15854, val_acc: 0.96000\n",
      "Epoch [6820/10000], loss: 0.15193 acc: 0.98667 val_loss: 0.15845, val_acc: 0.96000\n",
      "Epoch [6830/10000], loss: 0.15182 acc: 0.98667 val_loss: 0.15835, val_acc: 0.96000\n",
      "Epoch [6840/10000], loss: 0.15171 acc: 0.98667 val_loss: 0.15826, val_acc: 0.96000\n",
      "Epoch [6850/10000], loss: 0.15161 acc: 0.98667 val_loss: 0.15817, val_acc: 0.96000\n",
      "Epoch [6860/10000], loss: 0.15150 acc: 0.98667 val_loss: 0.15807, val_acc: 0.96000\n",
      "Epoch [6870/10000], loss: 0.15139 acc: 0.98667 val_loss: 0.15798, val_acc: 0.96000\n",
      "Epoch [6880/10000], loss: 0.15129 acc: 0.98667 val_loss: 0.15789, val_acc: 0.96000\n",
      "Epoch [6890/10000], loss: 0.15118 acc: 0.98667 val_loss: 0.15780, val_acc: 0.96000\n",
      "Epoch [6900/10000], loss: 0.15108 acc: 0.98667 val_loss: 0.15771, val_acc: 0.96000\n",
      "Epoch [6910/10000], loss: 0.15097 acc: 0.98667 val_loss: 0.15761, val_acc: 0.96000\n",
      "Epoch [6920/10000], loss: 0.15086 acc: 0.98667 val_loss: 0.15752, val_acc: 0.96000\n",
      "Epoch [6930/10000], loss: 0.15076 acc: 0.98667 val_loss: 0.15743, val_acc: 0.96000\n",
      "Epoch [6940/10000], loss: 0.15065 acc: 0.98667 val_loss: 0.15734, val_acc: 0.96000\n",
      "Epoch [6950/10000], loss: 0.15055 acc: 0.98667 val_loss: 0.15725, val_acc: 0.96000\n",
      "Epoch [6960/10000], loss: 0.15045 acc: 0.98667 val_loss: 0.15716, val_acc: 0.96000\n",
      "Epoch [6970/10000], loss: 0.15034 acc: 0.98667 val_loss: 0.15707, val_acc: 0.96000\n",
      "Epoch [6980/10000], loss: 0.15024 acc: 0.98667 val_loss: 0.15698, val_acc: 0.96000\n",
      "Epoch [6990/10000], loss: 0.15013 acc: 0.98667 val_loss: 0.15689, val_acc: 0.96000\n",
      "Epoch [7000/10000], loss: 0.15003 acc: 0.98667 val_loss: 0.15680, val_acc: 0.96000\n",
      "Epoch [7010/10000], loss: 0.14993 acc: 0.98667 val_loss: 0.15671, val_acc: 0.96000\n",
      "Epoch [7020/10000], loss: 0.14983 acc: 0.98667 val_loss: 0.15662, val_acc: 0.96000\n",
      "Epoch [7030/10000], loss: 0.14972 acc: 0.98667 val_loss: 0.15653, val_acc: 0.96000\n",
      "Epoch [7040/10000], loss: 0.14962 acc: 0.98667 val_loss: 0.15644, val_acc: 0.96000\n",
      "Epoch [7050/10000], loss: 0.14952 acc: 0.98667 val_loss: 0.15636, val_acc: 0.96000\n",
      "Epoch [7060/10000], loss: 0.14942 acc: 0.98667 val_loss: 0.15627, val_acc: 0.96000\n",
      "Epoch [7070/10000], loss: 0.14931 acc: 0.98667 val_loss: 0.15618, val_acc: 0.96000\n",
      "Epoch [7080/10000], loss: 0.14921 acc: 0.98667 val_loss: 0.15609, val_acc: 0.96000\n",
      "Epoch [7090/10000], loss: 0.14911 acc: 0.98667 val_loss: 0.15600, val_acc: 0.96000\n",
      "Epoch [7100/10000], loss: 0.14901 acc: 0.98667 val_loss: 0.15592, val_acc: 0.96000\n",
      "Epoch [7110/10000], loss: 0.14891 acc: 0.98667 val_loss: 0.15583, val_acc: 0.96000\n",
      "Epoch [7120/10000], loss: 0.14881 acc: 0.98667 val_loss: 0.15574, val_acc: 0.96000\n",
      "Epoch [7130/10000], loss: 0.14871 acc: 0.98667 val_loss: 0.15565, val_acc: 0.96000\n",
      "Epoch [7140/10000], loss: 0.14861 acc: 0.98667 val_loss: 0.15557, val_acc: 0.96000\n",
      "Epoch [7150/10000], loss: 0.14851 acc: 0.98667 val_loss: 0.15548, val_acc: 0.96000\n",
      "Epoch [7160/10000], loss: 0.14841 acc: 0.98667 val_loss: 0.15540, val_acc: 0.96000\n",
      "Epoch [7170/10000], loss: 0.14831 acc: 0.98667 val_loss: 0.15531, val_acc: 0.96000\n",
      "Epoch [7180/10000], loss: 0.14821 acc: 0.98667 val_loss: 0.15522, val_acc: 0.96000\n",
      "Epoch [7190/10000], loss: 0.14811 acc: 0.98667 val_loss: 0.15514, val_acc: 0.96000\n",
      "Epoch [7200/10000], loss: 0.14801 acc: 0.98667 val_loss: 0.15505, val_acc: 0.96000\n",
      "Epoch [7210/10000], loss: 0.14792 acc: 0.98667 val_loss: 0.15497, val_acc: 0.96000\n",
      "Epoch [7220/10000], loss: 0.14782 acc: 0.98667 val_loss: 0.15488, val_acc: 0.96000\n",
      "Epoch [7230/10000], loss: 0.14772 acc: 0.98667 val_loss: 0.15480, val_acc: 0.96000\n",
      "Epoch [7240/10000], loss: 0.14762 acc: 0.98667 val_loss: 0.15471, val_acc: 0.96000\n",
      "Epoch [7250/10000], loss: 0.14752 acc: 0.98667 val_loss: 0.15463, val_acc: 0.96000\n",
      "Epoch [7260/10000], loss: 0.14743 acc: 0.98667 val_loss: 0.15455, val_acc: 0.96000\n",
      "Epoch [7270/10000], loss: 0.14733 acc: 0.98667 val_loss: 0.15446, val_acc: 0.96000\n",
      "Epoch [7280/10000], loss: 0.14723 acc: 0.98667 val_loss: 0.15438, val_acc: 0.96000\n",
      "Epoch [7290/10000], loss: 0.14714 acc: 0.98667 val_loss: 0.15429, val_acc: 0.96000\n",
      "Epoch [7300/10000], loss: 0.14704 acc: 0.98667 val_loss: 0.15421, val_acc: 0.96000\n",
      "Epoch [7310/10000], loss: 0.14694 acc: 0.98667 val_loss: 0.15413, val_acc: 0.96000\n",
      "Epoch [7320/10000], loss: 0.14685 acc: 0.98667 val_loss: 0.15404, val_acc: 0.96000\n",
      "Epoch [7330/10000], loss: 0.14675 acc: 0.98667 val_loss: 0.15396, val_acc: 0.96000\n",
      "Epoch [7340/10000], loss: 0.14666 acc: 0.98667 val_loss: 0.15388, val_acc: 0.96000\n",
      "Epoch [7350/10000], loss: 0.14656 acc: 0.98667 val_loss: 0.15380, val_acc: 0.96000\n",
      "Epoch [7360/10000], loss: 0.14646 acc: 0.98667 val_loss: 0.15371, val_acc: 0.96000\n",
      "Epoch [7370/10000], loss: 0.14637 acc: 0.98667 val_loss: 0.15363, val_acc: 0.96000\n",
      "Epoch [7380/10000], loss: 0.14628 acc: 0.98667 val_loss: 0.15355, val_acc: 0.96000\n",
      "Epoch [7390/10000], loss: 0.14618 acc: 0.98667 val_loss: 0.15347, val_acc: 0.96000\n",
      "Epoch [7400/10000], loss: 0.14609 acc: 0.98667 val_loss: 0.15339, val_acc: 0.96000\n",
      "Epoch [7410/10000], loss: 0.14599 acc: 0.98667 val_loss: 0.15331, val_acc: 0.96000\n",
      "Epoch [7420/10000], loss: 0.14590 acc: 0.98667 val_loss: 0.15323, val_acc: 0.96000\n",
      "Epoch [7430/10000], loss: 0.14580 acc: 0.98667 val_loss: 0.15314, val_acc: 0.96000\n",
      "Epoch [7440/10000], loss: 0.14571 acc: 0.98667 val_loss: 0.15306, val_acc: 0.96000\n",
      "Epoch [7450/10000], loss: 0.14562 acc: 0.98667 val_loss: 0.15298, val_acc: 0.96000\n",
      "Epoch [7460/10000], loss: 0.14552 acc: 0.98667 val_loss: 0.15290, val_acc: 0.96000\n",
      "Epoch [7470/10000], loss: 0.14543 acc: 0.98667 val_loss: 0.15282, val_acc: 0.96000\n",
      "Epoch [7480/10000], loss: 0.14534 acc: 0.98667 val_loss: 0.15274, val_acc: 0.96000\n",
      "Epoch [7490/10000], loss: 0.14525 acc: 0.98667 val_loss: 0.15266, val_acc: 0.96000\n",
      "Epoch [7500/10000], loss: 0.14515 acc: 0.98667 val_loss: 0.15258, val_acc: 0.96000\n",
      "Epoch [7510/10000], loss: 0.14506 acc: 0.98667 val_loss: 0.15250, val_acc: 0.96000\n",
      "Epoch [7520/10000], loss: 0.14497 acc: 0.98667 val_loss: 0.15243, val_acc: 0.96000\n",
      "Epoch [7530/10000], loss: 0.14488 acc: 0.98667 val_loss: 0.15235, val_acc: 0.96000\n",
      "Epoch [7540/10000], loss: 0.14479 acc: 0.98667 val_loss: 0.15227, val_acc: 0.96000\n",
      "Epoch [7550/10000], loss: 0.14470 acc: 0.98667 val_loss: 0.15219, val_acc: 0.96000\n",
      "Epoch [7560/10000], loss: 0.14460 acc: 0.98667 val_loss: 0.15211, val_acc: 0.96000\n",
      "Epoch [7570/10000], loss: 0.14451 acc: 0.98667 val_loss: 0.15203, val_acc: 0.96000\n",
      "Epoch [7580/10000], loss: 0.14442 acc: 0.98667 val_loss: 0.15195, val_acc: 0.96000\n",
      "Epoch [7590/10000], loss: 0.14433 acc: 0.98667 val_loss: 0.15188, val_acc: 0.96000\n",
      "Epoch [7600/10000], loss: 0.14424 acc: 0.98667 val_loss: 0.15180, val_acc: 0.96000\n",
      "Epoch [7610/10000], loss: 0.14415 acc: 0.98667 val_loss: 0.15172, val_acc: 0.96000\n",
      "Epoch [7620/10000], loss: 0.14406 acc: 0.98667 val_loss: 0.15164, val_acc: 0.96000\n",
      "Epoch [7630/10000], loss: 0.14397 acc: 0.98667 val_loss: 0.15157, val_acc: 0.96000\n",
      "Epoch [7640/10000], loss: 0.14388 acc: 0.98667 val_loss: 0.15149, val_acc: 0.96000\n",
      "Epoch [7650/10000], loss: 0.14379 acc: 0.98667 val_loss: 0.15141, val_acc: 0.96000\n",
      "Epoch [7660/10000], loss: 0.14370 acc: 0.98667 val_loss: 0.15134, val_acc: 0.96000\n",
      "Epoch [7670/10000], loss: 0.14362 acc: 0.98667 val_loss: 0.15126, val_acc: 0.96000\n",
      "Epoch [7680/10000], loss: 0.14353 acc: 0.98667 val_loss: 0.15118, val_acc: 0.96000\n",
      "Epoch [7690/10000], loss: 0.14344 acc: 0.98667 val_loss: 0.15111, val_acc: 0.96000\n",
      "Epoch [7700/10000], loss: 0.14335 acc: 0.98667 val_loss: 0.15103, val_acc: 0.96000\n",
      "Epoch [7710/10000], loss: 0.14326 acc: 0.98667 val_loss: 0.15096, val_acc: 0.96000\n",
      "Epoch [7720/10000], loss: 0.14317 acc: 0.98667 val_loss: 0.15088, val_acc: 0.96000\n",
      "Epoch [7730/10000], loss: 0.14309 acc: 0.98667 val_loss: 0.15080, val_acc: 0.96000\n",
      "Epoch [7740/10000], loss: 0.14300 acc: 0.98667 val_loss: 0.15073, val_acc: 0.96000\n",
      "Epoch [7750/10000], loss: 0.14291 acc: 0.98667 val_loss: 0.15065, val_acc: 0.96000\n",
      "Epoch [7760/10000], loss: 0.14282 acc: 0.98667 val_loss: 0.15058, val_acc: 0.96000\n",
      "Epoch [7770/10000], loss: 0.14274 acc: 0.98667 val_loss: 0.15050, val_acc: 0.96000\n",
      "Epoch [7780/10000], loss: 0.14265 acc: 0.98667 val_loss: 0.15043, val_acc: 0.96000\n",
      "Epoch [7790/10000], loss: 0.14256 acc: 0.98667 val_loss: 0.15036, val_acc: 0.96000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7800/10000], loss: 0.14248 acc: 0.98667 val_loss: 0.15028, val_acc: 0.96000\n",
      "Epoch [7810/10000], loss: 0.14239 acc: 0.98667 val_loss: 0.15021, val_acc: 0.96000\n",
      "Epoch [7820/10000], loss: 0.14230 acc: 0.98667 val_loss: 0.15013, val_acc: 0.96000\n",
      "Epoch [7830/10000], loss: 0.14222 acc: 0.98667 val_loss: 0.15006, val_acc: 0.96000\n",
      "Epoch [7840/10000], loss: 0.14213 acc: 0.98667 val_loss: 0.14999, val_acc: 0.96000\n",
      "Epoch [7850/10000], loss: 0.14205 acc: 0.98667 val_loss: 0.14991, val_acc: 0.96000\n",
      "Epoch [7860/10000], loss: 0.14196 acc: 0.98667 val_loss: 0.14984, val_acc: 0.96000\n",
      "Epoch [7870/10000], loss: 0.14188 acc: 0.98667 val_loss: 0.14977, val_acc: 0.96000\n",
      "Epoch [7880/10000], loss: 0.14179 acc: 0.98667 val_loss: 0.14969, val_acc: 0.96000\n",
      "Epoch [7890/10000], loss: 0.14171 acc: 0.98667 val_loss: 0.14962, val_acc: 0.96000\n",
      "Epoch [7900/10000], loss: 0.14162 acc: 0.98667 val_loss: 0.14955, val_acc: 0.96000\n",
      "Epoch [7910/10000], loss: 0.14154 acc: 0.98667 val_loss: 0.14948, val_acc: 0.96000\n",
      "Epoch [7920/10000], loss: 0.14145 acc: 0.98667 val_loss: 0.14940, val_acc: 0.96000\n",
      "Epoch [7930/10000], loss: 0.14137 acc: 0.98667 val_loss: 0.14933, val_acc: 0.96000\n",
      "Epoch [7940/10000], loss: 0.14128 acc: 0.98667 val_loss: 0.14926, val_acc: 0.96000\n",
      "Epoch [7950/10000], loss: 0.14120 acc: 0.98667 val_loss: 0.14919, val_acc: 0.96000\n",
      "Epoch [7960/10000], loss: 0.14112 acc: 0.98667 val_loss: 0.14912, val_acc: 0.96000\n",
      "Epoch [7970/10000], loss: 0.14103 acc: 0.98667 val_loss: 0.14904, val_acc: 0.96000\n",
      "Epoch [7980/10000], loss: 0.14095 acc: 0.98667 val_loss: 0.14897, val_acc: 0.96000\n",
      "Epoch [7990/10000], loss: 0.14087 acc: 0.98667 val_loss: 0.14890, val_acc: 0.96000\n",
      "Epoch [8000/10000], loss: 0.14078 acc: 0.98667 val_loss: 0.14883, val_acc: 0.96000\n",
      "Epoch [8010/10000], loss: 0.14070 acc: 0.98667 val_loss: 0.14876, val_acc: 0.96000\n",
      "Epoch [8020/10000], loss: 0.14062 acc: 0.98667 val_loss: 0.14869, val_acc: 0.96000\n",
      "Epoch [8030/10000], loss: 0.14054 acc: 0.98667 val_loss: 0.14862, val_acc: 0.96000\n",
      "Epoch [8040/10000], loss: 0.14045 acc: 0.98667 val_loss: 0.14855, val_acc: 0.96000\n",
      "Epoch [8050/10000], loss: 0.14037 acc: 0.98667 val_loss: 0.14848, val_acc: 0.96000\n",
      "Epoch [8060/10000], loss: 0.14029 acc: 0.98667 val_loss: 0.14841, val_acc: 0.96000\n",
      "Epoch [8070/10000], loss: 0.14021 acc: 0.98667 val_loss: 0.14834, val_acc: 0.96000\n",
      "Epoch [8080/10000], loss: 0.14013 acc: 0.98667 val_loss: 0.14827, val_acc: 0.96000\n",
      "Epoch [8090/10000], loss: 0.14004 acc: 0.98667 val_loss: 0.14820, val_acc: 0.96000\n",
      "Epoch [8100/10000], loss: 0.13996 acc: 0.98667 val_loss: 0.14813, val_acc: 0.96000\n",
      "Epoch [8110/10000], loss: 0.13988 acc: 0.98667 val_loss: 0.14806, val_acc: 0.96000\n",
      "Epoch [8120/10000], loss: 0.13980 acc: 0.98667 val_loss: 0.14799, val_acc: 0.96000\n",
      "Epoch [8130/10000], loss: 0.13972 acc: 0.98667 val_loss: 0.14792, val_acc: 0.96000\n",
      "Epoch [8140/10000], loss: 0.13964 acc: 0.98667 val_loss: 0.14785, val_acc: 0.96000\n",
      "Epoch [8150/10000], loss: 0.13956 acc: 0.98667 val_loss: 0.14778, val_acc: 0.96000\n",
      "Epoch [8160/10000], loss: 0.13948 acc: 0.98667 val_loss: 0.14771, val_acc: 0.96000\n",
      "Epoch [8170/10000], loss: 0.13940 acc: 0.98667 val_loss: 0.14765, val_acc: 0.96000\n",
      "Epoch [8180/10000], loss: 0.13932 acc: 0.98667 val_loss: 0.14758, val_acc: 0.96000\n",
      "Epoch [8190/10000], loss: 0.13924 acc: 0.98667 val_loss: 0.14751, val_acc: 0.96000\n",
      "Epoch [8200/10000], loss: 0.13916 acc: 0.98667 val_loss: 0.14744, val_acc: 0.96000\n",
      "Epoch [8210/10000], loss: 0.13908 acc: 0.98667 val_loss: 0.14737, val_acc: 0.96000\n",
      "Epoch [8220/10000], loss: 0.13900 acc: 0.98667 val_loss: 0.14731, val_acc: 0.96000\n",
      "Epoch [8230/10000], loss: 0.13892 acc: 0.98667 val_loss: 0.14724, val_acc: 0.96000\n",
      "Epoch [8240/10000], loss: 0.13884 acc: 0.98667 val_loss: 0.14717, val_acc: 0.96000\n",
      "Epoch [8250/10000], loss: 0.13876 acc: 0.98667 val_loss: 0.14710, val_acc: 0.96000\n",
      "Epoch [8260/10000], loss: 0.13869 acc: 0.98667 val_loss: 0.14704, val_acc: 0.96000\n",
      "Epoch [8270/10000], loss: 0.13861 acc: 0.98667 val_loss: 0.14697, val_acc: 0.96000\n",
      "Epoch [8280/10000], loss: 0.13853 acc: 0.98667 val_loss: 0.14690, val_acc: 0.96000\n",
      "Epoch [8290/10000], loss: 0.13845 acc: 0.98667 val_loss: 0.14684, val_acc: 0.96000\n",
      "Epoch [8300/10000], loss: 0.13837 acc: 0.98667 val_loss: 0.14677, val_acc: 0.96000\n",
      "Epoch [8310/10000], loss: 0.13829 acc: 0.98667 val_loss: 0.14670, val_acc: 0.96000\n",
      "Epoch [8320/10000], loss: 0.13822 acc: 0.98667 val_loss: 0.14664, val_acc: 0.96000\n",
      "Epoch [8330/10000], loss: 0.13814 acc: 0.98667 val_loss: 0.14657, val_acc: 0.96000\n",
      "Epoch [8340/10000], loss: 0.13806 acc: 0.98667 val_loss: 0.14650, val_acc: 0.96000\n",
      "Epoch [8350/10000], loss: 0.13798 acc: 0.98667 val_loss: 0.14644, val_acc: 0.96000\n",
      "Epoch [8360/10000], loss: 0.13791 acc: 0.98667 val_loss: 0.14637, val_acc: 0.96000\n",
      "Epoch [8370/10000], loss: 0.13783 acc: 0.98667 val_loss: 0.14631, val_acc: 0.96000\n",
      "Epoch [8380/10000], loss: 0.13775 acc: 0.98667 val_loss: 0.14624, val_acc: 0.96000\n",
      "Epoch [8390/10000], loss: 0.13768 acc: 0.98667 val_loss: 0.14618, val_acc: 0.96000\n",
      "Epoch [8400/10000], loss: 0.13760 acc: 0.98667 val_loss: 0.14611, val_acc: 0.96000\n",
      "Epoch [8410/10000], loss: 0.13752 acc: 0.98667 val_loss: 0.14605, val_acc: 0.96000\n",
      "Epoch [8420/10000], loss: 0.13745 acc: 0.98667 val_loss: 0.14598, val_acc: 0.96000\n",
      "Epoch [8430/10000], loss: 0.13737 acc: 0.98667 val_loss: 0.14592, val_acc: 0.96000\n",
      "Epoch [8440/10000], loss: 0.13730 acc: 0.98667 val_loss: 0.14585, val_acc: 0.96000\n",
      "Epoch [8450/10000], loss: 0.13722 acc: 0.98667 val_loss: 0.14579, val_acc: 0.96000\n",
      "Epoch [8460/10000], loss: 0.13714 acc: 0.98667 val_loss: 0.14572, val_acc: 0.96000\n",
      "Epoch [8470/10000], loss: 0.13707 acc: 0.98667 val_loss: 0.14566, val_acc: 0.96000\n",
      "Epoch [8480/10000], loss: 0.13699 acc: 0.98667 val_loss: 0.14559, val_acc: 0.96000\n",
      "Epoch [8490/10000], loss: 0.13692 acc: 0.98667 val_loss: 0.14553, val_acc: 0.96000\n",
      "Epoch [8500/10000], loss: 0.13684 acc: 0.98667 val_loss: 0.14547, val_acc: 0.96000\n",
      "Epoch [8510/10000], loss: 0.13677 acc: 0.98667 val_loss: 0.14540, val_acc: 0.96000\n",
      "Epoch [8520/10000], loss: 0.13669 acc: 0.98667 val_loss: 0.14534, val_acc: 0.96000\n",
      "Epoch [8530/10000], loss: 0.13662 acc: 0.98667 val_loss: 0.14528, val_acc: 0.96000\n",
      "Epoch [8540/10000], loss: 0.13654 acc: 0.98667 val_loss: 0.14521, val_acc: 0.96000\n",
      "Epoch [8550/10000], loss: 0.13647 acc: 0.98667 val_loss: 0.14515, val_acc: 0.96000\n",
      "Epoch [8560/10000], loss: 0.13640 acc: 0.98667 val_loss: 0.14509, val_acc: 0.96000\n",
      "Epoch [8570/10000], loss: 0.13632 acc: 0.98667 val_loss: 0.14502, val_acc: 0.96000\n",
      "Epoch [8580/10000], loss: 0.13625 acc: 0.98667 val_loss: 0.14496, val_acc: 0.96000\n",
      "Epoch [8590/10000], loss: 0.13617 acc: 0.98667 val_loss: 0.14490, val_acc: 0.96000\n",
      "Epoch [8600/10000], loss: 0.13610 acc: 0.98667 val_loss: 0.14483, val_acc: 0.96000\n",
      "Epoch [8610/10000], loss: 0.13603 acc: 0.98667 val_loss: 0.14477, val_acc: 0.96000\n",
      "Epoch [8620/10000], loss: 0.13595 acc: 0.98667 val_loss: 0.14471, val_acc: 0.96000\n",
      "Epoch [8630/10000], loss: 0.13588 acc: 0.98667 val_loss: 0.14465, val_acc: 0.96000\n",
      "Epoch [8640/10000], loss: 0.13581 acc: 0.98667 val_loss: 0.14459, val_acc: 0.96000\n",
      "Epoch [8650/10000], loss: 0.13574 acc: 0.98667 val_loss: 0.14452, val_acc: 0.96000\n",
      "Epoch [8660/10000], loss: 0.13566 acc: 0.98667 val_loss: 0.14446, val_acc: 0.96000\n",
      "Epoch [8670/10000], loss: 0.13559 acc: 0.98667 val_loss: 0.14440, val_acc: 0.96000\n",
      "Epoch [8680/10000], loss: 0.13552 acc: 0.98667 val_loss: 0.14434, val_acc: 0.96000\n",
      "Epoch [8690/10000], loss: 0.13545 acc: 0.98667 val_loss: 0.14428, val_acc: 0.96000\n",
      "Epoch [8700/10000], loss: 0.13537 acc: 0.98667 val_loss: 0.14422, val_acc: 0.96000\n",
      "Epoch [8710/10000], loss: 0.13530 acc: 0.98667 val_loss: 0.14415, val_acc: 0.96000\n",
      "Epoch [8720/10000], loss: 0.13523 acc: 0.98667 val_loss: 0.14409, val_acc: 0.96000\n",
      "Epoch [8730/10000], loss: 0.13516 acc: 0.98667 val_loss: 0.14403, val_acc: 0.96000\n",
      "Epoch [8740/10000], loss: 0.13509 acc: 0.98667 val_loss: 0.14397, val_acc: 0.96000\n",
      "Epoch [8750/10000], loss: 0.13501 acc: 0.98667 val_loss: 0.14391, val_acc: 0.96000\n",
      "Epoch [8760/10000], loss: 0.13494 acc: 0.98667 val_loss: 0.14385, val_acc: 0.96000\n",
      "Epoch [8770/10000], loss: 0.13487 acc: 0.98667 val_loss: 0.14379, val_acc: 0.96000\n",
      "Epoch [8780/10000], loss: 0.13480 acc: 0.98667 val_loss: 0.14373, val_acc: 0.96000\n",
      "Epoch [8790/10000], loss: 0.13473 acc: 0.98667 val_loss: 0.14367, val_acc: 0.96000\n",
      "Epoch [8800/10000], loss: 0.13466 acc: 0.98667 val_loss: 0.14361, val_acc: 0.96000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8810/10000], loss: 0.13459 acc: 0.98667 val_loss: 0.14355, val_acc: 0.96000\n",
      "Epoch [8820/10000], loss: 0.13452 acc: 0.98667 val_loss: 0.14349, val_acc: 0.96000\n",
      "Epoch [8830/10000], loss: 0.13445 acc: 0.98667 val_loss: 0.14343, val_acc: 0.96000\n",
      "Epoch [8840/10000], loss: 0.13438 acc: 0.98667 val_loss: 0.14337, val_acc: 0.96000\n",
      "Epoch [8850/10000], loss: 0.13431 acc: 0.98667 val_loss: 0.14331, val_acc: 0.96000\n",
      "Epoch [8860/10000], loss: 0.13424 acc: 0.98667 val_loss: 0.14325, val_acc: 0.96000\n",
      "Epoch [8870/10000], loss: 0.13417 acc: 0.98667 val_loss: 0.14319, val_acc: 0.96000\n",
      "Epoch [8880/10000], loss: 0.13410 acc: 0.98667 val_loss: 0.14313, val_acc: 0.96000\n",
      "Epoch [8890/10000], loss: 0.13403 acc: 0.98667 val_loss: 0.14308, val_acc: 0.96000\n",
      "Epoch [8900/10000], loss: 0.13396 acc: 0.98667 val_loss: 0.14302, val_acc: 0.96000\n",
      "Epoch [8910/10000], loss: 0.13389 acc: 0.98667 val_loss: 0.14296, val_acc: 0.96000\n",
      "Epoch [8920/10000], loss: 0.13382 acc: 0.98667 val_loss: 0.14290, val_acc: 0.96000\n",
      "Epoch [8930/10000], loss: 0.13375 acc: 0.98667 val_loss: 0.14284, val_acc: 0.96000\n",
      "Epoch [8940/10000], loss: 0.13368 acc: 0.98667 val_loss: 0.14278, val_acc: 0.96000\n",
      "Epoch [8950/10000], loss: 0.13361 acc: 0.98667 val_loss: 0.14272, val_acc: 0.96000\n",
      "Epoch [8960/10000], loss: 0.13354 acc: 0.98667 val_loss: 0.14266, val_acc: 0.96000\n",
      "Epoch [8970/10000], loss: 0.13347 acc: 0.98667 val_loss: 0.14261, val_acc: 0.96000\n",
      "Epoch [8980/10000], loss: 0.13341 acc: 0.98667 val_loss: 0.14255, val_acc: 0.96000\n",
      "Epoch [8990/10000], loss: 0.13334 acc: 0.98667 val_loss: 0.14249, val_acc: 0.96000\n",
      "Epoch [9000/10000], loss: 0.13327 acc: 0.98667 val_loss: 0.14243, val_acc: 0.96000\n",
      "Epoch [9010/10000], loss: 0.13320 acc: 0.98667 val_loss: 0.14238, val_acc: 0.96000\n",
      "Epoch [9020/10000], loss: 0.13313 acc: 0.98667 val_loss: 0.14232, val_acc: 0.96000\n",
      "Epoch [9030/10000], loss: 0.13307 acc: 0.98667 val_loss: 0.14226, val_acc: 0.96000\n",
      "Epoch [9040/10000], loss: 0.13300 acc: 0.98667 val_loss: 0.14220, val_acc: 0.96000\n",
      "Epoch [9050/10000], loss: 0.13293 acc: 0.98667 val_loss: 0.14215, val_acc: 0.96000\n",
      "Epoch [9060/10000], loss: 0.13286 acc: 0.98667 val_loss: 0.14209, val_acc: 0.96000\n",
      "Epoch [9070/10000], loss: 0.13280 acc: 0.98667 val_loss: 0.14203, val_acc: 0.96000\n",
      "Epoch [9080/10000], loss: 0.13273 acc: 0.98667 val_loss: 0.14198, val_acc: 0.96000\n",
      "Epoch [9090/10000], loss: 0.13266 acc: 0.98667 val_loss: 0.14192, val_acc: 0.96000\n",
      "Epoch [9100/10000], loss: 0.13259 acc: 0.98667 val_loss: 0.14186, val_acc: 0.96000\n",
      "Epoch [9110/10000], loss: 0.13253 acc: 0.98667 val_loss: 0.14181, val_acc: 0.96000\n",
      "Epoch [9120/10000], loss: 0.13246 acc: 0.98667 val_loss: 0.14175, val_acc: 0.96000\n",
      "Epoch [9130/10000], loss: 0.13239 acc: 0.98667 val_loss: 0.14169, val_acc: 0.96000\n",
      "Epoch [9140/10000], loss: 0.13233 acc: 0.98667 val_loss: 0.14164, val_acc: 0.96000\n",
      "Epoch [9150/10000], loss: 0.13226 acc: 0.98667 val_loss: 0.14158, val_acc: 0.96000\n",
      "Epoch [9160/10000], loss: 0.13220 acc: 0.98667 val_loss: 0.14153, val_acc: 0.96000\n",
      "Epoch [9170/10000], loss: 0.13213 acc: 0.98667 val_loss: 0.14147, val_acc: 0.96000\n",
      "Epoch [9180/10000], loss: 0.13206 acc: 0.98667 val_loss: 0.14141, val_acc: 0.96000\n",
      "Epoch [9190/10000], loss: 0.13200 acc: 0.98667 val_loss: 0.14136, val_acc: 0.96000\n",
      "Epoch [9200/10000], loss: 0.13193 acc: 0.98667 val_loss: 0.14130, val_acc: 0.96000\n",
      "Epoch [9210/10000], loss: 0.13187 acc: 0.98667 val_loss: 0.14125, val_acc: 0.96000\n",
      "Epoch [9220/10000], loss: 0.13180 acc: 0.98667 val_loss: 0.14119, val_acc: 0.96000\n",
      "Epoch [9230/10000], loss: 0.13174 acc: 0.98667 val_loss: 0.14114, val_acc: 0.96000\n",
      "Epoch [9240/10000], loss: 0.13167 acc: 0.98667 val_loss: 0.14108, val_acc: 0.96000\n",
      "Epoch [9250/10000], loss: 0.13160 acc: 0.98667 val_loss: 0.14103, val_acc: 0.96000\n",
      "Epoch [9260/10000], loss: 0.13154 acc: 0.98667 val_loss: 0.14097, val_acc: 0.96000\n",
      "Epoch [9270/10000], loss: 0.13147 acc: 0.98667 val_loss: 0.14092, val_acc: 0.96000\n",
      "Epoch [9280/10000], loss: 0.13141 acc: 0.98667 val_loss: 0.14086, val_acc: 0.96000\n",
      "Epoch [9290/10000], loss: 0.13135 acc: 0.98667 val_loss: 0.14081, val_acc: 0.96000\n",
      "Epoch [9300/10000], loss: 0.13128 acc: 0.98667 val_loss: 0.14075, val_acc: 0.96000\n",
      "Epoch [9310/10000], loss: 0.13122 acc: 0.98667 val_loss: 0.14070, val_acc: 0.96000\n",
      "Epoch [9320/10000], loss: 0.13115 acc: 0.98667 val_loss: 0.14065, val_acc: 0.96000\n",
      "Epoch [9330/10000], loss: 0.13109 acc: 0.98667 val_loss: 0.14059, val_acc: 0.96000\n",
      "Epoch [9340/10000], loss: 0.13102 acc: 0.98667 val_loss: 0.14054, val_acc: 0.96000\n",
      "Epoch [9350/10000], loss: 0.13096 acc: 0.98667 val_loss: 0.14048, val_acc: 0.96000\n",
      "Epoch [9360/10000], loss: 0.13090 acc: 0.98667 val_loss: 0.14043, val_acc: 0.96000\n",
      "Epoch [9370/10000], loss: 0.13083 acc: 0.98667 val_loss: 0.14038, val_acc: 0.96000\n",
      "Epoch [9380/10000], loss: 0.13077 acc: 0.98667 val_loss: 0.14032, val_acc: 0.96000\n",
      "Epoch [9390/10000], loss: 0.13070 acc: 0.98667 val_loss: 0.14027, val_acc: 0.96000\n",
      "Epoch [9400/10000], loss: 0.13064 acc: 0.98667 val_loss: 0.14022, val_acc: 0.96000\n",
      "Epoch [9410/10000], loss: 0.13058 acc: 0.98667 val_loss: 0.14016, val_acc: 0.96000\n",
      "Epoch [9420/10000], loss: 0.13051 acc: 0.98667 val_loss: 0.14011, val_acc: 0.96000\n",
      "Epoch [9430/10000], loss: 0.13045 acc: 0.98667 val_loss: 0.14006, val_acc: 0.96000\n",
      "Epoch [9440/10000], loss: 0.13039 acc: 0.98667 val_loss: 0.14000, val_acc: 0.96000\n",
      "Epoch [9450/10000], loss: 0.13033 acc: 0.98667 val_loss: 0.13995, val_acc: 0.96000\n",
      "Epoch [9460/10000], loss: 0.13026 acc: 0.98667 val_loss: 0.13990, val_acc: 0.96000\n",
      "Epoch [9470/10000], loss: 0.13020 acc: 0.98667 val_loss: 0.13984, val_acc: 0.96000\n",
      "Epoch [9480/10000], loss: 0.13014 acc: 0.98667 val_loss: 0.13979, val_acc: 0.96000\n",
      "Epoch [9490/10000], loss: 0.13008 acc: 0.98667 val_loss: 0.13974, val_acc: 0.96000\n",
      "Epoch [9500/10000], loss: 0.13001 acc: 0.98667 val_loss: 0.13969, val_acc: 0.96000\n",
      "Epoch [9510/10000], loss: 0.12995 acc: 0.98667 val_loss: 0.13963, val_acc: 0.96000\n",
      "Epoch [9520/10000], loss: 0.12989 acc: 0.98667 val_loss: 0.13958, val_acc: 0.96000\n",
      "Epoch [9530/10000], loss: 0.12983 acc: 0.98667 val_loss: 0.13953, val_acc: 0.96000\n",
      "Epoch [9540/10000], loss: 0.12976 acc: 0.98667 val_loss: 0.13948, val_acc: 0.96000\n",
      "Epoch [9550/10000], loss: 0.12970 acc: 0.98667 val_loss: 0.13943, val_acc: 0.96000\n",
      "Epoch [9560/10000], loss: 0.12964 acc: 0.98667 val_loss: 0.13937, val_acc: 0.96000\n",
      "Epoch [9570/10000], loss: 0.12958 acc: 0.98667 val_loss: 0.13932, val_acc: 0.96000\n",
      "Epoch [9580/10000], loss: 0.12952 acc: 0.98667 val_loss: 0.13927, val_acc: 0.96000\n",
      "Epoch [9590/10000], loss: 0.12946 acc: 0.98667 val_loss: 0.13922, val_acc: 0.96000\n",
      "Epoch [9600/10000], loss: 0.12940 acc: 0.98667 val_loss: 0.13917, val_acc: 0.96000\n",
      "Epoch [9610/10000], loss: 0.12933 acc: 0.98667 val_loss: 0.13912, val_acc: 0.96000\n",
      "Epoch [9620/10000], loss: 0.12927 acc: 0.98667 val_loss: 0.13907, val_acc: 0.96000\n",
      "Epoch [9630/10000], loss: 0.12921 acc: 0.98667 val_loss: 0.13901, val_acc: 0.96000\n",
      "Epoch [9640/10000], loss: 0.12915 acc: 0.98667 val_loss: 0.13896, val_acc: 0.96000\n",
      "Epoch [9650/10000], loss: 0.12909 acc: 0.98667 val_loss: 0.13891, val_acc: 0.96000\n",
      "Epoch [9660/10000], loss: 0.12903 acc: 0.98667 val_loss: 0.13886, val_acc: 0.96000\n",
      "Epoch [9670/10000], loss: 0.12897 acc: 0.98667 val_loss: 0.13881, val_acc: 0.96000\n",
      "Epoch [9680/10000], loss: 0.12891 acc: 0.98667 val_loss: 0.13876, val_acc: 0.96000\n",
      "Epoch [9690/10000], loss: 0.12885 acc: 0.98667 val_loss: 0.13871, val_acc: 0.96000\n",
      "Epoch [9700/10000], loss: 0.12879 acc: 0.98667 val_loss: 0.13866, val_acc: 0.96000\n",
      "Epoch [9710/10000], loss: 0.12873 acc: 0.98667 val_loss: 0.13861, val_acc: 0.96000\n",
      "Epoch [9720/10000], loss: 0.12867 acc: 0.98667 val_loss: 0.13856, val_acc: 0.96000\n",
      "Epoch [9730/10000], loss: 0.12861 acc: 0.98667 val_loss: 0.13851, val_acc: 0.96000\n",
      "Epoch [9740/10000], loss: 0.12855 acc: 0.98667 val_loss: 0.13846, val_acc: 0.96000\n",
      "Epoch [9750/10000], loss: 0.12849 acc: 0.98667 val_loss: 0.13841, val_acc: 0.96000\n",
      "Epoch [9760/10000], loss: 0.12843 acc: 0.98667 val_loss: 0.13836, val_acc: 0.96000\n",
      "Epoch [9770/10000], loss: 0.12837 acc: 0.98667 val_loss: 0.13831, val_acc: 0.96000\n",
      "Epoch [9780/10000], loss: 0.12831 acc: 0.98667 val_loss: 0.13826, val_acc: 0.96000\n",
      "Epoch [9790/10000], loss: 0.12825 acc: 0.98667 val_loss: 0.13821, val_acc: 0.96000\n",
      "Epoch [9800/10000], loss: 0.12819 acc: 0.98667 val_loss: 0.13816, val_acc: 0.96000\n",
      "Epoch [9810/10000], loss: 0.12813 acc: 0.98667 val_loss: 0.13811, val_acc: 0.96000\n",
      "Epoch [9820/10000], loss: 0.12808 acc: 0.98667 val_loss: 0.13806, val_acc: 0.96000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9830/10000], loss: 0.12802 acc: 0.98667 val_loss: 0.13801, val_acc: 0.96000\n",
      "Epoch [9840/10000], loss: 0.12796 acc: 0.98667 val_loss: 0.13796, val_acc: 0.96000\n",
      "Epoch [9850/10000], loss: 0.12790 acc: 0.98667 val_loss: 0.13791, val_acc: 0.96000\n",
      "Epoch [9860/10000], loss: 0.12784 acc: 0.98667 val_loss: 0.13786, val_acc: 0.96000\n",
      "Epoch [9870/10000], loss: 0.12778 acc: 0.98667 val_loss: 0.13782, val_acc: 0.96000\n",
      "Epoch [9880/10000], loss: 0.12772 acc: 0.98667 val_loss: 0.13777, val_acc: 0.96000\n",
      "Epoch [9890/10000], loss: 0.12767 acc: 0.98667 val_loss: 0.13772, val_acc: 0.96000\n",
      "Epoch [9900/10000], loss: 0.12761 acc: 0.98667 val_loss: 0.13767, val_acc: 0.96000\n",
      "Epoch [9910/10000], loss: 0.12755 acc: 0.98667 val_loss: 0.13762, val_acc: 0.96000\n",
      "Epoch [9920/10000], loss: 0.12749 acc: 0.98667 val_loss: 0.13757, val_acc: 0.96000\n",
      "Epoch [9930/10000], loss: 0.12743 acc: 0.98667 val_loss: 0.13752, val_acc: 0.96000\n",
      "Epoch [9940/10000], loss: 0.12738 acc: 0.98667 val_loss: 0.13748, val_acc: 0.96000\n",
      "Epoch [9950/10000], loss: 0.12732 acc: 0.98667 val_loss: 0.13743, val_acc: 0.96000\n",
      "Epoch [9960/10000], loss: 0.12726 acc: 0.98667 val_loss: 0.13738, val_acc: 0.96000\n",
      "Epoch [9970/10000], loss: 0.12720 acc: 0.98667 val_loss: 0.13733, val_acc: 0.96000\n",
      "Epoch [9980/10000], loss: 0.12715 acc: 0.98667 val_loss: 0.13728, val_acc: 0.96000\n",
      "Epoch [9990/10000], loss: 0.12709 acc: 0.98667 val_loss: 0.13724, val_acc: 0.96000\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "\n",
    "    # 学習フェーズ\n",
    "    \n",
    "    #勾配の初期化\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 順伝搬計算\n",
    "    outputs = net(inputs)\n",
    "\n",
    "    # 誤差計算\n",
    "    loss = criterion(outputs, labels)\n",
    "\n",
    "    # 勾配計算\n",
    "    loss.backward()\n",
    "    \n",
    "    # 重み調整\n",
    "    optimizer.step()\n",
    "\n",
    "    #予測値算出\n",
    "    predicted = torch.max(outputs, 1)[1]\n",
    "\n",
    "    # 訓練データに対する損失と精度の計算\n",
    "    train_loss = loss.item()\n",
    "    train_acc = (predicted == labels).sum()  / len(labels)\n",
    "\n",
    "    #予測フェーズ\n",
    "    with torch.no_grad():\n",
    "\n",
    "        # 順伝搬計算\n",
    "        outputs_test = net(inputs_test)\n",
    "\n",
    "        # 誤差計算\n",
    "        # loss_test = criterion(torch.log(outputs_test), labels_test)\n",
    "        loss_test = criterion(outputs_test, labels_test)\n",
    "\n",
    "        #予測値算出\n",
    "        predicted_test = torch.max(outputs_test, 1)[1]\n",
    "\n",
    "        # 検証データに対する損失と精度の計算\n",
    "        val_loss =  loss_test.item()\n",
    "        val_acc =  (predicted_test == labels_test).sum() / len(labels_test)\n",
    "    \n",
    "    if ( epoch % 10 == 0):\n",
    "        print (f'Epoch [{epoch}/{num_epochs}], loss: {train_loss:.5f} acc: {train_acc:.5f} val_loss: {val_loss:.5f}, val_acc: {val_acc:.5f}')\n",
    "        item = np.array([epoch , train_loss, train_acc, val_loss, val_acc])\n",
    "        history = np.vstack((history, item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "初期状態: 損失関数: 1.09158 精度: 0.26667\n",
      "最終状態: 損失関数: 0.13724 精度: 0.96000\n"
     ]
    }
   ],
   "source": [
    "#損失関数値と精度の確認\n",
    "\n",
    "print(f'初期状態: 損失関数: {history[0,3]:.5f} 精度: {history[0,4]:.5f}' )\n",
    "print(f'最終状態: 損失関数: {history[-1,3]:.5f} 精度: {history[-1,4]:.5f}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 学習曲線の表示 (損失関数)\n",
    "\n",
    "plt.plot(history[:,0], history[:,1], 'b', label='訓練')\n",
    "plt.plot(history[:,0], history[:,3], 'k', label='検証')\n",
    "plt.xlabel('繰り返し回数')\n",
    "plt.ylabel('損失関数値')\n",
    "plt.title('学習曲線(損失関数)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 学習曲線の表示 (精度)\n",
    "\n",
    "plt.plot(history[:,0], history[:,2], 'b', label='訓練')\n",
    "plt.plot(history[:,0], history[:,4], 'k', label='検証')\n",
    "plt.xlabel('繰り返し回数')\n",
    "plt.ylabel('精度')\n",
    "plt.title('学習曲線(精度)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## コラム softmax 関数と交差エントロピー関数の微妙な関係"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### パターン1 モデルクラス側にlogsoftmax関数を含める"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの定義\n",
    "# 2入力3出力のロジスティック回帰モデル\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, n_input, n_output):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(n_input, n_output)\n",
    "        # softmax関数の定義\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "                \n",
    "        # 初期値を全部1にする\n",
    "        # 「ディープラーニングの数学」と条件を合わせる目的        \n",
    "        self.l1.weight.data.fill_(1.0)\n",
    "        self.l1.bias.data.fill_(1.0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.l1(x)\n",
    "        x2 = self.softmax(x1)\n",
    "        return x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習率\n",
    "lr = 0.01\n",
    "\n",
    "# 初期化\n",
    "net = Net(n_input, n_output)\n",
    "\n",
    "# 最適化アルゴリズム: 勾配降下法\n",
    "optimizer = optim.SGD(net.parameters(), lr=lr)\n",
    "\n",
    "# 損失関数： NLLLoss\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# 繰り返し回数\n",
    "num_epochs = 10000\n",
    "\n",
    "# 評価結果記録用\n",
    "history = np.zeros((0,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/10000], loss: 1.09861 acc: 0.30667 val_loss: 1.09158, val_acc: 0.26667\n",
      "Epoch [10/10000], loss: 1.01848 acc: 0.40000 val_loss: 1.04171, val_acc: 0.26667\n",
      "Epoch [20/10000], loss: 0.96854 acc: 0.40000 val_loss: 0.98850, val_acc: 0.26667\n",
      "Epoch [30/10000], loss: 0.92459 acc: 0.65333 val_loss: 0.93996, val_acc: 0.57333\n",
      "Epoch [40/10000], loss: 0.88568 acc: 0.70667 val_loss: 0.89704, val_acc: 0.62667\n",
      "Epoch [50/10000], loss: 0.85120 acc: 0.70667 val_loss: 0.85918, val_acc: 0.62667\n",
      "Epoch [60/10000], loss: 0.82059 acc: 0.70667 val_loss: 0.82572, val_acc: 0.62667\n",
      "Epoch [70/10000], loss: 0.79335 acc: 0.72000 val_loss: 0.79607, val_acc: 0.62667\n",
      "Epoch [80/10000], loss: 0.76900 acc: 0.72000 val_loss: 0.76968, val_acc: 0.65333\n",
      "Epoch [90/10000], loss: 0.74717 acc: 0.72000 val_loss: 0.74610, val_acc: 0.65333\n",
      "Epoch [100/10000], loss: 0.72750 acc: 0.76000 val_loss: 0.72494, val_acc: 0.69333\n",
      "Epoch [110/10000], loss: 0.70970 acc: 0.77333 val_loss: 0.70585, val_acc: 0.74667\n",
      "Epoch [120/10000], loss: 0.69354 acc: 0.81333 val_loss: 0.68856, val_acc: 0.76000\n",
      "Epoch [130/10000], loss: 0.67878 acc: 0.84000 val_loss: 0.67283, val_acc: 0.76000\n",
      "Epoch [140/10000], loss: 0.66526 acc: 0.84000 val_loss: 0.65846, val_acc: 0.78667\n",
      "Epoch [150/10000], loss: 0.65283 acc: 0.86667 val_loss: 0.64528, val_acc: 0.78667\n",
      "Epoch [160/10000], loss: 0.64135 acc: 0.88000 val_loss: 0.63313, val_acc: 0.78667\n",
      "Epoch [170/10000], loss: 0.63070 acc: 0.89333 val_loss: 0.62190, val_acc: 0.81333\n",
      "Epoch [180/10000], loss: 0.62080 acc: 0.90667 val_loss: 0.61149, val_acc: 0.81333\n",
      "Epoch [190/10000], loss: 0.61157 acc: 0.90667 val_loss: 0.60179, val_acc: 0.84000\n",
      "Epoch [200/10000], loss: 0.60292 acc: 0.90667 val_loss: 0.59273, val_acc: 0.84000\n",
      "Epoch [210/10000], loss: 0.59481 acc: 0.90667 val_loss: 0.58425, val_acc: 0.88000\n",
      "Epoch [220/10000], loss: 0.58717 acc: 0.93333 val_loss: 0.57628, val_acc: 0.88000\n",
      "Epoch [230/10000], loss: 0.57996 acc: 0.93333 val_loss: 0.56877, val_acc: 0.89333\n",
      "Epoch [240/10000], loss: 0.57313 acc: 0.93333 val_loss: 0.56169, val_acc: 0.90667\n",
      "Epoch [250/10000], loss: 0.56666 acc: 0.93333 val_loss: 0.55498, val_acc: 0.90667\n",
      "Epoch [260/10000], loss: 0.56051 acc: 0.92000 val_loss: 0.54862, val_acc: 0.90667\n",
      "Epoch [270/10000], loss: 0.55465 acc: 0.92000 val_loss: 0.54257, val_acc: 0.90667\n",
      "Epoch [280/10000], loss: 0.54906 acc: 0.92000 val_loss: 0.53681, val_acc: 0.90667\n",
      "Epoch [290/10000], loss: 0.54371 acc: 0.92000 val_loss: 0.53131, val_acc: 0.90667\n",
      "Epoch [300/10000], loss: 0.53859 acc: 0.93333 val_loss: 0.52605, val_acc: 0.90667\n",
      "Epoch [310/10000], loss: 0.53368 acc: 0.93333 val_loss: 0.52102, val_acc: 0.90667\n",
      "Epoch [320/10000], loss: 0.52896 acc: 0.93333 val_loss: 0.51619, val_acc: 0.90667\n",
      "Epoch [330/10000], loss: 0.52442 acc: 0.93333 val_loss: 0.51155, val_acc: 0.90667\n",
      "Epoch [340/10000], loss: 0.52004 acc: 0.93333 val_loss: 0.50709, val_acc: 0.90667\n",
      "Epoch [350/10000], loss: 0.51582 acc: 0.93333 val_loss: 0.50280, val_acc: 0.90667\n",
      "Epoch [360/10000], loss: 0.51173 acc: 0.93333 val_loss: 0.49865, val_acc: 0.90667\n",
      "Epoch [370/10000], loss: 0.50779 acc: 0.93333 val_loss: 0.49465, val_acc: 0.90667\n",
      "Epoch [380/10000], loss: 0.50397 acc: 0.93333 val_loss: 0.49078, val_acc: 0.90667\n",
      "Epoch [390/10000], loss: 0.50026 acc: 0.93333 val_loss: 0.48703, val_acc: 0.90667\n",
      "Epoch [400/10000], loss: 0.49666 acc: 0.94667 val_loss: 0.48340, val_acc: 0.90667\n",
      "Epoch [410/10000], loss: 0.49317 acc: 0.94667 val_loss: 0.47988, val_acc: 0.90667\n",
      "Epoch [420/10000], loss: 0.48978 acc: 0.94667 val_loss: 0.47647, val_acc: 0.90667\n",
      "Epoch [430/10000], loss: 0.48647 acc: 0.96000 val_loss: 0.47315, val_acc: 0.90667\n",
      "Epoch [440/10000], loss: 0.48326 acc: 0.96000 val_loss: 0.46992, val_acc: 0.90667\n",
      "Epoch [450/10000], loss: 0.48012 acc: 0.96000 val_loss: 0.46678, val_acc: 0.90667\n",
      "Epoch [460/10000], loss: 0.47706 acc: 0.96000 val_loss: 0.46372, val_acc: 0.90667\n",
      "Epoch [470/10000], loss: 0.47408 acc: 0.96000 val_loss: 0.46073, val_acc: 0.90667\n",
      "Epoch [480/10000], loss: 0.47116 acc: 0.96000 val_loss: 0.45783, val_acc: 0.90667\n",
      "Epoch [490/10000], loss: 0.46831 acc: 0.96000 val_loss: 0.45499, val_acc: 0.90667\n",
      "Epoch [500/10000], loss: 0.46553 acc: 0.96000 val_loss: 0.45221, val_acc: 0.90667\n",
      "Epoch [510/10000], loss: 0.46280 acc: 0.96000 val_loss: 0.44951, val_acc: 0.90667\n",
      "Epoch [520/10000], loss: 0.46013 acc: 0.96000 val_loss: 0.44686, val_acc: 0.90667\n",
      "Epoch [530/10000], loss: 0.45752 acc: 0.96000 val_loss: 0.44426, val_acc: 0.90667\n",
      "Epoch [540/10000], loss: 0.45496 acc: 0.96000 val_loss: 0.44173, val_acc: 0.90667\n",
      "Epoch [550/10000], loss: 0.45245 acc: 0.96000 val_loss: 0.43924, val_acc: 0.90667\n",
      "Epoch [560/10000], loss: 0.44998 acc: 0.96000 val_loss: 0.43681, val_acc: 0.90667\n",
      "Epoch [570/10000], loss: 0.44757 acc: 0.96000 val_loss: 0.43442, val_acc: 0.90667\n",
      "Epoch [580/10000], loss: 0.44519 acc: 0.96000 val_loss: 0.43208, val_acc: 0.90667\n",
      "Epoch [590/10000], loss: 0.44286 acc: 0.96000 val_loss: 0.42979, val_acc: 0.92000\n",
      "Epoch [600/10000], loss: 0.44057 acc: 0.96000 val_loss: 0.42753, val_acc: 0.92000\n",
      "Epoch [610/10000], loss: 0.43832 acc: 0.96000 val_loss: 0.42532, val_acc: 0.92000\n",
      "Epoch [620/10000], loss: 0.43611 acc: 0.96000 val_loss: 0.42315, val_acc: 0.92000\n",
      "Epoch [630/10000], loss: 0.43393 acc: 0.96000 val_loss: 0.42101, val_acc: 0.92000\n",
      "Epoch [640/10000], loss: 0.43179 acc: 0.96000 val_loss: 0.41891, val_acc: 0.92000\n",
      "Epoch [650/10000], loss: 0.42968 acc: 0.96000 val_loss: 0.41685, val_acc: 0.92000\n",
      "Epoch [660/10000], loss: 0.42761 acc: 0.96000 val_loss: 0.41482, val_acc: 0.92000\n",
      "Epoch [670/10000], loss: 0.42556 acc: 0.96000 val_loss: 0.41282, val_acc: 0.92000\n",
      "Epoch [680/10000], loss: 0.42355 acc: 0.96000 val_loss: 0.41085, val_acc: 0.92000\n",
      "Epoch [690/10000], loss: 0.42157 acc: 0.96000 val_loss: 0.40892, val_acc: 0.92000\n",
      "Epoch [700/10000], loss: 0.41961 acc: 0.96000 val_loss: 0.40701, val_acc: 0.92000\n",
      "Epoch [710/10000], loss: 0.41768 acc: 0.96000 val_loss: 0.40513, val_acc: 0.92000\n",
      "Epoch [720/10000], loss: 0.41578 acc: 0.96000 val_loss: 0.40329, val_acc: 0.92000\n",
      "Epoch [730/10000], loss: 0.41391 acc: 0.96000 val_loss: 0.40146, val_acc: 0.92000\n",
      "Epoch [740/10000], loss: 0.41206 acc: 0.96000 val_loss: 0.39967, val_acc: 0.92000\n",
      "Epoch [750/10000], loss: 0.41024 acc: 0.96000 val_loss: 0.39789, val_acc: 0.92000\n",
      "Epoch [760/10000], loss: 0.40844 acc: 0.96000 val_loss: 0.39615, val_acc: 0.92000\n",
      "Epoch [770/10000], loss: 0.40666 acc: 0.96000 val_loss: 0.39443, val_acc: 0.93333\n",
      "Epoch [780/10000], loss: 0.40491 acc: 0.96000 val_loss: 0.39273, val_acc: 0.93333\n",
      "Epoch [790/10000], loss: 0.40317 acc: 0.96000 val_loss: 0.39105, val_acc: 0.93333\n",
      "Epoch [800/10000], loss: 0.40146 acc: 0.96000 val_loss: 0.38939, val_acc: 0.93333\n",
      "Epoch [810/10000], loss: 0.39977 acc: 0.96000 val_loss: 0.38776, val_acc: 0.93333\n",
      "Epoch [820/10000], loss: 0.39810 acc: 0.96000 val_loss: 0.38615, val_acc: 0.93333\n",
      "Epoch [830/10000], loss: 0.39645 acc: 0.96000 val_loss: 0.38456, val_acc: 0.93333\n",
      "Epoch [840/10000], loss: 0.39483 acc: 0.96000 val_loss: 0.38298, val_acc: 0.93333\n",
      "Epoch [850/10000], loss: 0.39321 acc: 0.97333 val_loss: 0.38143, val_acc: 0.94667\n",
      "Epoch [860/10000], loss: 0.39162 acc: 0.97333 val_loss: 0.37990, val_acc: 0.94667\n",
      "Epoch [870/10000], loss: 0.39005 acc: 0.97333 val_loss: 0.37838, val_acc: 0.94667\n",
      "Epoch [880/10000], loss: 0.38849 acc: 0.97333 val_loss: 0.37688, val_acc: 0.94667\n",
      "Epoch [890/10000], loss: 0.38695 acc: 0.97333 val_loss: 0.37540, val_acc: 0.94667\n",
      "Epoch [900/10000], loss: 0.38543 acc: 0.97333 val_loss: 0.37394, val_acc: 0.94667\n",
      "Epoch [910/10000], loss: 0.38392 acc: 0.97333 val_loss: 0.37249, val_acc: 0.94667\n",
      "Epoch [920/10000], loss: 0.38243 acc: 0.97333 val_loss: 0.37106, val_acc: 0.94667\n",
      "Epoch [930/10000], loss: 0.38096 acc: 0.97333 val_loss: 0.36965, val_acc: 0.94667\n",
      "Epoch [940/10000], loss: 0.37950 acc: 0.97333 val_loss: 0.36825, val_acc: 0.94667\n",
      "Epoch [950/10000], loss: 0.37806 acc: 0.97333 val_loss: 0.36686, val_acc: 0.94667\n",
      "Epoch [960/10000], loss: 0.37663 acc: 0.97333 val_loss: 0.36550, val_acc: 0.96000\n",
      "Epoch [970/10000], loss: 0.37522 acc: 0.97333 val_loss: 0.36414, val_acc: 0.96000\n",
      "Epoch [980/10000], loss: 0.37382 acc: 0.97333 val_loss: 0.36280, val_acc: 0.96000\n",
      "Epoch [990/10000], loss: 0.37243 acc: 0.97333 val_loss: 0.36148, val_acc: 0.96000\n",
      "Epoch [1000/10000], loss: 0.37106 acc: 0.97333 val_loss: 0.36017, val_acc: 0.96000\n",
      "Epoch [1010/10000], loss: 0.36970 acc: 0.97333 val_loss: 0.35887, val_acc: 0.96000\n",
      "Epoch [1020/10000], loss: 0.36836 acc: 0.97333 val_loss: 0.35758, val_acc: 0.96000\n",
      "Epoch [1030/10000], loss: 0.36703 acc: 0.97333 val_loss: 0.35631, val_acc: 0.96000\n",
      "Epoch [1040/10000], loss: 0.36571 acc: 0.97333 val_loss: 0.35506, val_acc: 0.96000\n",
      "Epoch [1050/10000], loss: 0.36440 acc: 0.97333 val_loss: 0.35381, val_acc: 0.96000\n",
      "Epoch [1060/10000], loss: 0.36311 acc: 0.97333 val_loss: 0.35258, val_acc: 0.96000\n",
      "Epoch [1070/10000], loss: 0.36183 acc: 0.97333 val_loss: 0.35135, val_acc: 0.96000\n",
      "Epoch [1080/10000], loss: 0.36056 acc: 0.97333 val_loss: 0.35014, val_acc: 0.96000\n",
      "Epoch [1090/10000], loss: 0.35930 acc: 0.97333 val_loss: 0.34895, val_acc: 0.96000\n",
      "Epoch [1100/10000], loss: 0.35805 acc: 0.97333 val_loss: 0.34776, val_acc: 0.96000\n",
      "Epoch [1110/10000], loss: 0.35682 acc: 0.97333 val_loss: 0.34659, val_acc: 0.96000\n",
      "Epoch [1120/10000], loss: 0.35559 acc: 0.97333 val_loss: 0.34542, val_acc: 0.96000\n",
      "Epoch [1130/10000], loss: 0.35438 acc: 0.97333 val_loss: 0.34427, val_acc: 0.96000\n",
      "Epoch [1140/10000], loss: 0.35318 acc: 0.97333 val_loss: 0.34313, val_acc: 0.96000\n",
      "Epoch [1150/10000], loss: 0.35199 acc: 0.97333 val_loss: 0.34199, val_acc: 0.96000\n",
      "Epoch [1160/10000], loss: 0.35081 acc: 0.97333 val_loss: 0.34087, val_acc: 0.96000\n",
      "Epoch [1170/10000], loss: 0.34964 acc: 0.97333 val_loss: 0.33976, val_acc: 0.96000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1180/10000], loss: 0.34848 acc: 0.97333 val_loss: 0.33866, val_acc: 0.96000\n",
      "Epoch [1190/10000], loss: 0.34732 acc: 0.97333 val_loss: 0.33757, val_acc: 0.96000\n",
      "Epoch [1200/10000], loss: 0.34618 acc: 0.97333 val_loss: 0.33649, val_acc: 0.96000\n",
      "Epoch [1210/10000], loss: 0.34505 acc: 0.97333 val_loss: 0.33542, val_acc: 0.96000\n",
      "Epoch [1220/10000], loss: 0.34393 acc: 0.97333 val_loss: 0.33435, val_acc: 0.96000\n",
      "Epoch [1230/10000], loss: 0.34282 acc: 0.97333 val_loss: 0.33330, val_acc: 0.96000\n",
      "Epoch [1240/10000], loss: 0.34172 acc: 0.97333 val_loss: 0.33226, val_acc: 0.96000\n",
      "Epoch [1250/10000], loss: 0.34062 acc: 0.97333 val_loss: 0.33122, val_acc: 0.96000\n",
      "Epoch [1260/10000], loss: 0.33954 acc: 0.97333 val_loss: 0.33020, val_acc: 0.96000\n",
      "Epoch [1270/10000], loss: 0.33846 acc: 0.97333 val_loss: 0.32918, val_acc: 0.96000\n",
      "Epoch [1280/10000], loss: 0.33740 acc: 0.97333 val_loss: 0.32817, val_acc: 0.96000\n",
      "Epoch [1290/10000], loss: 0.33634 acc: 0.97333 val_loss: 0.32717, val_acc: 0.96000\n",
      "Epoch [1300/10000], loss: 0.33529 acc: 0.97333 val_loss: 0.32618, val_acc: 0.96000\n",
      "Epoch [1310/10000], loss: 0.33425 acc: 0.97333 val_loss: 0.32520, val_acc: 0.96000\n",
      "Epoch [1320/10000], loss: 0.33321 acc: 0.97333 val_loss: 0.32422, val_acc: 0.96000\n",
      "Epoch [1330/10000], loss: 0.33219 acc: 0.97333 val_loss: 0.32325, val_acc: 0.96000\n",
      "Epoch [1340/10000], loss: 0.33117 acc: 0.97333 val_loss: 0.32229, val_acc: 0.96000\n",
      "Epoch [1350/10000], loss: 0.33016 acc: 0.97333 val_loss: 0.32134, val_acc: 0.96000\n",
      "Epoch [1360/10000], loss: 0.32916 acc: 0.97333 val_loss: 0.32040, val_acc: 0.96000\n",
      "Epoch [1370/10000], loss: 0.32817 acc: 0.97333 val_loss: 0.31946, val_acc: 0.96000\n",
      "Epoch [1380/10000], loss: 0.32719 acc: 0.97333 val_loss: 0.31853, val_acc: 0.96000\n",
      "Epoch [1390/10000], loss: 0.32621 acc: 0.97333 val_loss: 0.31761, val_acc: 0.96000\n",
      "Epoch [1400/10000], loss: 0.32524 acc: 0.97333 val_loss: 0.31670, val_acc: 0.96000\n",
      "Epoch [1410/10000], loss: 0.32428 acc: 0.97333 val_loss: 0.31579, val_acc: 0.96000\n",
      "Epoch [1420/10000], loss: 0.32332 acc: 0.97333 val_loss: 0.31489, val_acc: 0.96000\n",
      "Epoch [1430/10000], loss: 0.32237 acc: 0.97333 val_loss: 0.31400, val_acc: 0.96000\n",
      "Epoch [1440/10000], loss: 0.32143 acc: 0.97333 val_loss: 0.31312, val_acc: 0.96000\n",
      "Epoch [1450/10000], loss: 0.32050 acc: 0.97333 val_loss: 0.31224, val_acc: 0.96000\n",
      "Epoch [1460/10000], loss: 0.31957 acc: 0.97333 val_loss: 0.31137, val_acc: 0.96000\n",
      "Epoch [1470/10000], loss: 0.31865 acc: 0.97333 val_loss: 0.31050, val_acc: 0.96000\n",
      "Epoch [1480/10000], loss: 0.31774 acc: 0.97333 val_loss: 0.30964, val_acc: 0.96000\n",
      "Epoch [1490/10000], loss: 0.31683 acc: 0.97333 val_loss: 0.30879, val_acc: 0.96000\n",
      "Epoch [1500/10000], loss: 0.31593 acc: 0.97333 val_loss: 0.30795, val_acc: 0.96000\n",
      "Epoch [1510/10000], loss: 0.31504 acc: 0.97333 val_loss: 0.30711, val_acc: 0.96000\n",
      "Epoch [1520/10000], loss: 0.31415 acc: 0.97333 val_loss: 0.30628, val_acc: 0.96000\n",
      "Epoch [1530/10000], loss: 0.31327 acc: 0.97333 val_loss: 0.30545, val_acc: 0.96000\n",
      "Epoch [1540/10000], loss: 0.31240 acc: 0.97333 val_loss: 0.30463, val_acc: 0.96000\n",
      "Epoch [1550/10000], loss: 0.31153 acc: 0.97333 val_loss: 0.30382, val_acc: 0.96000\n",
      "Epoch [1560/10000], loss: 0.31067 acc: 0.97333 val_loss: 0.30301, val_acc: 0.96000\n",
      "Epoch [1570/10000], loss: 0.30981 acc: 0.97333 val_loss: 0.30221, val_acc: 0.96000\n",
      "Epoch [1580/10000], loss: 0.30896 acc: 0.97333 val_loss: 0.30141, val_acc: 0.96000\n",
      "Epoch [1590/10000], loss: 0.30812 acc: 0.97333 val_loss: 0.30062, val_acc: 0.96000\n",
      "Epoch [1600/10000], loss: 0.30728 acc: 0.97333 val_loss: 0.29984, val_acc: 0.96000\n",
      "Epoch [1610/10000], loss: 0.30645 acc: 0.97333 val_loss: 0.29906, val_acc: 0.96000\n",
      "Epoch [1620/10000], loss: 0.30562 acc: 0.97333 val_loss: 0.29828, val_acc: 0.96000\n",
      "Epoch [1630/10000], loss: 0.30480 acc: 0.97333 val_loss: 0.29752, val_acc: 0.96000\n",
      "Epoch [1640/10000], loss: 0.30399 acc: 0.97333 val_loss: 0.29675, val_acc: 0.96000\n",
      "Epoch [1650/10000], loss: 0.30318 acc: 0.97333 val_loss: 0.29600, val_acc: 0.96000\n",
      "Epoch [1660/10000], loss: 0.30237 acc: 0.97333 val_loss: 0.29525, val_acc: 0.96000\n",
      "Epoch [1670/10000], loss: 0.30158 acc: 0.97333 val_loss: 0.29450, val_acc: 0.96000\n",
      "Epoch [1680/10000], loss: 0.30078 acc: 0.97333 val_loss: 0.29376, val_acc: 0.96000\n",
      "Epoch [1690/10000], loss: 0.30000 acc: 0.97333 val_loss: 0.29302, val_acc: 0.96000\n",
      "Epoch [1700/10000], loss: 0.29922 acc: 0.97333 val_loss: 0.29229, val_acc: 0.96000\n",
      "Epoch [1710/10000], loss: 0.29844 acc: 0.97333 val_loss: 0.29157, val_acc: 0.96000\n",
      "Epoch [1720/10000], loss: 0.29767 acc: 0.97333 val_loss: 0.29085, val_acc: 0.96000\n",
      "Epoch [1730/10000], loss: 0.29690 acc: 0.97333 val_loss: 0.29013, val_acc: 0.96000\n",
      "Epoch [1740/10000], loss: 0.29614 acc: 0.97333 val_loss: 0.28942, val_acc: 0.96000\n",
      "Epoch [1750/10000], loss: 0.29538 acc: 0.97333 val_loss: 0.28872, val_acc: 0.96000\n",
      "Epoch [1760/10000], loss: 0.29463 acc: 0.97333 val_loss: 0.28801, val_acc: 0.96000\n",
      "Epoch [1770/10000], loss: 0.29389 acc: 0.97333 val_loss: 0.28732, val_acc: 0.96000\n",
      "Epoch [1780/10000], loss: 0.29315 acc: 0.97333 val_loss: 0.28663, val_acc: 0.96000\n",
      "Epoch [1790/10000], loss: 0.29241 acc: 0.97333 val_loss: 0.28594, val_acc: 0.96000\n",
      "Epoch [1800/10000], loss: 0.29168 acc: 0.97333 val_loss: 0.28526, val_acc: 0.96000\n",
      "Epoch [1810/10000], loss: 0.29095 acc: 0.97333 val_loss: 0.28458, val_acc: 0.96000\n",
      "Epoch [1820/10000], loss: 0.29023 acc: 0.97333 val_loss: 0.28391, val_acc: 0.96000\n",
      "Epoch [1830/10000], loss: 0.28951 acc: 0.97333 val_loss: 0.28324, val_acc: 0.96000\n",
      "Epoch [1840/10000], loss: 0.28880 acc: 0.97333 val_loss: 0.28258, val_acc: 0.96000\n",
      "Epoch [1850/10000], loss: 0.28809 acc: 0.97333 val_loss: 0.28192, val_acc: 0.96000\n",
      "Epoch [1860/10000], loss: 0.28739 acc: 0.97333 val_loss: 0.28126, val_acc: 0.96000\n",
      "Epoch [1870/10000], loss: 0.28669 acc: 0.97333 val_loss: 0.28061, val_acc: 0.96000\n",
      "Epoch [1880/10000], loss: 0.28599 acc: 0.97333 val_loss: 0.27996, val_acc: 0.96000\n",
      "Epoch [1890/10000], loss: 0.28530 acc: 0.97333 val_loss: 0.27932, val_acc: 0.96000\n",
      "Epoch [1900/10000], loss: 0.28462 acc: 0.97333 val_loss: 0.27868, val_acc: 0.96000\n",
      "Epoch [1910/10000], loss: 0.28394 acc: 0.97333 val_loss: 0.27805, val_acc: 0.96000\n",
      "Epoch [1920/10000], loss: 0.28326 acc: 0.97333 val_loss: 0.27742, val_acc: 0.96000\n",
      "Epoch [1930/10000], loss: 0.28258 acc: 0.97333 val_loss: 0.27679, val_acc: 0.96000\n",
      "Epoch [1940/10000], loss: 0.28192 acc: 0.97333 val_loss: 0.27617, val_acc: 0.96000\n",
      "Epoch [1950/10000], loss: 0.28125 acc: 0.97333 val_loss: 0.27555, val_acc: 0.96000\n",
      "Epoch [1960/10000], loss: 0.28059 acc: 0.97333 val_loss: 0.27494, val_acc: 0.96000\n",
      "Epoch [1970/10000], loss: 0.27993 acc: 0.97333 val_loss: 0.27433, val_acc: 0.96000\n",
      "Epoch [1980/10000], loss: 0.27928 acc: 0.97333 val_loss: 0.27372, val_acc: 0.96000\n",
      "Epoch [1990/10000], loss: 0.27863 acc: 0.97333 val_loss: 0.27312, val_acc: 0.96000\n",
      "Epoch [2000/10000], loss: 0.27799 acc: 0.97333 val_loss: 0.27252, val_acc: 0.96000\n",
      "Epoch [2010/10000], loss: 0.27735 acc: 0.97333 val_loss: 0.27193, val_acc: 0.96000\n",
      "Epoch [2020/10000], loss: 0.27671 acc: 0.97333 val_loss: 0.27134, val_acc: 0.96000\n",
      "Epoch [2030/10000], loss: 0.27608 acc: 0.97333 val_loss: 0.27075, val_acc: 0.96000\n",
      "Epoch [2040/10000], loss: 0.27545 acc: 0.97333 val_loss: 0.27016, val_acc: 0.96000\n",
      "Epoch [2050/10000], loss: 0.27482 acc: 0.97333 val_loss: 0.26958, val_acc: 0.96000\n",
      "Epoch [2060/10000], loss: 0.27420 acc: 0.97333 val_loss: 0.26901, val_acc: 0.96000\n",
      "Epoch [2070/10000], loss: 0.27358 acc: 0.97333 val_loss: 0.26843, val_acc: 0.96000\n",
      "Epoch [2080/10000], loss: 0.27297 acc: 0.97333 val_loss: 0.26786, val_acc: 0.96000\n",
      "Epoch [2090/10000], loss: 0.27236 acc: 0.97333 val_loss: 0.26730, val_acc: 0.96000\n",
      "Epoch [2100/10000], loss: 0.27175 acc: 0.97333 val_loss: 0.26674, val_acc: 0.96000\n",
      "Epoch [2110/10000], loss: 0.27115 acc: 0.97333 val_loss: 0.26618, val_acc: 0.96000\n",
      "Epoch [2120/10000], loss: 0.27055 acc: 0.97333 val_loss: 0.26562, val_acc: 0.96000\n",
      "Epoch [2130/10000], loss: 0.26995 acc: 0.97333 val_loss: 0.26507, val_acc: 0.96000\n",
      "Epoch [2140/10000], loss: 0.26936 acc: 0.97333 val_loss: 0.26452, val_acc: 0.96000\n",
      "Epoch [2150/10000], loss: 0.26877 acc: 0.97333 val_loss: 0.26397, val_acc: 0.96000\n",
      "Epoch [2160/10000], loss: 0.26818 acc: 0.97333 val_loss: 0.26343, val_acc: 0.96000\n",
      "Epoch [2170/10000], loss: 0.26760 acc: 0.97333 val_loss: 0.26289, val_acc: 0.96000\n",
      "Epoch [2180/10000], loss: 0.26702 acc: 0.97333 val_loss: 0.26236, val_acc: 0.96000\n",
      "Epoch [2190/10000], loss: 0.26644 acc: 0.97333 val_loss: 0.26182, val_acc: 0.96000\n",
      "Epoch [2200/10000], loss: 0.26587 acc: 0.97333 val_loss: 0.26129, val_acc: 0.96000\n",
      "Epoch [2210/10000], loss: 0.26530 acc: 0.97333 val_loss: 0.26077, val_acc: 0.96000\n",
      "Epoch [2220/10000], loss: 0.26473 acc: 0.97333 val_loss: 0.26024, val_acc: 0.96000\n",
      "Epoch [2230/10000], loss: 0.26417 acc: 0.97333 val_loss: 0.25972, val_acc: 0.96000\n",
      "Epoch [2240/10000], loss: 0.26361 acc: 0.97333 val_loss: 0.25921, val_acc: 0.96000\n",
      "Epoch [2250/10000], loss: 0.26305 acc: 0.97333 val_loss: 0.25869, val_acc: 0.96000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2260/10000], loss: 0.26250 acc: 0.97333 val_loss: 0.25818, val_acc: 0.96000\n",
      "Epoch [2270/10000], loss: 0.26195 acc: 0.97333 val_loss: 0.25767, val_acc: 0.96000\n",
      "Epoch [2280/10000], loss: 0.26140 acc: 0.97333 val_loss: 0.25717, val_acc: 0.96000\n",
      "Epoch [2290/10000], loss: 0.26086 acc: 0.97333 val_loss: 0.25666, val_acc: 0.96000\n",
      "Epoch [2300/10000], loss: 0.26032 acc: 0.97333 val_loss: 0.25616, val_acc: 0.96000\n",
      "Epoch [2310/10000], loss: 0.25978 acc: 0.97333 val_loss: 0.25567, val_acc: 0.96000\n",
      "Epoch [2320/10000], loss: 0.25924 acc: 0.97333 val_loss: 0.25517, val_acc: 0.96000\n",
      "Epoch [2330/10000], loss: 0.25871 acc: 0.97333 val_loss: 0.25468, val_acc: 0.96000\n",
      "Epoch [2340/10000], loss: 0.25818 acc: 0.97333 val_loss: 0.25419, val_acc: 0.96000\n",
      "Epoch [2350/10000], loss: 0.25766 acc: 0.97333 val_loss: 0.25371, val_acc: 0.96000\n",
      "Epoch [2360/10000], loss: 0.25713 acc: 0.97333 val_loss: 0.25322, val_acc: 0.96000\n",
      "Epoch [2370/10000], loss: 0.25661 acc: 0.97333 val_loss: 0.25274, val_acc: 0.96000\n",
      "Epoch [2380/10000], loss: 0.25609 acc: 0.97333 val_loss: 0.25227, val_acc: 0.96000\n",
      "Epoch [2390/10000], loss: 0.25558 acc: 0.97333 val_loss: 0.25179, val_acc: 0.96000\n",
      "Epoch [2400/10000], loss: 0.25507 acc: 0.97333 val_loss: 0.25132, val_acc: 0.96000\n",
      "Epoch [2410/10000], loss: 0.25456 acc: 0.97333 val_loss: 0.25085, val_acc: 0.96000\n",
      "Epoch [2420/10000], loss: 0.25405 acc: 0.97333 val_loss: 0.25038, val_acc: 0.96000\n",
      "Epoch [2430/10000], loss: 0.25355 acc: 0.97333 val_loss: 0.24992, val_acc: 0.96000\n",
      "Epoch [2440/10000], loss: 0.25304 acc: 0.97333 val_loss: 0.24946, val_acc: 0.96000\n",
      "Epoch [2450/10000], loss: 0.25255 acc: 0.97333 val_loss: 0.24900, val_acc: 0.96000\n",
      "Epoch [2460/10000], loss: 0.25205 acc: 0.97333 val_loss: 0.24854, val_acc: 0.96000\n",
      "Epoch [2470/10000], loss: 0.25156 acc: 0.97333 val_loss: 0.24809, val_acc: 0.96000\n",
      "Epoch [2480/10000], loss: 0.25107 acc: 0.97333 val_loss: 0.24764, val_acc: 0.96000\n",
      "Epoch [2490/10000], loss: 0.25058 acc: 0.97333 val_loss: 0.24719, val_acc: 0.96000\n",
      "Epoch [2500/10000], loss: 0.25009 acc: 0.97333 val_loss: 0.24674, val_acc: 0.96000\n",
      "Epoch [2510/10000], loss: 0.24961 acc: 0.97333 val_loss: 0.24630, val_acc: 0.96000\n",
      "Epoch [2520/10000], loss: 0.24913 acc: 0.97333 val_loss: 0.24585, val_acc: 0.96000\n",
      "Epoch [2530/10000], loss: 0.24865 acc: 0.97333 val_loss: 0.24541, val_acc: 0.96000\n",
      "Epoch [2540/10000], loss: 0.24818 acc: 0.97333 val_loss: 0.24498, val_acc: 0.96000\n",
      "Epoch [2550/10000], loss: 0.24770 acc: 0.97333 val_loss: 0.24454, val_acc: 0.96000\n",
      "Epoch [2560/10000], loss: 0.24723 acc: 0.97333 val_loss: 0.24411, val_acc: 0.96000\n",
      "Epoch [2570/10000], loss: 0.24676 acc: 0.97333 val_loss: 0.24368, val_acc: 0.96000\n",
      "Epoch [2580/10000], loss: 0.24630 acc: 0.98667 val_loss: 0.24325, val_acc: 0.96000\n",
      "Epoch [2590/10000], loss: 0.24584 acc: 0.98667 val_loss: 0.24283, val_acc: 0.96000\n",
      "Epoch [2600/10000], loss: 0.24537 acc: 0.98667 val_loss: 0.24240, val_acc: 0.96000\n",
      "Epoch [2610/10000], loss: 0.24492 acc: 0.98667 val_loss: 0.24198, val_acc: 0.96000\n",
      "Epoch [2620/10000], loss: 0.24446 acc: 0.98667 val_loss: 0.24156, val_acc: 0.96000\n",
      "Epoch [2630/10000], loss: 0.24401 acc: 0.98667 val_loss: 0.24115, val_acc: 0.96000\n",
      "Epoch [2640/10000], loss: 0.24355 acc: 0.98667 val_loss: 0.24073, val_acc: 0.96000\n",
      "Epoch [2650/10000], loss: 0.24311 acc: 0.98667 val_loss: 0.24032, val_acc: 0.96000\n",
      "Epoch [2660/10000], loss: 0.24266 acc: 0.98667 val_loss: 0.23991, val_acc: 0.96000\n",
      "Epoch [2670/10000], loss: 0.24221 acc: 0.98667 val_loss: 0.23950, val_acc: 0.96000\n",
      "Epoch [2680/10000], loss: 0.24177 acc: 0.98667 val_loss: 0.23909, val_acc: 0.96000\n",
      "Epoch [2690/10000], loss: 0.24133 acc: 0.98667 val_loss: 0.23869, val_acc: 0.96000\n",
      "Epoch [2700/10000], loss: 0.24089 acc: 0.98667 val_loss: 0.23829, val_acc: 0.96000\n",
      "Epoch [2710/10000], loss: 0.24046 acc: 0.98667 val_loss: 0.23789, val_acc: 0.96000\n",
      "Epoch [2720/10000], loss: 0.24002 acc: 0.98667 val_loss: 0.23749, val_acc: 0.96000\n",
      "Epoch [2730/10000], loss: 0.23959 acc: 0.98667 val_loss: 0.23710, val_acc: 0.96000\n",
      "Epoch [2740/10000], loss: 0.23916 acc: 0.98667 val_loss: 0.23670, val_acc: 0.96000\n",
      "Epoch [2750/10000], loss: 0.23874 acc: 0.98667 val_loss: 0.23631, val_acc: 0.96000\n",
      "Epoch [2760/10000], loss: 0.23831 acc: 0.98667 val_loss: 0.23592, val_acc: 0.96000\n",
      "Epoch [2770/10000], loss: 0.23789 acc: 0.98667 val_loss: 0.23553, val_acc: 0.96000\n",
      "Epoch [2780/10000], loss: 0.23747 acc: 0.98667 val_loss: 0.23515, val_acc: 0.96000\n",
      "Epoch [2790/10000], loss: 0.23705 acc: 0.98667 val_loss: 0.23476, val_acc: 0.96000\n",
      "Epoch [2800/10000], loss: 0.23663 acc: 0.98667 val_loss: 0.23438, val_acc: 0.96000\n",
      "Epoch [2810/10000], loss: 0.23622 acc: 0.98667 val_loss: 0.23400, val_acc: 0.96000\n",
      "Epoch [2820/10000], loss: 0.23580 acc: 0.98667 val_loss: 0.23363, val_acc: 0.96000\n",
      "Epoch [2830/10000], loss: 0.23539 acc: 0.98667 val_loss: 0.23325, val_acc: 0.96000\n",
      "Epoch [2840/10000], loss: 0.23498 acc: 0.98667 val_loss: 0.23288, val_acc: 0.96000\n",
      "Epoch [2850/10000], loss: 0.23458 acc: 0.98667 val_loss: 0.23250, val_acc: 0.96000\n",
      "Epoch [2860/10000], loss: 0.23417 acc: 0.98667 val_loss: 0.23213, val_acc: 0.96000\n",
      "Epoch [2870/10000], loss: 0.23377 acc: 0.98667 val_loss: 0.23176, val_acc: 0.96000\n",
      "Epoch [2880/10000], loss: 0.23337 acc: 0.98667 val_loss: 0.23140, val_acc: 0.96000\n",
      "Epoch [2890/10000], loss: 0.23297 acc: 0.98667 val_loss: 0.23103, val_acc: 0.96000\n",
      "Epoch [2900/10000], loss: 0.23257 acc: 0.98667 val_loss: 0.23067, val_acc: 0.96000\n",
      "Epoch [2910/10000], loss: 0.23218 acc: 0.98667 val_loss: 0.23031, val_acc: 0.96000\n",
      "Epoch [2920/10000], loss: 0.23178 acc: 0.98667 val_loss: 0.22995, val_acc: 0.96000\n",
      "Epoch [2930/10000], loss: 0.23139 acc: 0.98667 val_loss: 0.22959, val_acc: 0.96000\n",
      "Epoch [2940/10000], loss: 0.23100 acc: 0.98667 val_loss: 0.22923, val_acc: 0.96000\n",
      "Epoch [2950/10000], loss: 0.23061 acc: 0.98667 val_loss: 0.22888, val_acc: 0.96000\n",
      "Epoch [2960/10000], loss: 0.23023 acc: 0.98667 val_loss: 0.22853, val_acc: 0.96000\n",
      "Epoch [2970/10000], loss: 0.22984 acc: 0.98667 val_loss: 0.22818, val_acc: 0.96000\n",
      "Epoch [2980/10000], loss: 0.22946 acc: 0.98667 val_loss: 0.22783, val_acc: 0.96000\n",
      "Epoch [2990/10000], loss: 0.22908 acc: 0.98667 val_loss: 0.22748, val_acc: 0.96000\n",
      "Epoch [3000/10000], loss: 0.22870 acc: 0.98667 val_loss: 0.22713, val_acc: 0.96000\n",
      "Epoch [3010/10000], loss: 0.22832 acc: 0.98667 val_loss: 0.22679, val_acc: 0.96000\n",
      "Epoch [3020/10000], loss: 0.22795 acc: 0.98667 val_loss: 0.22645, val_acc: 0.96000\n",
      "Epoch [3030/10000], loss: 0.22757 acc: 0.98667 val_loss: 0.22610, val_acc: 0.96000\n",
      "Epoch [3040/10000], loss: 0.22720 acc: 0.98667 val_loss: 0.22577, val_acc: 0.96000\n",
      "Epoch [3050/10000], loss: 0.22683 acc: 0.98667 val_loss: 0.22543, val_acc: 0.96000\n",
      "Epoch [3060/10000], loss: 0.22646 acc: 0.98667 val_loss: 0.22509, val_acc: 0.96000\n",
      "Epoch [3070/10000], loss: 0.22610 acc: 0.98667 val_loss: 0.22476, val_acc: 0.96000\n",
      "Epoch [3080/10000], loss: 0.22573 acc: 0.98667 val_loss: 0.22442, val_acc: 0.96000\n",
      "Epoch [3090/10000], loss: 0.22537 acc: 0.98667 val_loss: 0.22409, val_acc: 0.96000\n",
      "Epoch [3100/10000], loss: 0.22501 acc: 0.98667 val_loss: 0.22376, val_acc: 0.96000\n",
      "Epoch [3110/10000], loss: 0.22465 acc: 0.98667 val_loss: 0.22343, val_acc: 0.96000\n",
      "Epoch [3120/10000], loss: 0.22429 acc: 0.98667 val_loss: 0.22311, val_acc: 0.96000\n",
      "Epoch [3130/10000], loss: 0.22393 acc: 0.98667 val_loss: 0.22278, val_acc: 0.96000\n",
      "Epoch [3140/10000], loss: 0.22357 acc: 0.98667 val_loss: 0.22246, val_acc: 0.96000\n",
      "Epoch [3150/10000], loss: 0.22322 acc: 0.98667 val_loss: 0.22214, val_acc: 0.96000\n",
      "Epoch [3160/10000], loss: 0.22287 acc: 0.98667 val_loss: 0.22181, val_acc: 0.96000\n",
      "Epoch [3170/10000], loss: 0.22252 acc: 0.98667 val_loss: 0.22150, val_acc: 0.96000\n",
      "Epoch [3180/10000], loss: 0.22217 acc: 0.98667 val_loss: 0.22118, val_acc: 0.96000\n",
      "Epoch [3190/10000], loss: 0.22182 acc: 0.98667 val_loss: 0.22086, val_acc: 0.96000\n",
      "Epoch [3200/10000], loss: 0.22148 acc: 0.98667 val_loss: 0.22055, val_acc: 0.96000\n",
      "Epoch [3210/10000], loss: 0.22113 acc: 0.98667 val_loss: 0.22023, val_acc: 0.96000\n",
      "Epoch [3220/10000], loss: 0.22079 acc: 0.98667 val_loss: 0.21992, val_acc: 0.96000\n",
      "Epoch [3230/10000], loss: 0.22045 acc: 0.98667 val_loss: 0.21961, val_acc: 0.96000\n",
      "Epoch [3240/10000], loss: 0.22011 acc: 0.98667 val_loss: 0.21930, val_acc: 0.96000\n",
      "Epoch [3250/10000], loss: 0.21977 acc: 0.98667 val_loss: 0.21899, val_acc: 0.96000\n",
      "Epoch [3260/10000], loss: 0.21943 acc: 0.98667 val_loss: 0.21869, val_acc: 0.96000\n",
      "Epoch [3270/10000], loss: 0.21910 acc: 0.98667 val_loss: 0.21838, val_acc: 0.96000\n",
      "Epoch [3280/10000], loss: 0.21876 acc: 0.98667 val_loss: 0.21808, val_acc: 0.96000\n",
      "Epoch [3290/10000], loss: 0.21843 acc: 0.98667 val_loss: 0.21778, val_acc: 0.96000\n",
      "Epoch [3300/10000], loss: 0.21810 acc: 0.98667 val_loss: 0.21747, val_acc: 0.96000\n",
      "Epoch [3310/10000], loss: 0.21777 acc: 0.98667 val_loss: 0.21717, val_acc: 0.96000\n",
      "Epoch [3320/10000], loss: 0.21744 acc: 0.98667 val_loss: 0.21688, val_acc: 0.96000\n",
      "Epoch [3330/10000], loss: 0.21711 acc: 0.98667 val_loss: 0.21658, val_acc: 0.96000\n",
      "Epoch [3340/10000], loss: 0.21679 acc: 0.98667 val_loss: 0.21628, val_acc: 0.96000\n",
      "Epoch [3350/10000], loss: 0.21646 acc: 0.98667 val_loss: 0.21599, val_acc: 0.96000\n",
      "Epoch [3360/10000], loss: 0.21614 acc: 0.98667 val_loss: 0.21570, val_acc: 0.96000\n",
      "Epoch [3370/10000], loss: 0.21582 acc: 0.98667 val_loss: 0.21540, val_acc: 0.96000\n",
      "Epoch [3380/10000], loss: 0.21550 acc: 0.98667 val_loss: 0.21511, val_acc: 0.96000\n",
      "Epoch [3390/10000], loss: 0.21518 acc: 0.98667 val_loss: 0.21482, val_acc: 0.96000\n",
      "Epoch [3400/10000], loss: 0.21487 acc: 0.98667 val_loss: 0.21454, val_acc: 0.96000\n",
      "Epoch [3410/10000], loss: 0.21455 acc: 0.98667 val_loss: 0.21425, val_acc: 0.96000\n",
      "Epoch [3420/10000], loss: 0.21424 acc: 0.98667 val_loss: 0.21397, val_acc: 0.96000\n",
      "Epoch [3430/10000], loss: 0.21392 acc: 0.98667 val_loss: 0.21368, val_acc: 0.96000\n",
      "Epoch [3440/10000], loss: 0.21361 acc: 0.98667 val_loss: 0.21340, val_acc: 0.96000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3450/10000], loss: 0.21330 acc: 0.98667 val_loss: 0.21312, val_acc: 0.96000\n",
      "Epoch [3460/10000], loss: 0.21299 acc: 0.98667 val_loss: 0.21284, val_acc: 0.96000\n",
      "Epoch [3470/10000], loss: 0.21268 acc: 0.98667 val_loss: 0.21256, val_acc: 0.96000\n",
      "Epoch [3480/10000], loss: 0.21238 acc: 0.98667 val_loss: 0.21228, val_acc: 0.96000\n",
      "Epoch [3490/10000], loss: 0.21207 acc: 0.98667 val_loss: 0.21200, val_acc: 0.96000\n",
      "Epoch [3500/10000], loss: 0.21177 acc: 0.98667 val_loss: 0.21173, val_acc: 0.96000\n",
      "Epoch [3510/10000], loss: 0.21146 acc: 0.98667 val_loss: 0.21145, val_acc: 0.96000\n",
      "Epoch [3520/10000], loss: 0.21116 acc: 0.98667 val_loss: 0.21118, val_acc: 0.96000\n",
      "Epoch [3530/10000], loss: 0.21086 acc: 0.98667 val_loss: 0.21091, val_acc: 0.96000\n",
      "Epoch [3540/10000], loss: 0.21056 acc: 0.98667 val_loss: 0.21064, val_acc: 0.96000\n",
      "Epoch [3550/10000], loss: 0.21026 acc: 0.98667 val_loss: 0.21037, val_acc: 0.96000\n",
      "Epoch [3560/10000], loss: 0.20997 acc: 0.98667 val_loss: 0.21010, val_acc: 0.96000\n",
      "Epoch [3570/10000], loss: 0.20967 acc: 0.98667 val_loss: 0.20983, val_acc: 0.96000\n",
      "Epoch [3580/10000], loss: 0.20938 acc: 0.98667 val_loss: 0.20956, val_acc: 0.96000\n",
      "Epoch [3590/10000], loss: 0.20909 acc: 0.98667 val_loss: 0.20930, val_acc: 0.96000\n",
      "Epoch [3600/10000], loss: 0.20879 acc: 0.98667 val_loss: 0.20903, val_acc: 0.96000\n",
      "Epoch [3610/10000], loss: 0.20850 acc: 0.98667 val_loss: 0.20877, val_acc: 0.96000\n",
      "Epoch [3620/10000], loss: 0.20821 acc: 0.98667 val_loss: 0.20851, val_acc: 0.96000\n",
      "Epoch [3630/10000], loss: 0.20793 acc: 0.98667 val_loss: 0.20825, val_acc: 0.96000\n",
      "Epoch [3640/10000], loss: 0.20764 acc: 0.98667 val_loss: 0.20799, val_acc: 0.96000\n",
      "Epoch [3650/10000], loss: 0.20735 acc: 0.98667 val_loss: 0.20773, val_acc: 0.96000\n",
      "Epoch [3660/10000], loss: 0.20707 acc: 0.98667 val_loss: 0.20747, val_acc: 0.96000\n",
      "Epoch [3670/10000], loss: 0.20678 acc: 0.98667 val_loss: 0.20721, val_acc: 0.96000\n",
      "Epoch [3680/10000], loss: 0.20650 acc: 0.98667 val_loss: 0.20696, val_acc: 0.96000\n",
      "Epoch [3690/10000], loss: 0.20622 acc: 0.98667 val_loss: 0.20670, val_acc: 0.96000\n",
      "Epoch [3700/10000], loss: 0.20594 acc: 0.98667 val_loss: 0.20645, val_acc: 0.96000\n",
      "Epoch [3710/10000], loss: 0.20566 acc: 0.98667 val_loss: 0.20620, val_acc: 0.96000\n",
      "Epoch [3720/10000], loss: 0.20538 acc: 0.98667 val_loss: 0.20595, val_acc: 0.96000\n",
      "Epoch [3730/10000], loss: 0.20511 acc: 0.98667 val_loss: 0.20570, val_acc: 0.96000\n",
      "Epoch [3740/10000], loss: 0.20483 acc: 0.98667 val_loss: 0.20545, val_acc: 0.96000\n",
      "Epoch [3750/10000], loss: 0.20455 acc: 0.98667 val_loss: 0.20520, val_acc: 0.96000\n",
      "Epoch [3760/10000], loss: 0.20428 acc: 0.98667 val_loss: 0.20495, val_acc: 0.96000\n",
      "Epoch [3770/10000], loss: 0.20401 acc: 0.98667 val_loss: 0.20471, val_acc: 0.96000\n",
      "Epoch [3780/10000], loss: 0.20374 acc: 0.98667 val_loss: 0.20446, val_acc: 0.96000\n",
      "Epoch [3790/10000], loss: 0.20347 acc: 0.98667 val_loss: 0.20422, val_acc: 0.96000\n",
      "Epoch [3800/10000], loss: 0.20320 acc: 0.98667 val_loss: 0.20397, val_acc: 0.96000\n",
      "Epoch [3810/10000], loss: 0.20293 acc: 0.98667 val_loss: 0.20373, val_acc: 0.96000\n",
      "Epoch [3820/10000], loss: 0.20266 acc: 0.98667 val_loss: 0.20349, val_acc: 0.96000\n",
      "Epoch [3830/10000], loss: 0.20239 acc: 0.98667 val_loss: 0.20325, val_acc: 0.96000\n",
      "Epoch [3840/10000], loss: 0.20213 acc: 0.98667 val_loss: 0.20301, val_acc: 0.96000\n",
      "Epoch [3850/10000], loss: 0.20186 acc: 0.98667 val_loss: 0.20277, val_acc: 0.96000\n",
      "Epoch [3860/10000], loss: 0.20160 acc: 0.98667 val_loss: 0.20253, val_acc: 0.96000\n",
      "Epoch [3870/10000], loss: 0.20134 acc: 0.98667 val_loss: 0.20230, val_acc: 0.96000\n",
      "Epoch [3880/10000], loss: 0.20108 acc: 0.98667 val_loss: 0.20206, val_acc: 0.96000\n",
      "Epoch [3890/10000], loss: 0.20082 acc: 0.98667 val_loss: 0.20183, val_acc: 0.96000\n",
      "Epoch [3900/10000], loss: 0.20056 acc: 0.98667 val_loss: 0.20159, val_acc: 0.96000\n",
      "Epoch [3910/10000], loss: 0.20030 acc: 0.98667 val_loss: 0.20136, val_acc: 0.96000\n",
      "Epoch [3920/10000], loss: 0.20004 acc: 0.98667 val_loss: 0.20113, val_acc: 0.96000\n",
      "Epoch [3930/10000], loss: 0.19979 acc: 0.98667 val_loss: 0.20090, val_acc: 0.96000\n",
      "Epoch [3940/10000], loss: 0.19953 acc: 0.98667 val_loss: 0.20067, val_acc: 0.96000\n",
      "Epoch [3950/10000], loss: 0.19928 acc: 0.98667 val_loss: 0.20044, val_acc: 0.96000\n",
      "Epoch [3960/10000], loss: 0.19902 acc: 0.98667 val_loss: 0.20021, val_acc: 0.96000\n",
      "Epoch [3970/10000], loss: 0.19877 acc: 0.98667 val_loss: 0.19998, val_acc: 0.96000\n",
      "Epoch [3980/10000], loss: 0.19852 acc: 0.98667 val_loss: 0.19976, val_acc: 0.96000\n",
      "Epoch [3990/10000], loss: 0.19827 acc: 0.98667 val_loss: 0.19953, val_acc: 0.96000\n",
      "Epoch [4000/10000], loss: 0.19802 acc: 0.98667 val_loss: 0.19931, val_acc: 0.96000\n",
      "Epoch [4010/10000], loss: 0.19777 acc: 0.98667 val_loss: 0.19908, val_acc: 0.96000\n",
      "Epoch [4020/10000], loss: 0.19752 acc: 0.98667 val_loss: 0.19886, val_acc: 0.96000\n",
      "Epoch [4030/10000], loss: 0.19728 acc: 0.98667 val_loss: 0.19864, val_acc: 0.96000\n",
      "Epoch [4040/10000], loss: 0.19703 acc: 0.98667 val_loss: 0.19842, val_acc: 0.96000\n",
      "Epoch [4050/10000], loss: 0.19679 acc: 0.98667 val_loss: 0.19820, val_acc: 0.96000\n",
      "Epoch [4060/10000], loss: 0.19654 acc: 0.98667 val_loss: 0.19798, val_acc: 0.96000\n",
      "Epoch [4070/10000], loss: 0.19630 acc: 0.98667 val_loss: 0.19776, val_acc: 0.96000\n",
      "Epoch [4080/10000], loss: 0.19606 acc: 0.98667 val_loss: 0.19754, val_acc: 0.96000\n",
      "Epoch [4090/10000], loss: 0.19582 acc: 0.98667 val_loss: 0.19732, val_acc: 0.96000\n",
      "Epoch [4100/10000], loss: 0.19557 acc: 0.98667 val_loss: 0.19711, val_acc: 0.96000\n",
      "Epoch [4110/10000], loss: 0.19534 acc: 0.98667 val_loss: 0.19689, val_acc: 0.96000\n",
      "Epoch [4120/10000], loss: 0.19510 acc: 0.98667 val_loss: 0.19668, val_acc: 0.96000\n",
      "Epoch [4130/10000], loss: 0.19486 acc: 0.98667 val_loss: 0.19646, val_acc: 0.96000\n",
      "Epoch [4140/10000], loss: 0.19462 acc: 0.98667 val_loss: 0.19625, val_acc: 0.96000\n",
      "Epoch [4150/10000], loss: 0.19439 acc: 0.98667 val_loss: 0.19604, val_acc: 0.96000\n",
      "Epoch [4160/10000], loss: 0.19415 acc: 0.98667 val_loss: 0.19583, val_acc: 0.96000\n",
      "Epoch [4170/10000], loss: 0.19392 acc: 0.98667 val_loss: 0.19562, val_acc: 0.96000\n",
      "Epoch [4180/10000], loss: 0.19368 acc: 0.98667 val_loss: 0.19541, val_acc: 0.96000\n",
      "Epoch [4190/10000], loss: 0.19345 acc: 0.98667 val_loss: 0.19520, val_acc: 0.96000\n",
      "Epoch [4200/10000], loss: 0.19322 acc: 0.98667 val_loss: 0.19499, val_acc: 0.96000\n",
      "Epoch [4210/10000], loss: 0.19299 acc: 0.98667 val_loss: 0.19478, val_acc: 0.96000\n",
      "Epoch [4220/10000], loss: 0.19276 acc: 0.98667 val_loss: 0.19457, val_acc: 0.96000\n",
      "Epoch [4230/10000], loss: 0.19253 acc: 0.98667 val_loss: 0.19437, val_acc: 0.96000\n",
      "Epoch [4240/10000], loss: 0.19230 acc: 0.98667 val_loss: 0.19416, val_acc: 0.96000\n",
      "Epoch [4250/10000], loss: 0.19207 acc: 0.98667 val_loss: 0.19396, val_acc: 0.96000\n",
      "Epoch [4260/10000], loss: 0.19184 acc: 0.98667 val_loss: 0.19376, val_acc: 0.96000\n",
      "Epoch [4270/10000], loss: 0.19162 acc: 0.98667 val_loss: 0.19355, val_acc: 0.96000\n",
      "Epoch [4280/10000], loss: 0.19139 acc: 0.98667 val_loss: 0.19335, val_acc: 0.96000\n",
      "Epoch [4290/10000], loss: 0.19117 acc: 0.98667 val_loss: 0.19315, val_acc: 0.96000\n",
      "Epoch [4300/10000], loss: 0.19094 acc: 0.98667 val_loss: 0.19295, val_acc: 0.96000\n",
      "Epoch [4310/10000], loss: 0.19072 acc: 0.98667 val_loss: 0.19275, val_acc: 0.96000\n",
      "Epoch [4320/10000], loss: 0.19050 acc: 0.98667 val_loss: 0.19255, val_acc: 0.96000\n",
      "Epoch [4330/10000], loss: 0.19028 acc: 0.98667 val_loss: 0.19235, val_acc: 0.96000\n",
      "Epoch [4340/10000], loss: 0.19006 acc: 0.98667 val_loss: 0.19215, val_acc: 0.96000\n",
      "Epoch [4350/10000], loss: 0.18984 acc: 0.98667 val_loss: 0.19196, val_acc: 0.96000\n",
      "Epoch [4360/10000], loss: 0.18962 acc: 0.98667 val_loss: 0.19176, val_acc: 0.96000\n",
      "Epoch [4370/10000], loss: 0.18940 acc: 0.98667 val_loss: 0.19156, val_acc: 0.96000\n",
      "Epoch [4380/10000], loss: 0.18918 acc: 0.98667 val_loss: 0.19137, val_acc: 0.96000\n",
      "Epoch [4390/10000], loss: 0.18897 acc: 0.98667 val_loss: 0.19118, val_acc: 0.96000\n",
      "Epoch [4400/10000], loss: 0.18875 acc: 0.98667 val_loss: 0.19098, val_acc: 0.96000\n",
      "Epoch [4410/10000], loss: 0.18853 acc: 0.98667 val_loss: 0.19079, val_acc: 0.96000\n",
      "Epoch [4420/10000], loss: 0.18832 acc: 0.98667 val_loss: 0.19060, val_acc: 0.96000\n",
      "Epoch [4430/10000], loss: 0.18811 acc: 0.98667 val_loss: 0.19041, val_acc: 0.96000\n",
      "Epoch [4440/10000], loss: 0.18789 acc: 0.98667 val_loss: 0.19021, val_acc: 0.96000\n",
      "Epoch [4450/10000], loss: 0.18768 acc: 0.98667 val_loss: 0.19002, val_acc: 0.96000\n",
      "Epoch [4460/10000], loss: 0.18747 acc: 0.98667 val_loss: 0.18984, val_acc: 0.96000\n",
      "Epoch [4470/10000], loss: 0.18726 acc: 0.98667 val_loss: 0.18965, val_acc: 0.96000\n",
      "Epoch [4480/10000], loss: 0.18705 acc: 0.98667 val_loss: 0.18946, val_acc: 0.96000\n",
      "Epoch [4490/10000], loss: 0.18684 acc: 0.98667 val_loss: 0.18927, val_acc: 0.96000\n",
      "Epoch [4500/10000], loss: 0.18663 acc: 0.98667 val_loss: 0.18908, val_acc: 0.96000\n",
      "Epoch [4510/10000], loss: 0.18642 acc: 0.98667 val_loss: 0.18890, val_acc: 0.96000\n",
      "Epoch [4520/10000], loss: 0.18622 acc: 0.98667 val_loss: 0.18871, val_acc: 0.96000\n",
      "Epoch [4530/10000], loss: 0.18601 acc: 0.98667 val_loss: 0.18853, val_acc: 0.96000\n",
      "Epoch [4540/10000], loss: 0.18580 acc: 0.98667 val_loss: 0.18834, val_acc: 0.96000\n",
      "Epoch [4550/10000], loss: 0.18560 acc: 0.98667 val_loss: 0.18816, val_acc: 0.96000\n",
      "Epoch [4560/10000], loss: 0.18539 acc: 0.98667 val_loss: 0.18798, val_acc: 0.96000\n",
      "Epoch [4570/10000], loss: 0.18519 acc: 0.98667 val_loss: 0.18780, val_acc: 0.96000\n",
      "Epoch [4580/10000], loss: 0.18499 acc: 0.98667 val_loss: 0.18761, val_acc: 0.96000\n",
      "Epoch [4590/10000], loss: 0.18478 acc: 0.98667 val_loss: 0.18743, val_acc: 0.96000\n",
      "Epoch [4600/10000], loss: 0.18458 acc: 0.98667 val_loss: 0.18725, val_acc: 0.96000\n",
      "Epoch [4610/10000], loss: 0.18438 acc: 0.98667 val_loss: 0.18707, val_acc: 0.96000\n",
      "Epoch [4620/10000], loss: 0.18418 acc: 0.98667 val_loss: 0.18690, val_acc: 0.96000\n",
      "Epoch [4630/10000], loss: 0.18398 acc: 0.98667 val_loss: 0.18672, val_acc: 0.96000\n",
      "Epoch [4640/10000], loss: 0.18378 acc: 0.98667 val_loss: 0.18654, val_acc: 0.96000\n",
      "Epoch [4650/10000], loss: 0.18358 acc: 0.98667 val_loss: 0.18636, val_acc: 0.96000\n",
      "Epoch [4660/10000], loss: 0.18339 acc: 0.98667 val_loss: 0.18619, val_acc: 0.96000\n",
      "Epoch [4670/10000], loss: 0.18319 acc: 0.98667 val_loss: 0.18601, val_acc: 0.96000\n",
      "Epoch [4680/10000], loss: 0.18299 acc: 0.98667 val_loss: 0.18583, val_acc: 0.96000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4690/10000], loss: 0.18280 acc: 0.98667 val_loss: 0.18566, val_acc: 0.96000\n",
      "Epoch [4700/10000], loss: 0.18260 acc: 0.98667 val_loss: 0.18549, val_acc: 0.96000\n",
      "Epoch [4710/10000], loss: 0.18241 acc: 0.98667 val_loss: 0.18531, val_acc: 0.96000\n",
      "Epoch [4720/10000], loss: 0.18221 acc: 0.98667 val_loss: 0.18514, val_acc: 0.96000\n",
      "Epoch [4730/10000], loss: 0.18202 acc: 0.98667 val_loss: 0.18497, val_acc: 0.96000\n",
      "Epoch [4740/10000], loss: 0.18183 acc: 0.98667 val_loss: 0.18480, val_acc: 0.96000\n",
      "Epoch [4750/10000], loss: 0.18164 acc: 0.98667 val_loss: 0.18462, val_acc: 0.96000\n",
      "Epoch [4760/10000], loss: 0.18144 acc: 0.98667 val_loss: 0.18445, val_acc: 0.96000\n",
      "Epoch [4770/10000], loss: 0.18125 acc: 0.98667 val_loss: 0.18428, val_acc: 0.96000\n",
      "Epoch [4780/10000], loss: 0.18106 acc: 0.98667 val_loss: 0.18411, val_acc: 0.96000\n",
      "Epoch [4790/10000], loss: 0.18087 acc: 0.98667 val_loss: 0.18395, val_acc: 0.96000\n",
      "Epoch [4800/10000], loss: 0.18068 acc: 0.98667 val_loss: 0.18378, val_acc: 0.96000\n",
      "Epoch [4810/10000], loss: 0.18050 acc: 0.98667 val_loss: 0.18361, val_acc: 0.96000\n",
      "Epoch [4820/10000], loss: 0.18031 acc: 0.98667 val_loss: 0.18344, val_acc: 0.96000\n",
      "Epoch [4830/10000], loss: 0.18012 acc: 0.98667 val_loss: 0.18328, val_acc: 0.96000\n",
      "Epoch [4840/10000], loss: 0.17994 acc: 0.98667 val_loss: 0.18311, val_acc: 0.96000\n",
      "Epoch [4850/10000], loss: 0.17975 acc: 0.98667 val_loss: 0.18294, val_acc: 0.96000\n",
      "Epoch [4860/10000], loss: 0.17956 acc: 0.98667 val_loss: 0.18278, val_acc: 0.96000\n",
      "Epoch [4870/10000], loss: 0.17938 acc: 0.98667 val_loss: 0.18261, val_acc: 0.96000\n",
      "Epoch [4880/10000], loss: 0.17920 acc: 0.98667 val_loss: 0.18245, val_acc: 0.96000\n",
      "Epoch [4890/10000], loss: 0.17901 acc: 0.98667 val_loss: 0.18229, val_acc: 0.96000\n",
      "Epoch [4900/10000], loss: 0.17883 acc: 0.98667 val_loss: 0.18212, val_acc: 0.96000\n",
      "Epoch [4910/10000], loss: 0.17865 acc: 0.98667 val_loss: 0.18196, val_acc: 0.96000\n",
      "Epoch [4920/10000], loss: 0.17846 acc: 0.98667 val_loss: 0.18180, val_acc: 0.96000\n",
      "Epoch [4930/10000], loss: 0.17828 acc: 0.98667 val_loss: 0.18164, val_acc: 0.96000\n",
      "Epoch [4940/10000], loss: 0.17810 acc: 0.98667 val_loss: 0.18148, val_acc: 0.96000\n",
      "Epoch [4950/10000], loss: 0.17792 acc: 0.98667 val_loss: 0.18132, val_acc: 0.96000\n",
      "Epoch [4960/10000], loss: 0.17774 acc: 0.98667 val_loss: 0.18116, val_acc: 0.96000\n",
      "Epoch [4970/10000], loss: 0.17756 acc: 0.98667 val_loss: 0.18100, val_acc: 0.96000\n",
      "Epoch [4980/10000], loss: 0.17739 acc: 0.98667 val_loss: 0.18084, val_acc: 0.96000\n",
      "Epoch [4990/10000], loss: 0.17721 acc: 0.98667 val_loss: 0.18068, val_acc: 0.96000\n",
      "Epoch [5000/10000], loss: 0.17703 acc: 0.98667 val_loss: 0.18053, val_acc: 0.96000\n",
      "Epoch [5010/10000], loss: 0.17685 acc: 0.98667 val_loss: 0.18037, val_acc: 0.96000\n",
      "Epoch [5020/10000], loss: 0.17668 acc: 0.98667 val_loss: 0.18021, val_acc: 0.96000\n",
      "Epoch [5030/10000], loss: 0.17650 acc: 0.98667 val_loss: 0.18006, val_acc: 0.96000\n",
      "Epoch [5040/10000], loss: 0.17633 acc: 0.98667 val_loss: 0.17990, val_acc: 0.96000\n",
      "Epoch [5050/10000], loss: 0.17615 acc: 0.98667 val_loss: 0.17975, val_acc: 0.96000\n",
      "Epoch [5060/10000], loss: 0.17598 acc: 0.98667 val_loss: 0.17959, val_acc: 0.96000\n",
      "Epoch [5070/10000], loss: 0.17581 acc: 0.98667 val_loss: 0.17944, val_acc: 0.96000\n",
      "Epoch [5080/10000], loss: 0.17563 acc: 0.98667 val_loss: 0.17928, val_acc: 0.96000\n",
      "Epoch [5090/10000], loss: 0.17546 acc: 0.98667 val_loss: 0.17913, val_acc: 0.96000\n",
      "Epoch [5100/10000], loss: 0.17529 acc: 0.98667 val_loss: 0.17898, val_acc: 0.96000\n",
      "Epoch [5110/10000], loss: 0.17512 acc: 0.98667 val_loss: 0.17883, val_acc: 0.96000\n",
      "Epoch [5120/10000], loss: 0.17495 acc: 0.98667 val_loss: 0.17867, val_acc: 0.96000\n",
      "Epoch [5130/10000], loss: 0.17478 acc: 0.98667 val_loss: 0.17852, val_acc: 0.96000\n",
      "Epoch [5140/10000], loss: 0.17461 acc: 0.98667 val_loss: 0.17837, val_acc: 0.96000\n",
      "Epoch [5150/10000], loss: 0.17444 acc: 0.98667 val_loss: 0.17822, val_acc: 0.96000\n",
      "Epoch [5160/10000], loss: 0.17427 acc: 0.98667 val_loss: 0.17807, val_acc: 0.96000\n",
      "Epoch [5170/10000], loss: 0.17410 acc: 0.98667 val_loss: 0.17792, val_acc: 0.96000\n",
      "Epoch [5180/10000], loss: 0.17393 acc: 0.98667 val_loss: 0.17778, val_acc: 0.96000\n",
      "Epoch [5190/10000], loss: 0.17377 acc: 0.98667 val_loss: 0.17763, val_acc: 0.96000\n",
      "Epoch [5200/10000], loss: 0.17360 acc: 0.98667 val_loss: 0.17748, val_acc: 0.96000\n",
      "Epoch [5210/10000], loss: 0.17343 acc: 0.98667 val_loss: 0.17733, val_acc: 0.96000\n",
      "Epoch [5220/10000], loss: 0.17327 acc: 0.98667 val_loss: 0.17719, val_acc: 0.96000\n",
      "Epoch [5230/10000], loss: 0.17310 acc: 0.98667 val_loss: 0.17704, val_acc: 0.96000\n",
      "Epoch [5240/10000], loss: 0.17294 acc: 0.98667 val_loss: 0.17689, val_acc: 0.96000\n",
      "Epoch [5250/10000], loss: 0.17277 acc: 0.98667 val_loss: 0.17675, val_acc: 0.96000\n",
      "Epoch [5260/10000], loss: 0.17261 acc: 0.98667 val_loss: 0.17660, val_acc: 0.96000\n",
      "Epoch [5270/10000], loss: 0.17245 acc: 0.98667 val_loss: 0.17646, val_acc: 0.96000\n",
      "Epoch [5280/10000], loss: 0.17229 acc: 0.98667 val_loss: 0.17631, val_acc: 0.96000\n",
      "Epoch [5290/10000], loss: 0.17212 acc: 0.98667 val_loss: 0.17617, val_acc: 0.96000\n",
      "Epoch [5300/10000], loss: 0.17196 acc: 0.98667 val_loss: 0.17603, val_acc: 0.96000\n",
      "Epoch [5310/10000], loss: 0.17180 acc: 0.98667 val_loss: 0.17588, val_acc: 0.96000\n",
      "Epoch [5320/10000], loss: 0.17164 acc: 0.98667 val_loss: 0.17574, val_acc: 0.96000\n",
      "Epoch [5330/10000], loss: 0.17148 acc: 0.98667 val_loss: 0.17560, val_acc: 0.96000\n",
      "Epoch [5340/10000], loss: 0.17132 acc: 0.98667 val_loss: 0.17546, val_acc: 0.96000\n",
      "Epoch [5350/10000], loss: 0.17116 acc: 0.98667 val_loss: 0.17532, val_acc: 0.96000\n",
      "Epoch [5360/10000], loss: 0.17100 acc: 0.98667 val_loss: 0.17518, val_acc: 0.96000\n",
      "Epoch [5370/10000], loss: 0.17084 acc: 0.98667 val_loss: 0.17504, val_acc: 0.96000\n",
      "Epoch [5380/10000], loss: 0.17068 acc: 0.98667 val_loss: 0.17490, val_acc: 0.96000\n",
      "Epoch [5390/10000], loss: 0.17053 acc: 0.98667 val_loss: 0.17476, val_acc: 0.96000\n",
      "Epoch [5400/10000], loss: 0.17037 acc: 0.98667 val_loss: 0.17462, val_acc: 0.96000\n",
      "Epoch [5410/10000], loss: 0.17021 acc: 0.98667 val_loss: 0.17448, val_acc: 0.96000\n",
      "Epoch [5420/10000], loss: 0.17006 acc: 0.98667 val_loss: 0.17434, val_acc: 0.96000\n",
      "Epoch [5430/10000], loss: 0.16990 acc: 0.98667 val_loss: 0.17421, val_acc: 0.96000\n",
      "Epoch [5440/10000], loss: 0.16975 acc: 0.98667 val_loss: 0.17407, val_acc: 0.96000\n",
      "Epoch [5450/10000], loss: 0.16959 acc: 0.98667 val_loss: 0.17393, val_acc: 0.96000\n",
      "Epoch [5460/10000], loss: 0.16944 acc: 0.98667 val_loss: 0.17380, val_acc: 0.96000\n",
      "Epoch [5470/10000], loss: 0.16928 acc: 0.98667 val_loss: 0.17366, val_acc: 0.96000\n",
      "Epoch [5480/10000], loss: 0.16913 acc: 0.98667 val_loss: 0.17352, val_acc: 0.96000\n",
      "Epoch [5490/10000], loss: 0.16898 acc: 0.98667 val_loss: 0.17339, val_acc: 0.96000\n",
      "Epoch [5500/10000], loss: 0.16883 acc: 0.98667 val_loss: 0.17325, val_acc: 0.96000\n",
      "Epoch [5510/10000], loss: 0.16867 acc: 0.98667 val_loss: 0.17312, val_acc: 0.96000\n",
      "Epoch [5520/10000], loss: 0.16852 acc: 0.98667 val_loss: 0.17299, val_acc: 0.96000\n",
      "Epoch [5530/10000], loss: 0.16837 acc: 0.98667 val_loss: 0.17285, val_acc: 0.96000\n",
      "Epoch [5540/10000], loss: 0.16822 acc: 0.98667 val_loss: 0.17272, val_acc: 0.96000\n",
      "Epoch [5550/10000], loss: 0.16807 acc: 0.98667 val_loss: 0.17259, val_acc: 0.96000\n",
      "Epoch [5560/10000], loss: 0.16792 acc: 0.98667 val_loss: 0.17246, val_acc: 0.96000\n",
      "Epoch [5570/10000], loss: 0.16777 acc: 0.98667 val_loss: 0.17232, val_acc: 0.96000\n",
      "Epoch [5580/10000], loss: 0.16762 acc: 0.98667 val_loss: 0.17219, val_acc: 0.96000\n",
      "Epoch [5590/10000], loss: 0.16747 acc: 0.98667 val_loss: 0.17206, val_acc: 0.96000\n",
      "Epoch [5600/10000], loss: 0.16732 acc: 0.98667 val_loss: 0.17193, val_acc: 0.96000\n",
      "Epoch [5610/10000], loss: 0.16718 acc: 0.98667 val_loss: 0.17180, val_acc: 0.96000\n",
      "Epoch [5620/10000], loss: 0.16703 acc: 0.98667 val_loss: 0.17167, val_acc: 0.96000\n",
      "Epoch [5630/10000], loss: 0.16688 acc: 0.98667 val_loss: 0.17154, val_acc: 0.96000\n",
      "Epoch [5640/10000], loss: 0.16674 acc: 0.98667 val_loss: 0.17141, val_acc: 0.96000\n",
      "Epoch [5650/10000], loss: 0.16659 acc: 0.98667 val_loss: 0.17128, val_acc: 0.96000\n",
      "Epoch [5660/10000], loss: 0.16644 acc: 0.98667 val_loss: 0.17115, val_acc: 0.96000\n",
      "Epoch [5670/10000], loss: 0.16630 acc: 0.98667 val_loss: 0.17103, val_acc: 0.96000\n",
      "Epoch [5680/10000], loss: 0.16615 acc: 0.98667 val_loss: 0.17090, val_acc: 0.96000\n",
      "Epoch [5690/10000], loss: 0.16601 acc: 0.98667 val_loss: 0.17077, val_acc: 0.96000\n",
      "Epoch [5700/10000], loss: 0.16587 acc: 0.98667 val_loss: 0.17064, val_acc: 0.96000\n",
      "Epoch [5710/10000], loss: 0.16572 acc: 0.98667 val_loss: 0.17052, val_acc: 0.96000\n",
      "Epoch [5720/10000], loss: 0.16558 acc: 0.98667 val_loss: 0.17039, val_acc: 0.96000\n",
      "Epoch [5730/10000], loss: 0.16544 acc: 0.98667 val_loss: 0.17027, val_acc: 0.96000\n",
      "Epoch [5740/10000], loss: 0.16529 acc: 0.98667 val_loss: 0.17014, val_acc: 0.96000\n",
      "Epoch [5750/10000], loss: 0.16515 acc: 0.98667 val_loss: 0.17001, val_acc: 0.96000\n",
      "Epoch [5760/10000], loss: 0.16501 acc: 0.98667 val_loss: 0.16989, val_acc: 0.96000\n",
      "Epoch [5770/10000], loss: 0.16487 acc: 0.98667 val_loss: 0.16977, val_acc: 0.96000\n",
      "Epoch [5780/10000], loss: 0.16473 acc: 0.98667 val_loss: 0.16964, val_acc: 0.96000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5790/10000], loss: 0.16459 acc: 0.98667 val_loss: 0.16952, val_acc: 0.96000\n",
      "Epoch [5800/10000], loss: 0.16445 acc: 0.98667 val_loss: 0.16940, val_acc: 0.96000\n",
      "Epoch [5810/10000], loss: 0.16431 acc: 0.98667 val_loss: 0.16927, val_acc: 0.96000\n",
      "Epoch [5820/10000], loss: 0.16417 acc: 0.98667 val_loss: 0.16915, val_acc: 0.96000\n",
      "Epoch [5830/10000], loss: 0.16403 acc: 0.98667 val_loss: 0.16903, val_acc: 0.96000\n",
      "Epoch [5840/10000], loss: 0.16389 acc: 0.98667 val_loss: 0.16891, val_acc: 0.96000\n",
      "Epoch [5850/10000], loss: 0.16375 acc: 0.98667 val_loss: 0.16878, val_acc: 0.96000\n",
      "Epoch [5860/10000], loss: 0.16361 acc: 0.98667 val_loss: 0.16866, val_acc: 0.96000\n",
      "Epoch [5870/10000], loss: 0.16348 acc: 0.98667 val_loss: 0.16854, val_acc: 0.96000\n",
      "Epoch [5880/10000], loss: 0.16334 acc: 0.98667 val_loss: 0.16842, val_acc: 0.96000\n",
      "Epoch [5890/10000], loss: 0.16320 acc: 0.98667 val_loss: 0.16830, val_acc: 0.96000\n",
      "Epoch [5900/10000], loss: 0.16307 acc: 0.98667 val_loss: 0.16818, val_acc: 0.96000\n",
      "Epoch [5910/10000], loss: 0.16293 acc: 0.98667 val_loss: 0.16806, val_acc: 0.96000\n",
      "Epoch [5920/10000], loss: 0.16280 acc: 0.98667 val_loss: 0.16794, val_acc: 0.96000\n",
      "Epoch [5930/10000], loss: 0.16266 acc: 0.98667 val_loss: 0.16782, val_acc: 0.96000\n",
      "Epoch [5940/10000], loss: 0.16253 acc: 0.98667 val_loss: 0.16771, val_acc: 0.96000\n",
      "Epoch [5950/10000], loss: 0.16239 acc: 0.98667 val_loss: 0.16759, val_acc: 0.96000\n",
      "Epoch [5960/10000], loss: 0.16226 acc: 0.98667 val_loss: 0.16747, val_acc: 0.96000\n",
      "Epoch [5970/10000], loss: 0.16212 acc: 0.98667 val_loss: 0.16735, val_acc: 0.96000\n",
      "Epoch [5980/10000], loss: 0.16199 acc: 0.98667 val_loss: 0.16724, val_acc: 0.96000\n",
      "Epoch [5990/10000], loss: 0.16186 acc: 0.98667 val_loss: 0.16712, val_acc: 0.96000\n",
      "Epoch [6000/10000], loss: 0.16172 acc: 0.98667 val_loss: 0.16700, val_acc: 0.96000\n",
      "Epoch [6010/10000], loss: 0.16159 acc: 0.98667 val_loss: 0.16689, val_acc: 0.96000\n",
      "Epoch [6020/10000], loss: 0.16146 acc: 0.98667 val_loss: 0.16677, val_acc: 0.96000\n",
      "Epoch [6030/10000], loss: 0.16133 acc: 0.98667 val_loss: 0.16665, val_acc: 0.96000\n",
      "Epoch [6040/10000], loss: 0.16120 acc: 0.98667 val_loss: 0.16654, val_acc: 0.96000\n",
      "Epoch [6050/10000], loss: 0.16107 acc: 0.98667 val_loss: 0.16642, val_acc: 0.96000\n",
      "Epoch [6060/10000], loss: 0.16093 acc: 0.98667 val_loss: 0.16631, val_acc: 0.96000\n",
      "Epoch [6070/10000], loss: 0.16080 acc: 0.98667 val_loss: 0.16620, val_acc: 0.96000\n",
      "Epoch [6080/10000], loss: 0.16067 acc: 0.98667 val_loss: 0.16608, val_acc: 0.96000\n",
      "Epoch [6090/10000], loss: 0.16055 acc: 0.98667 val_loss: 0.16597, val_acc: 0.96000\n",
      "Epoch [6100/10000], loss: 0.16042 acc: 0.98667 val_loss: 0.16585, val_acc: 0.96000\n",
      "Epoch [6110/10000], loss: 0.16029 acc: 0.98667 val_loss: 0.16574, val_acc: 0.96000\n",
      "Epoch [6120/10000], loss: 0.16016 acc: 0.98667 val_loss: 0.16563, val_acc: 0.96000\n",
      "Epoch [6130/10000], loss: 0.16003 acc: 0.98667 val_loss: 0.16552, val_acc: 0.96000\n",
      "Epoch [6140/10000], loss: 0.15990 acc: 0.98667 val_loss: 0.16540, val_acc: 0.96000\n",
      "Epoch [6150/10000], loss: 0.15978 acc: 0.98667 val_loss: 0.16529, val_acc: 0.96000\n",
      "Epoch [6160/10000], loss: 0.15965 acc: 0.98667 val_loss: 0.16518, val_acc: 0.96000\n",
      "Epoch [6170/10000], loss: 0.15952 acc: 0.98667 val_loss: 0.16507, val_acc: 0.96000\n",
      "Epoch [6180/10000], loss: 0.15939 acc: 0.98667 val_loss: 0.16496, val_acc: 0.96000\n",
      "Epoch [6190/10000], loss: 0.15927 acc: 0.98667 val_loss: 0.16485, val_acc: 0.96000\n",
      "Epoch [6200/10000], loss: 0.15914 acc: 0.98667 val_loss: 0.16474, val_acc: 0.96000\n",
      "Epoch [6210/10000], loss: 0.15902 acc: 0.98667 val_loss: 0.16463, val_acc: 0.96000\n",
      "Epoch [6220/10000], loss: 0.15889 acc: 0.98667 val_loss: 0.16452, val_acc: 0.96000\n",
      "Epoch [6230/10000], loss: 0.15877 acc: 0.98667 val_loss: 0.16441, val_acc: 0.96000\n",
      "Epoch [6240/10000], loss: 0.15864 acc: 0.98667 val_loss: 0.16430, val_acc: 0.96000\n",
      "Epoch [6250/10000], loss: 0.15852 acc: 0.98667 val_loss: 0.16419, val_acc: 0.96000\n",
      "Epoch [6260/10000], loss: 0.15839 acc: 0.98667 val_loss: 0.16408, val_acc: 0.96000\n",
      "Epoch [6270/10000], loss: 0.15827 acc: 0.98667 val_loss: 0.16398, val_acc: 0.96000\n",
      "Epoch [6280/10000], loss: 0.15815 acc: 0.98667 val_loss: 0.16387, val_acc: 0.96000\n",
      "Epoch [6290/10000], loss: 0.15802 acc: 0.98667 val_loss: 0.16376, val_acc: 0.96000\n",
      "Epoch [6300/10000], loss: 0.15790 acc: 0.98667 val_loss: 0.16365, val_acc: 0.96000\n",
      "Epoch [6310/10000], loss: 0.15778 acc: 0.98667 val_loss: 0.16355, val_acc: 0.96000\n",
      "Epoch [6320/10000], loss: 0.15766 acc: 0.98667 val_loss: 0.16344, val_acc: 0.96000\n",
      "Epoch [6330/10000], loss: 0.15754 acc: 0.98667 val_loss: 0.16333, val_acc: 0.96000\n",
      "Epoch [6340/10000], loss: 0.15741 acc: 0.98667 val_loss: 0.16323, val_acc: 0.96000\n",
      "Epoch [6350/10000], loss: 0.15729 acc: 0.98667 val_loss: 0.16312, val_acc: 0.96000\n",
      "Epoch [6360/10000], loss: 0.15717 acc: 0.98667 val_loss: 0.16302, val_acc: 0.96000\n",
      "Epoch [6370/10000], loss: 0.15705 acc: 0.98667 val_loss: 0.16291, val_acc: 0.96000\n",
      "Epoch [6380/10000], loss: 0.15693 acc: 0.98667 val_loss: 0.16281, val_acc: 0.96000\n",
      "Epoch [6390/10000], loss: 0.15681 acc: 0.98667 val_loss: 0.16270, val_acc: 0.96000\n",
      "Epoch [6400/10000], loss: 0.15669 acc: 0.98667 val_loss: 0.16260, val_acc: 0.96000\n",
      "Epoch [6410/10000], loss: 0.15657 acc: 0.98667 val_loss: 0.16249, val_acc: 0.96000\n",
      "Epoch [6420/10000], loss: 0.15645 acc: 0.98667 val_loss: 0.16239, val_acc: 0.96000\n",
      "Epoch [6430/10000], loss: 0.15634 acc: 0.98667 val_loss: 0.16228, val_acc: 0.96000\n",
      "Epoch [6440/10000], loss: 0.15622 acc: 0.98667 val_loss: 0.16218, val_acc: 0.96000\n",
      "Epoch [6450/10000], loss: 0.15610 acc: 0.98667 val_loss: 0.16208, val_acc: 0.96000\n",
      "Epoch [6460/10000], loss: 0.15598 acc: 0.98667 val_loss: 0.16198, val_acc: 0.96000\n",
      "Epoch [6470/10000], loss: 0.15586 acc: 0.98667 val_loss: 0.16187, val_acc: 0.96000\n",
      "Epoch [6480/10000], loss: 0.15575 acc: 0.98667 val_loss: 0.16177, val_acc: 0.96000\n",
      "Epoch [6490/10000], loss: 0.15563 acc: 0.98667 val_loss: 0.16167, val_acc: 0.96000\n",
      "Epoch [6500/10000], loss: 0.15551 acc: 0.98667 val_loss: 0.16157, val_acc: 0.96000\n",
      "Epoch [6510/10000], loss: 0.15540 acc: 0.98667 val_loss: 0.16147, val_acc: 0.96000\n",
      "Epoch [6520/10000], loss: 0.15528 acc: 0.98667 val_loss: 0.16136, val_acc: 0.96000\n",
      "Epoch [6530/10000], loss: 0.15516 acc: 0.98667 val_loss: 0.16126, val_acc: 0.96000\n",
      "Epoch [6540/10000], loss: 0.15505 acc: 0.98667 val_loss: 0.16116, val_acc: 0.96000\n",
      "Epoch [6550/10000], loss: 0.15493 acc: 0.98667 val_loss: 0.16106, val_acc: 0.96000\n",
      "Epoch [6560/10000], loss: 0.15482 acc: 0.98667 val_loss: 0.16096, val_acc: 0.96000\n",
      "Epoch [6570/10000], loss: 0.15470 acc: 0.98667 val_loss: 0.16086, val_acc: 0.96000\n",
      "Epoch [6580/10000], loss: 0.15459 acc: 0.98667 val_loss: 0.16076, val_acc: 0.96000\n",
      "Epoch [6590/10000], loss: 0.15448 acc: 0.98667 val_loss: 0.16066, val_acc: 0.96000\n",
      "Epoch [6600/10000], loss: 0.15436 acc: 0.98667 val_loss: 0.16056, val_acc: 0.96000\n",
      "Epoch [6610/10000], loss: 0.15425 acc: 0.98667 val_loss: 0.16047, val_acc: 0.96000\n",
      "Epoch [6620/10000], loss: 0.15414 acc: 0.98667 val_loss: 0.16037, val_acc: 0.96000\n",
      "Epoch [6630/10000], loss: 0.15402 acc: 0.98667 val_loss: 0.16027, val_acc: 0.96000\n",
      "Epoch [6640/10000], loss: 0.15391 acc: 0.98667 val_loss: 0.16017, val_acc: 0.96000\n",
      "Epoch [6650/10000], loss: 0.15380 acc: 0.98667 val_loss: 0.16007, val_acc: 0.96000\n",
      "Epoch [6660/10000], loss: 0.15369 acc: 0.98667 val_loss: 0.15998, val_acc: 0.96000\n",
      "Epoch [6670/10000], loss: 0.15357 acc: 0.98667 val_loss: 0.15988, val_acc: 0.96000\n",
      "Epoch [6680/10000], loss: 0.15346 acc: 0.98667 val_loss: 0.15978, val_acc: 0.96000\n",
      "Epoch [6690/10000], loss: 0.15335 acc: 0.98667 val_loss: 0.15968, val_acc: 0.96000\n",
      "Epoch [6700/10000], loss: 0.15324 acc: 0.98667 val_loss: 0.15959, val_acc: 0.96000\n",
      "Epoch [6710/10000], loss: 0.15313 acc: 0.98667 val_loss: 0.15949, val_acc: 0.96000\n",
      "Epoch [6720/10000], loss: 0.15302 acc: 0.98667 val_loss: 0.15939, val_acc: 0.96000\n",
      "Epoch [6730/10000], loss: 0.15291 acc: 0.98667 val_loss: 0.15930, val_acc: 0.96000\n",
      "Epoch [6740/10000], loss: 0.15280 acc: 0.98667 val_loss: 0.15920, val_acc: 0.96000\n",
      "Epoch [6750/10000], loss: 0.15269 acc: 0.98667 val_loss: 0.15911, val_acc: 0.96000\n",
      "Epoch [6760/10000], loss: 0.15258 acc: 0.98667 val_loss: 0.15901, val_acc: 0.96000\n",
      "Epoch [6770/10000], loss: 0.15247 acc: 0.98667 val_loss: 0.15892, val_acc: 0.96000\n",
      "Epoch [6780/10000], loss: 0.15236 acc: 0.98667 val_loss: 0.15882, val_acc: 0.96000\n",
      "Epoch [6790/10000], loss: 0.15225 acc: 0.98667 val_loss: 0.15873, val_acc: 0.96000\n",
      "Epoch [6800/10000], loss: 0.15215 acc: 0.98667 val_loss: 0.15863, val_acc: 0.96000\n",
      "Epoch [6810/10000], loss: 0.15204 acc: 0.98667 val_loss: 0.15854, val_acc: 0.96000\n",
      "Epoch [6820/10000], loss: 0.15193 acc: 0.98667 val_loss: 0.15845, val_acc: 0.96000\n",
      "Epoch [6830/10000], loss: 0.15182 acc: 0.98667 val_loss: 0.15835, val_acc: 0.96000\n",
      "Epoch [6840/10000], loss: 0.15171 acc: 0.98667 val_loss: 0.15826, val_acc: 0.96000\n",
      "Epoch [6850/10000], loss: 0.15161 acc: 0.98667 val_loss: 0.15817, val_acc: 0.96000\n",
      "Epoch [6860/10000], loss: 0.15150 acc: 0.98667 val_loss: 0.15807, val_acc: 0.96000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6870/10000], loss: 0.15139 acc: 0.98667 val_loss: 0.15798, val_acc: 0.96000\n",
      "Epoch [6880/10000], loss: 0.15129 acc: 0.98667 val_loss: 0.15789, val_acc: 0.96000\n",
      "Epoch [6890/10000], loss: 0.15118 acc: 0.98667 val_loss: 0.15780, val_acc: 0.96000\n",
      "Epoch [6900/10000], loss: 0.15108 acc: 0.98667 val_loss: 0.15771, val_acc: 0.96000\n",
      "Epoch [6910/10000], loss: 0.15097 acc: 0.98667 val_loss: 0.15761, val_acc: 0.96000\n",
      "Epoch [6920/10000], loss: 0.15086 acc: 0.98667 val_loss: 0.15752, val_acc: 0.96000\n",
      "Epoch [6930/10000], loss: 0.15076 acc: 0.98667 val_loss: 0.15743, val_acc: 0.96000\n",
      "Epoch [6940/10000], loss: 0.15065 acc: 0.98667 val_loss: 0.15734, val_acc: 0.96000\n",
      "Epoch [6950/10000], loss: 0.15055 acc: 0.98667 val_loss: 0.15725, val_acc: 0.96000\n",
      "Epoch [6960/10000], loss: 0.15045 acc: 0.98667 val_loss: 0.15716, val_acc: 0.96000\n",
      "Epoch [6970/10000], loss: 0.15034 acc: 0.98667 val_loss: 0.15707, val_acc: 0.96000\n",
      "Epoch [6980/10000], loss: 0.15024 acc: 0.98667 val_loss: 0.15698, val_acc: 0.96000\n",
      "Epoch [6990/10000], loss: 0.15013 acc: 0.98667 val_loss: 0.15689, val_acc: 0.96000\n",
      "Epoch [7000/10000], loss: 0.15003 acc: 0.98667 val_loss: 0.15680, val_acc: 0.96000\n",
      "Epoch [7010/10000], loss: 0.14993 acc: 0.98667 val_loss: 0.15671, val_acc: 0.96000\n",
      "Epoch [7020/10000], loss: 0.14983 acc: 0.98667 val_loss: 0.15662, val_acc: 0.96000\n",
      "Epoch [7030/10000], loss: 0.14972 acc: 0.98667 val_loss: 0.15653, val_acc: 0.96000\n",
      "Epoch [7040/10000], loss: 0.14962 acc: 0.98667 val_loss: 0.15644, val_acc: 0.96000\n",
      "Epoch [7050/10000], loss: 0.14952 acc: 0.98667 val_loss: 0.15636, val_acc: 0.96000\n",
      "Epoch [7060/10000], loss: 0.14942 acc: 0.98667 val_loss: 0.15627, val_acc: 0.96000\n",
      "Epoch [7070/10000], loss: 0.14931 acc: 0.98667 val_loss: 0.15618, val_acc: 0.96000\n",
      "Epoch [7080/10000], loss: 0.14921 acc: 0.98667 val_loss: 0.15609, val_acc: 0.96000\n",
      "Epoch [7090/10000], loss: 0.14911 acc: 0.98667 val_loss: 0.15600, val_acc: 0.96000\n",
      "Epoch [7100/10000], loss: 0.14901 acc: 0.98667 val_loss: 0.15592, val_acc: 0.96000\n",
      "Epoch [7110/10000], loss: 0.14891 acc: 0.98667 val_loss: 0.15583, val_acc: 0.96000\n",
      "Epoch [7120/10000], loss: 0.14881 acc: 0.98667 val_loss: 0.15574, val_acc: 0.96000\n",
      "Epoch [7130/10000], loss: 0.14871 acc: 0.98667 val_loss: 0.15565, val_acc: 0.96000\n",
      "Epoch [7140/10000], loss: 0.14861 acc: 0.98667 val_loss: 0.15557, val_acc: 0.96000\n",
      "Epoch [7150/10000], loss: 0.14851 acc: 0.98667 val_loss: 0.15548, val_acc: 0.96000\n",
      "Epoch [7160/10000], loss: 0.14841 acc: 0.98667 val_loss: 0.15540, val_acc: 0.96000\n",
      "Epoch [7170/10000], loss: 0.14831 acc: 0.98667 val_loss: 0.15531, val_acc: 0.96000\n",
      "Epoch [7180/10000], loss: 0.14821 acc: 0.98667 val_loss: 0.15522, val_acc: 0.96000\n",
      "Epoch [7190/10000], loss: 0.14811 acc: 0.98667 val_loss: 0.15514, val_acc: 0.96000\n",
      "Epoch [7200/10000], loss: 0.14801 acc: 0.98667 val_loss: 0.15505, val_acc: 0.96000\n",
      "Epoch [7210/10000], loss: 0.14792 acc: 0.98667 val_loss: 0.15497, val_acc: 0.96000\n",
      "Epoch [7220/10000], loss: 0.14782 acc: 0.98667 val_loss: 0.15488, val_acc: 0.96000\n",
      "Epoch [7230/10000], loss: 0.14772 acc: 0.98667 val_loss: 0.15480, val_acc: 0.96000\n",
      "Epoch [7240/10000], loss: 0.14762 acc: 0.98667 val_loss: 0.15471, val_acc: 0.96000\n",
      "Epoch [7250/10000], loss: 0.14752 acc: 0.98667 val_loss: 0.15463, val_acc: 0.96000\n",
      "Epoch [7260/10000], loss: 0.14743 acc: 0.98667 val_loss: 0.15455, val_acc: 0.96000\n",
      "Epoch [7270/10000], loss: 0.14733 acc: 0.98667 val_loss: 0.15446, val_acc: 0.96000\n",
      "Epoch [7280/10000], loss: 0.14723 acc: 0.98667 val_loss: 0.15438, val_acc: 0.96000\n",
      "Epoch [7290/10000], loss: 0.14714 acc: 0.98667 val_loss: 0.15429, val_acc: 0.96000\n",
      "Epoch [7300/10000], loss: 0.14704 acc: 0.98667 val_loss: 0.15421, val_acc: 0.96000\n",
      "Epoch [7310/10000], loss: 0.14694 acc: 0.98667 val_loss: 0.15413, val_acc: 0.96000\n",
      "Epoch [7320/10000], loss: 0.14685 acc: 0.98667 val_loss: 0.15404, val_acc: 0.96000\n",
      "Epoch [7330/10000], loss: 0.14675 acc: 0.98667 val_loss: 0.15396, val_acc: 0.96000\n",
      "Epoch [7340/10000], loss: 0.14666 acc: 0.98667 val_loss: 0.15388, val_acc: 0.96000\n",
      "Epoch [7350/10000], loss: 0.14656 acc: 0.98667 val_loss: 0.15380, val_acc: 0.96000\n",
      "Epoch [7360/10000], loss: 0.14646 acc: 0.98667 val_loss: 0.15371, val_acc: 0.96000\n",
      "Epoch [7370/10000], loss: 0.14637 acc: 0.98667 val_loss: 0.15363, val_acc: 0.96000\n",
      "Epoch [7380/10000], loss: 0.14628 acc: 0.98667 val_loss: 0.15355, val_acc: 0.96000\n",
      "Epoch [7390/10000], loss: 0.14618 acc: 0.98667 val_loss: 0.15347, val_acc: 0.96000\n",
      "Epoch [7400/10000], loss: 0.14609 acc: 0.98667 val_loss: 0.15339, val_acc: 0.96000\n",
      "Epoch [7410/10000], loss: 0.14599 acc: 0.98667 val_loss: 0.15331, val_acc: 0.96000\n",
      "Epoch [7420/10000], loss: 0.14590 acc: 0.98667 val_loss: 0.15323, val_acc: 0.96000\n",
      "Epoch [7430/10000], loss: 0.14580 acc: 0.98667 val_loss: 0.15314, val_acc: 0.96000\n",
      "Epoch [7440/10000], loss: 0.14571 acc: 0.98667 val_loss: 0.15306, val_acc: 0.96000\n",
      "Epoch [7450/10000], loss: 0.14562 acc: 0.98667 val_loss: 0.15298, val_acc: 0.96000\n",
      "Epoch [7460/10000], loss: 0.14552 acc: 0.98667 val_loss: 0.15290, val_acc: 0.96000\n",
      "Epoch [7470/10000], loss: 0.14543 acc: 0.98667 val_loss: 0.15282, val_acc: 0.96000\n",
      "Epoch [7480/10000], loss: 0.14534 acc: 0.98667 val_loss: 0.15274, val_acc: 0.96000\n",
      "Epoch [7490/10000], loss: 0.14525 acc: 0.98667 val_loss: 0.15266, val_acc: 0.96000\n",
      "Epoch [7500/10000], loss: 0.14515 acc: 0.98667 val_loss: 0.15258, val_acc: 0.96000\n",
      "Epoch [7510/10000], loss: 0.14506 acc: 0.98667 val_loss: 0.15250, val_acc: 0.96000\n",
      "Epoch [7520/10000], loss: 0.14497 acc: 0.98667 val_loss: 0.15243, val_acc: 0.96000\n",
      "Epoch [7530/10000], loss: 0.14488 acc: 0.98667 val_loss: 0.15235, val_acc: 0.96000\n",
      "Epoch [7540/10000], loss: 0.14479 acc: 0.98667 val_loss: 0.15227, val_acc: 0.96000\n",
      "Epoch [7550/10000], loss: 0.14470 acc: 0.98667 val_loss: 0.15219, val_acc: 0.96000\n",
      "Epoch [7560/10000], loss: 0.14460 acc: 0.98667 val_loss: 0.15211, val_acc: 0.96000\n",
      "Epoch [7570/10000], loss: 0.14451 acc: 0.98667 val_loss: 0.15203, val_acc: 0.96000\n",
      "Epoch [7580/10000], loss: 0.14442 acc: 0.98667 val_loss: 0.15195, val_acc: 0.96000\n",
      "Epoch [7590/10000], loss: 0.14433 acc: 0.98667 val_loss: 0.15188, val_acc: 0.96000\n",
      "Epoch [7600/10000], loss: 0.14424 acc: 0.98667 val_loss: 0.15180, val_acc: 0.96000\n",
      "Epoch [7610/10000], loss: 0.14415 acc: 0.98667 val_loss: 0.15172, val_acc: 0.96000\n",
      "Epoch [7620/10000], loss: 0.14406 acc: 0.98667 val_loss: 0.15164, val_acc: 0.96000\n",
      "Epoch [7630/10000], loss: 0.14397 acc: 0.98667 val_loss: 0.15157, val_acc: 0.96000\n",
      "Epoch [7640/10000], loss: 0.14388 acc: 0.98667 val_loss: 0.15149, val_acc: 0.96000\n",
      "Epoch [7650/10000], loss: 0.14379 acc: 0.98667 val_loss: 0.15141, val_acc: 0.96000\n",
      "Epoch [7660/10000], loss: 0.14370 acc: 0.98667 val_loss: 0.15134, val_acc: 0.96000\n",
      "Epoch [7670/10000], loss: 0.14362 acc: 0.98667 val_loss: 0.15126, val_acc: 0.96000\n",
      "Epoch [7680/10000], loss: 0.14353 acc: 0.98667 val_loss: 0.15118, val_acc: 0.96000\n",
      "Epoch [7690/10000], loss: 0.14344 acc: 0.98667 val_loss: 0.15111, val_acc: 0.96000\n",
      "Epoch [7700/10000], loss: 0.14335 acc: 0.98667 val_loss: 0.15103, val_acc: 0.96000\n",
      "Epoch [7710/10000], loss: 0.14326 acc: 0.98667 val_loss: 0.15096, val_acc: 0.96000\n",
      "Epoch [7720/10000], loss: 0.14317 acc: 0.98667 val_loss: 0.15088, val_acc: 0.96000\n",
      "Epoch [7730/10000], loss: 0.14309 acc: 0.98667 val_loss: 0.15080, val_acc: 0.96000\n",
      "Epoch [7740/10000], loss: 0.14300 acc: 0.98667 val_loss: 0.15073, val_acc: 0.96000\n",
      "Epoch [7750/10000], loss: 0.14291 acc: 0.98667 val_loss: 0.15065, val_acc: 0.96000\n",
      "Epoch [7760/10000], loss: 0.14282 acc: 0.98667 val_loss: 0.15058, val_acc: 0.96000\n",
      "Epoch [7770/10000], loss: 0.14274 acc: 0.98667 val_loss: 0.15050, val_acc: 0.96000\n",
      "Epoch [7780/10000], loss: 0.14265 acc: 0.98667 val_loss: 0.15043, val_acc: 0.96000\n",
      "Epoch [7790/10000], loss: 0.14256 acc: 0.98667 val_loss: 0.15036, val_acc: 0.96000\n",
      "Epoch [7800/10000], loss: 0.14248 acc: 0.98667 val_loss: 0.15028, val_acc: 0.96000\n",
      "Epoch [7810/10000], loss: 0.14239 acc: 0.98667 val_loss: 0.15021, val_acc: 0.96000\n",
      "Epoch [7820/10000], loss: 0.14230 acc: 0.98667 val_loss: 0.15013, val_acc: 0.96000\n",
      "Epoch [7830/10000], loss: 0.14222 acc: 0.98667 val_loss: 0.15006, val_acc: 0.96000\n",
      "Epoch [7840/10000], loss: 0.14213 acc: 0.98667 val_loss: 0.14999, val_acc: 0.96000\n",
      "Epoch [7850/10000], loss: 0.14205 acc: 0.98667 val_loss: 0.14991, val_acc: 0.96000\n",
      "Epoch [7860/10000], loss: 0.14196 acc: 0.98667 val_loss: 0.14984, val_acc: 0.96000\n",
      "Epoch [7870/10000], loss: 0.14188 acc: 0.98667 val_loss: 0.14977, val_acc: 0.96000\n",
      "Epoch [7880/10000], loss: 0.14179 acc: 0.98667 val_loss: 0.14969, val_acc: 0.96000\n",
      "Epoch [7890/10000], loss: 0.14171 acc: 0.98667 val_loss: 0.14962, val_acc: 0.96000\n",
      "Epoch [7900/10000], loss: 0.14162 acc: 0.98667 val_loss: 0.14955, val_acc: 0.96000\n",
      "Epoch [7910/10000], loss: 0.14154 acc: 0.98667 val_loss: 0.14948, val_acc: 0.96000\n",
      "Epoch [7920/10000], loss: 0.14145 acc: 0.98667 val_loss: 0.14940, val_acc: 0.96000\n",
      "Epoch [7930/10000], loss: 0.14137 acc: 0.98667 val_loss: 0.14933, val_acc: 0.96000\n",
      "Epoch [7940/10000], loss: 0.14128 acc: 0.98667 val_loss: 0.14926, val_acc: 0.96000\n",
      "Epoch [7950/10000], loss: 0.14120 acc: 0.98667 val_loss: 0.14919, val_acc: 0.96000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7960/10000], loss: 0.14112 acc: 0.98667 val_loss: 0.14912, val_acc: 0.96000\n",
      "Epoch [7970/10000], loss: 0.14103 acc: 0.98667 val_loss: 0.14904, val_acc: 0.96000\n",
      "Epoch [7980/10000], loss: 0.14095 acc: 0.98667 val_loss: 0.14897, val_acc: 0.96000\n",
      "Epoch [7990/10000], loss: 0.14087 acc: 0.98667 val_loss: 0.14890, val_acc: 0.96000\n",
      "Epoch [8000/10000], loss: 0.14078 acc: 0.98667 val_loss: 0.14883, val_acc: 0.96000\n",
      "Epoch [8010/10000], loss: 0.14070 acc: 0.98667 val_loss: 0.14876, val_acc: 0.96000\n",
      "Epoch [8020/10000], loss: 0.14062 acc: 0.98667 val_loss: 0.14869, val_acc: 0.96000\n",
      "Epoch [8030/10000], loss: 0.14054 acc: 0.98667 val_loss: 0.14862, val_acc: 0.96000\n",
      "Epoch [8040/10000], loss: 0.14045 acc: 0.98667 val_loss: 0.14855, val_acc: 0.96000\n",
      "Epoch [8050/10000], loss: 0.14037 acc: 0.98667 val_loss: 0.14848, val_acc: 0.96000\n",
      "Epoch [8060/10000], loss: 0.14029 acc: 0.98667 val_loss: 0.14841, val_acc: 0.96000\n",
      "Epoch [8070/10000], loss: 0.14021 acc: 0.98667 val_loss: 0.14834, val_acc: 0.96000\n",
      "Epoch [8080/10000], loss: 0.14013 acc: 0.98667 val_loss: 0.14827, val_acc: 0.96000\n",
      "Epoch [8090/10000], loss: 0.14004 acc: 0.98667 val_loss: 0.14820, val_acc: 0.96000\n",
      "Epoch [8100/10000], loss: 0.13996 acc: 0.98667 val_loss: 0.14813, val_acc: 0.96000\n",
      "Epoch [8110/10000], loss: 0.13988 acc: 0.98667 val_loss: 0.14806, val_acc: 0.96000\n",
      "Epoch [8120/10000], loss: 0.13980 acc: 0.98667 val_loss: 0.14799, val_acc: 0.96000\n",
      "Epoch [8130/10000], loss: 0.13972 acc: 0.98667 val_loss: 0.14792, val_acc: 0.96000\n",
      "Epoch [8140/10000], loss: 0.13964 acc: 0.98667 val_loss: 0.14785, val_acc: 0.96000\n",
      "Epoch [8150/10000], loss: 0.13956 acc: 0.98667 val_loss: 0.14778, val_acc: 0.96000\n",
      "Epoch [8160/10000], loss: 0.13948 acc: 0.98667 val_loss: 0.14771, val_acc: 0.96000\n",
      "Epoch [8170/10000], loss: 0.13940 acc: 0.98667 val_loss: 0.14765, val_acc: 0.96000\n",
      "Epoch [8180/10000], loss: 0.13932 acc: 0.98667 val_loss: 0.14758, val_acc: 0.96000\n",
      "Epoch [8190/10000], loss: 0.13924 acc: 0.98667 val_loss: 0.14751, val_acc: 0.96000\n",
      "Epoch [8200/10000], loss: 0.13916 acc: 0.98667 val_loss: 0.14744, val_acc: 0.96000\n",
      "Epoch [8210/10000], loss: 0.13908 acc: 0.98667 val_loss: 0.14737, val_acc: 0.96000\n",
      "Epoch [8220/10000], loss: 0.13900 acc: 0.98667 val_loss: 0.14731, val_acc: 0.96000\n",
      "Epoch [8230/10000], loss: 0.13892 acc: 0.98667 val_loss: 0.14724, val_acc: 0.96000\n",
      "Epoch [8240/10000], loss: 0.13884 acc: 0.98667 val_loss: 0.14717, val_acc: 0.96000\n",
      "Epoch [8250/10000], loss: 0.13876 acc: 0.98667 val_loss: 0.14710, val_acc: 0.96000\n",
      "Epoch [8260/10000], loss: 0.13869 acc: 0.98667 val_loss: 0.14704, val_acc: 0.96000\n",
      "Epoch [8270/10000], loss: 0.13861 acc: 0.98667 val_loss: 0.14697, val_acc: 0.96000\n",
      "Epoch [8280/10000], loss: 0.13853 acc: 0.98667 val_loss: 0.14690, val_acc: 0.96000\n",
      "Epoch [8290/10000], loss: 0.13845 acc: 0.98667 val_loss: 0.14684, val_acc: 0.96000\n",
      "Epoch [8300/10000], loss: 0.13837 acc: 0.98667 val_loss: 0.14677, val_acc: 0.96000\n",
      "Epoch [8310/10000], loss: 0.13829 acc: 0.98667 val_loss: 0.14670, val_acc: 0.96000\n",
      "Epoch [8320/10000], loss: 0.13822 acc: 0.98667 val_loss: 0.14664, val_acc: 0.96000\n",
      "Epoch [8330/10000], loss: 0.13814 acc: 0.98667 val_loss: 0.14657, val_acc: 0.96000\n",
      "Epoch [8340/10000], loss: 0.13806 acc: 0.98667 val_loss: 0.14650, val_acc: 0.96000\n",
      "Epoch [8350/10000], loss: 0.13798 acc: 0.98667 val_loss: 0.14644, val_acc: 0.96000\n",
      "Epoch [8360/10000], loss: 0.13791 acc: 0.98667 val_loss: 0.14637, val_acc: 0.96000\n",
      "Epoch [8370/10000], loss: 0.13783 acc: 0.98667 val_loss: 0.14631, val_acc: 0.96000\n",
      "Epoch [8380/10000], loss: 0.13775 acc: 0.98667 val_loss: 0.14624, val_acc: 0.96000\n",
      "Epoch [8390/10000], loss: 0.13768 acc: 0.98667 val_loss: 0.14618, val_acc: 0.96000\n",
      "Epoch [8400/10000], loss: 0.13760 acc: 0.98667 val_loss: 0.14611, val_acc: 0.96000\n",
      "Epoch [8410/10000], loss: 0.13752 acc: 0.98667 val_loss: 0.14605, val_acc: 0.96000\n",
      "Epoch [8420/10000], loss: 0.13745 acc: 0.98667 val_loss: 0.14598, val_acc: 0.96000\n",
      "Epoch [8430/10000], loss: 0.13737 acc: 0.98667 val_loss: 0.14592, val_acc: 0.96000\n",
      "Epoch [8440/10000], loss: 0.13730 acc: 0.98667 val_loss: 0.14585, val_acc: 0.96000\n",
      "Epoch [8450/10000], loss: 0.13722 acc: 0.98667 val_loss: 0.14579, val_acc: 0.96000\n",
      "Epoch [8460/10000], loss: 0.13714 acc: 0.98667 val_loss: 0.14572, val_acc: 0.96000\n",
      "Epoch [8470/10000], loss: 0.13707 acc: 0.98667 val_loss: 0.14566, val_acc: 0.96000\n",
      "Epoch [8480/10000], loss: 0.13699 acc: 0.98667 val_loss: 0.14559, val_acc: 0.96000\n",
      "Epoch [8490/10000], loss: 0.13692 acc: 0.98667 val_loss: 0.14553, val_acc: 0.96000\n",
      "Epoch [8500/10000], loss: 0.13684 acc: 0.98667 val_loss: 0.14547, val_acc: 0.96000\n",
      "Epoch [8510/10000], loss: 0.13677 acc: 0.98667 val_loss: 0.14540, val_acc: 0.96000\n",
      "Epoch [8520/10000], loss: 0.13669 acc: 0.98667 val_loss: 0.14534, val_acc: 0.96000\n",
      "Epoch [8530/10000], loss: 0.13662 acc: 0.98667 val_loss: 0.14528, val_acc: 0.96000\n",
      "Epoch [8540/10000], loss: 0.13654 acc: 0.98667 val_loss: 0.14521, val_acc: 0.96000\n",
      "Epoch [8550/10000], loss: 0.13647 acc: 0.98667 val_loss: 0.14515, val_acc: 0.96000\n",
      "Epoch [8560/10000], loss: 0.13640 acc: 0.98667 val_loss: 0.14509, val_acc: 0.96000\n",
      "Epoch [8570/10000], loss: 0.13632 acc: 0.98667 val_loss: 0.14502, val_acc: 0.96000\n",
      "Epoch [8580/10000], loss: 0.13625 acc: 0.98667 val_loss: 0.14496, val_acc: 0.96000\n",
      "Epoch [8590/10000], loss: 0.13617 acc: 0.98667 val_loss: 0.14490, val_acc: 0.96000\n",
      "Epoch [8600/10000], loss: 0.13610 acc: 0.98667 val_loss: 0.14483, val_acc: 0.96000\n",
      "Epoch [8610/10000], loss: 0.13603 acc: 0.98667 val_loss: 0.14477, val_acc: 0.96000\n",
      "Epoch [8620/10000], loss: 0.13595 acc: 0.98667 val_loss: 0.14471, val_acc: 0.96000\n",
      "Epoch [8630/10000], loss: 0.13588 acc: 0.98667 val_loss: 0.14465, val_acc: 0.96000\n",
      "Epoch [8640/10000], loss: 0.13581 acc: 0.98667 val_loss: 0.14459, val_acc: 0.96000\n",
      "Epoch [8650/10000], loss: 0.13574 acc: 0.98667 val_loss: 0.14452, val_acc: 0.96000\n",
      "Epoch [8660/10000], loss: 0.13566 acc: 0.98667 val_loss: 0.14446, val_acc: 0.96000\n",
      "Epoch [8670/10000], loss: 0.13559 acc: 0.98667 val_loss: 0.14440, val_acc: 0.96000\n",
      "Epoch [8680/10000], loss: 0.13552 acc: 0.98667 val_loss: 0.14434, val_acc: 0.96000\n",
      "Epoch [8690/10000], loss: 0.13545 acc: 0.98667 val_loss: 0.14428, val_acc: 0.96000\n",
      "Epoch [8700/10000], loss: 0.13537 acc: 0.98667 val_loss: 0.14422, val_acc: 0.96000\n",
      "Epoch [8710/10000], loss: 0.13530 acc: 0.98667 val_loss: 0.14415, val_acc: 0.96000\n",
      "Epoch [8720/10000], loss: 0.13523 acc: 0.98667 val_loss: 0.14409, val_acc: 0.96000\n",
      "Epoch [8730/10000], loss: 0.13516 acc: 0.98667 val_loss: 0.14403, val_acc: 0.96000\n",
      "Epoch [8740/10000], loss: 0.13509 acc: 0.98667 val_loss: 0.14397, val_acc: 0.96000\n",
      "Epoch [8750/10000], loss: 0.13501 acc: 0.98667 val_loss: 0.14391, val_acc: 0.96000\n",
      "Epoch [8760/10000], loss: 0.13494 acc: 0.98667 val_loss: 0.14385, val_acc: 0.96000\n",
      "Epoch [8770/10000], loss: 0.13487 acc: 0.98667 val_loss: 0.14379, val_acc: 0.96000\n",
      "Epoch [8780/10000], loss: 0.13480 acc: 0.98667 val_loss: 0.14373, val_acc: 0.96000\n",
      "Epoch [8790/10000], loss: 0.13473 acc: 0.98667 val_loss: 0.14367, val_acc: 0.96000\n",
      "Epoch [8800/10000], loss: 0.13466 acc: 0.98667 val_loss: 0.14361, val_acc: 0.96000\n",
      "Epoch [8810/10000], loss: 0.13459 acc: 0.98667 val_loss: 0.14355, val_acc: 0.96000\n",
      "Epoch [8820/10000], loss: 0.13452 acc: 0.98667 val_loss: 0.14349, val_acc: 0.96000\n",
      "Epoch [8830/10000], loss: 0.13445 acc: 0.98667 val_loss: 0.14343, val_acc: 0.96000\n",
      "Epoch [8840/10000], loss: 0.13438 acc: 0.98667 val_loss: 0.14337, val_acc: 0.96000\n",
      "Epoch [8850/10000], loss: 0.13431 acc: 0.98667 val_loss: 0.14331, val_acc: 0.96000\n",
      "Epoch [8860/10000], loss: 0.13424 acc: 0.98667 val_loss: 0.14325, val_acc: 0.96000\n",
      "Epoch [8870/10000], loss: 0.13417 acc: 0.98667 val_loss: 0.14319, val_acc: 0.96000\n",
      "Epoch [8880/10000], loss: 0.13410 acc: 0.98667 val_loss: 0.14313, val_acc: 0.96000\n",
      "Epoch [8890/10000], loss: 0.13403 acc: 0.98667 val_loss: 0.14308, val_acc: 0.96000\n",
      "Epoch [8900/10000], loss: 0.13396 acc: 0.98667 val_loss: 0.14302, val_acc: 0.96000\n",
      "Epoch [8910/10000], loss: 0.13389 acc: 0.98667 val_loss: 0.14296, val_acc: 0.96000\n",
      "Epoch [8920/10000], loss: 0.13382 acc: 0.98667 val_loss: 0.14290, val_acc: 0.96000\n",
      "Epoch [8930/10000], loss: 0.13375 acc: 0.98667 val_loss: 0.14284, val_acc: 0.96000\n",
      "Epoch [8940/10000], loss: 0.13368 acc: 0.98667 val_loss: 0.14278, val_acc: 0.96000\n",
      "Epoch [8950/10000], loss: 0.13361 acc: 0.98667 val_loss: 0.14272, val_acc: 0.96000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8960/10000], loss: 0.13354 acc: 0.98667 val_loss: 0.14266, val_acc: 0.96000\n",
      "Epoch [8970/10000], loss: 0.13347 acc: 0.98667 val_loss: 0.14261, val_acc: 0.96000\n",
      "Epoch [8980/10000], loss: 0.13341 acc: 0.98667 val_loss: 0.14255, val_acc: 0.96000\n",
      "Epoch [8990/10000], loss: 0.13334 acc: 0.98667 val_loss: 0.14249, val_acc: 0.96000\n",
      "Epoch [9000/10000], loss: 0.13327 acc: 0.98667 val_loss: 0.14243, val_acc: 0.96000\n",
      "Epoch [9010/10000], loss: 0.13320 acc: 0.98667 val_loss: 0.14238, val_acc: 0.96000\n",
      "Epoch [9020/10000], loss: 0.13313 acc: 0.98667 val_loss: 0.14232, val_acc: 0.96000\n",
      "Epoch [9030/10000], loss: 0.13307 acc: 0.98667 val_loss: 0.14226, val_acc: 0.96000\n",
      "Epoch [9040/10000], loss: 0.13300 acc: 0.98667 val_loss: 0.14220, val_acc: 0.96000\n",
      "Epoch [9050/10000], loss: 0.13293 acc: 0.98667 val_loss: 0.14215, val_acc: 0.96000\n",
      "Epoch [9060/10000], loss: 0.13286 acc: 0.98667 val_loss: 0.14209, val_acc: 0.96000\n",
      "Epoch [9070/10000], loss: 0.13280 acc: 0.98667 val_loss: 0.14203, val_acc: 0.96000\n",
      "Epoch [9080/10000], loss: 0.13273 acc: 0.98667 val_loss: 0.14198, val_acc: 0.96000\n",
      "Epoch [9090/10000], loss: 0.13266 acc: 0.98667 val_loss: 0.14192, val_acc: 0.96000\n",
      "Epoch [9100/10000], loss: 0.13259 acc: 0.98667 val_loss: 0.14186, val_acc: 0.96000\n",
      "Epoch [9110/10000], loss: 0.13253 acc: 0.98667 val_loss: 0.14181, val_acc: 0.96000\n",
      "Epoch [9120/10000], loss: 0.13246 acc: 0.98667 val_loss: 0.14175, val_acc: 0.96000\n",
      "Epoch [9130/10000], loss: 0.13239 acc: 0.98667 val_loss: 0.14169, val_acc: 0.96000\n",
      "Epoch [9140/10000], loss: 0.13233 acc: 0.98667 val_loss: 0.14164, val_acc: 0.96000\n",
      "Epoch [9150/10000], loss: 0.13226 acc: 0.98667 val_loss: 0.14158, val_acc: 0.96000\n",
      "Epoch [9160/10000], loss: 0.13220 acc: 0.98667 val_loss: 0.14153, val_acc: 0.96000\n",
      "Epoch [9170/10000], loss: 0.13213 acc: 0.98667 val_loss: 0.14147, val_acc: 0.96000\n",
      "Epoch [9180/10000], loss: 0.13206 acc: 0.98667 val_loss: 0.14141, val_acc: 0.96000\n",
      "Epoch [9190/10000], loss: 0.13200 acc: 0.98667 val_loss: 0.14136, val_acc: 0.96000\n",
      "Epoch [9200/10000], loss: 0.13193 acc: 0.98667 val_loss: 0.14130, val_acc: 0.96000\n",
      "Epoch [9210/10000], loss: 0.13187 acc: 0.98667 val_loss: 0.14125, val_acc: 0.96000\n",
      "Epoch [9220/10000], loss: 0.13180 acc: 0.98667 val_loss: 0.14119, val_acc: 0.96000\n",
      "Epoch [9230/10000], loss: 0.13174 acc: 0.98667 val_loss: 0.14114, val_acc: 0.96000\n",
      "Epoch [9240/10000], loss: 0.13167 acc: 0.98667 val_loss: 0.14108, val_acc: 0.96000\n",
      "Epoch [9250/10000], loss: 0.13160 acc: 0.98667 val_loss: 0.14103, val_acc: 0.96000\n",
      "Epoch [9260/10000], loss: 0.13154 acc: 0.98667 val_loss: 0.14097, val_acc: 0.96000\n",
      "Epoch [9270/10000], loss: 0.13147 acc: 0.98667 val_loss: 0.14092, val_acc: 0.96000\n",
      "Epoch [9280/10000], loss: 0.13141 acc: 0.98667 val_loss: 0.14086, val_acc: 0.96000\n",
      "Epoch [9290/10000], loss: 0.13135 acc: 0.98667 val_loss: 0.14081, val_acc: 0.96000\n",
      "Epoch [9300/10000], loss: 0.13128 acc: 0.98667 val_loss: 0.14075, val_acc: 0.96000\n",
      "Epoch [9310/10000], loss: 0.13122 acc: 0.98667 val_loss: 0.14070, val_acc: 0.96000\n",
      "Epoch [9320/10000], loss: 0.13115 acc: 0.98667 val_loss: 0.14065, val_acc: 0.96000\n",
      "Epoch [9330/10000], loss: 0.13109 acc: 0.98667 val_loss: 0.14059, val_acc: 0.96000\n",
      "Epoch [9340/10000], loss: 0.13102 acc: 0.98667 val_loss: 0.14054, val_acc: 0.96000\n",
      "Epoch [9350/10000], loss: 0.13096 acc: 0.98667 val_loss: 0.14048, val_acc: 0.96000\n",
      "Epoch [9360/10000], loss: 0.13090 acc: 0.98667 val_loss: 0.14043, val_acc: 0.96000\n",
      "Epoch [9370/10000], loss: 0.13083 acc: 0.98667 val_loss: 0.14038, val_acc: 0.96000\n",
      "Epoch [9380/10000], loss: 0.13077 acc: 0.98667 val_loss: 0.14032, val_acc: 0.96000\n",
      "Epoch [9390/10000], loss: 0.13070 acc: 0.98667 val_loss: 0.14027, val_acc: 0.96000\n",
      "Epoch [9400/10000], loss: 0.13064 acc: 0.98667 val_loss: 0.14022, val_acc: 0.96000\n",
      "Epoch [9410/10000], loss: 0.13058 acc: 0.98667 val_loss: 0.14016, val_acc: 0.96000\n",
      "Epoch [9420/10000], loss: 0.13051 acc: 0.98667 val_loss: 0.14011, val_acc: 0.96000\n",
      "Epoch [9430/10000], loss: 0.13045 acc: 0.98667 val_loss: 0.14006, val_acc: 0.96000\n",
      "Epoch [9440/10000], loss: 0.13039 acc: 0.98667 val_loss: 0.14000, val_acc: 0.96000\n",
      "Epoch [9450/10000], loss: 0.13033 acc: 0.98667 val_loss: 0.13995, val_acc: 0.96000\n",
      "Epoch [9460/10000], loss: 0.13026 acc: 0.98667 val_loss: 0.13990, val_acc: 0.96000\n",
      "Epoch [9470/10000], loss: 0.13020 acc: 0.98667 val_loss: 0.13984, val_acc: 0.96000\n",
      "Epoch [9480/10000], loss: 0.13014 acc: 0.98667 val_loss: 0.13979, val_acc: 0.96000\n",
      "Epoch [9490/10000], loss: 0.13008 acc: 0.98667 val_loss: 0.13974, val_acc: 0.96000\n",
      "Epoch [9500/10000], loss: 0.13001 acc: 0.98667 val_loss: 0.13969, val_acc: 0.96000\n",
      "Epoch [9510/10000], loss: 0.12995 acc: 0.98667 val_loss: 0.13963, val_acc: 0.96000\n",
      "Epoch [9520/10000], loss: 0.12989 acc: 0.98667 val_loss: 0.13958, val_acc: 0.96000\n",
      "Epoch [9530/10000], loss: 0.12983 acc: 0.98667 val_loss: 0.13953, val_acc: 0.96000\n",
      "Epoch [9540/10000], loss: 0.12976 acc: 0.98667 val_loss: 0.13948, val_acc: 0.96000\n",
      "Epoch [9550/10000], loss: 0.12970 acc: 0.98667 val_loss: 0.13943, val_acc: 0.96000\n",
      "Epoch [9560/10000], loss: 0.12964 acc: 0.98667 val_loss: 0.13937, val_acc: 0.96000\n",
      "Epoch [9570/10000], loss: 0.12958 acc: 0.98667 val_loss: 0.13932, val_acc: 0.96000\n",
      "Epoch [9580/10000], loss: 0.12952 acc: 0.98667 val_loss: 0.13927, val_acc: 0.96000\n",
      "Epoch [9590/10000], loss: 0.12946 acc: 0.98667 val_loss: 0.13922, val_acc: 0.96000\n",
      "Epoch [9600/10000], loss: 0.12940 acc: 0.98667 val_loss: 0.13917, val_acc: 0.96000\n",
      "Epoch [9610/10000], loss: 0.12933 acc: 0.98667 val_loss: 0.13912, val_acc: 0.96000\n",
      "Epoch [9620/10000], loss: 0.12927 acc: 0.98667 val_loss: 0.13907, val_acc: 0.96000\n",
      "Epoch [9630/10000], loss: 0.12921 acc: 0.98667 val_loss: 0.13901, val_acc: 0.96000\n",
      "Epoch [9640/10000], loss: 0.12915 acc: 0.98667 val_loss: 0.13896, val_acc: 0.96000\n",
      "Epoch [9650/10000], loss: 0.12909 acc: 0.98667 val_loss: 0.13891, val_acc: 0.96000\n",
      "Epoch [9660/10000], loss: 0.12903 acc: 0.98667 val_loss: 0.13886, val_acc: 0.96000\n",
      "Epoch [9670/10000], loss: 0.12897 acc: 0.98667 val_loss: 0.13881, val_acc: 0.96000\n",
      "Epoch [9680/10000], loss: 0.12891 acc: 0.98667 val_loss: 0.13876, val_acc: 0.96000\n",
      "Epoch [9690/10000], loss: 0.12885 acc: 0.98667 val_loss: 0.13871, val_acc: 0.96000\n",
      "Epoch [9700/10000], loss: 0.12879 acc: 0.98667 val_loss: 0.13866, val_acc: 0.96000\n",
      "Epoch [9710/10000], loss: 0.12873 acc: 0.98667 val_loss: 0.13861, val_acc: 0.96000\n",
      "Epoch [9720/10000], loss: 0.12867 acc: 0.98667 val_loss: 0.13856, val_acc: 0.96000\n",
      "Epoch [9730/10000], loss: 0.12861 acc: 0.98667 val_loss: 0.13851, val_acc: 0.96000\n",
      "Epoch [9740/10000], loss: 0.12855 acc: 0.98667 val_loss: 0.13846, val_acc: 0.96000\n",
      "Epoch [9750/10000], loss: 0.12849 acc: 0.98667 val_loss: 0.13841, val_acc: 0.96000\n",
      "Epoch [9760/10000], loss: 0.12843 acc: 0.98667 val_loss: 0.13836, val_acc: 0.96000\n",
      "Epoch [9770/10000], loss: 0.12837 acc: 0.98667 val_loss: 0.13831, val_acc: 0.96000\n",
      "Epoch [9780/10000], loss: 0.12831 acc: 0.98667 val_loss: 0.13826, val_acc: 0.96000\n",
      "Epoch [9790/10000], loss: 0.12825 acc: 0.98667 val_loss: 0.13821, val_acc: 0.96000\n",
      "Epoch [9800/10000], loss: 0.12819 acc: 0.98667 val_loss: 0.13816, val_acc: 0.96000\n",
      "Epoch [9810/10000], loss: 0.12813 acc: 0.98667 val_loss: 0.13811, val_acc: 0.96000\n",
      "Epoch [9820/10000], loss: 0.12808 acc: 0.98667 val_loss: 0.13806, val_acc: 0.96000\n",
      "Epoch [9830/10000], loss: 0.12802 acc: 0.98667 val_loss: 0.13801, val_acc: 0.96000\n",
      "Epoch [9840/10000], loss: 0.12796 acc: 0.98667 val_loss: 0.13796, val_acc: 0.96000\n",
      "Epoch [9850/10000], loss: 0.12790 acc: 0.98667 val_loss: 0.13791, val_acc: 0.96000\n",
      "Epoch [9860/10000], loss: 0.12784 acc: 0.98667 val_loss: 0.13786, val_acc: 0.96000\n",
      "Epoch [9870/10000], loss: 0.12778 acc: 0.98667 val_loss: 0.13782, val_acc: 0.96000\n",
      "Epoch [9880/10000], loss: 0.12772 acc: 0.98667 val_loss: 0.13777, val_acc: 0.96000\n",
      "Epoch [9890/10000], loss: 0.12767 acc: 0.98667 val_loss: 0.13772, val_acc: 0.96000\n",
      "Epoch [9900/10000], loss: 0.12761 acc: 0.98667 val_loss: 0.13767, val_acc: 0.96000\n",
      "Epoch [9910/10000], loss: 0.12755 acc: 0.98667 val_loss: 0.13762, val_acc: 0.96000\n",
      "Epoch [9920/10000], loss: 0.12749 acc: 0.98667 val_loss: 0.13757, val_acc: 0.96000\n",
      "Epoch [9930/10000], loss: 0.12743 acc: 0.98667 val_loss: 0.13752, val_acc: 0.96000\n",
      "Epoch [9940/10000], loss: 0.12738 acc: 0.98667 val_loss: 0.13748, val_acc: 0.96000\n",
      "Epoch [9950/10000], loss: 0.12732 acc: 0.98667 val_loss: 0.13743, val_acc: 0.96000\n",
      "Epoch [9960/10000], loss: 0.12726 acc: 0.98667 val_loss: 0.13738, val_acc: 0.96000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9970/10000], loss: 0.12720 acc: 0.98667 val_loss: 0.13733, val_acc: 0.96000\n",
      "Epoch [9980/10000], loss: 0.12715 acc: 0.98667 val_loss: 0.13728, val_acc: 0.96000\n",
      "Epoch [9990/10000], loss: 0.12709 acc: 0.98667 val_loss: 0.13724, val_acc: 0.96000\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "\n",
    "    # 学習フェーズ\n",
    "    \n",
    "    #勾配の初期化\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 順伝搬計算\n",
    "    outputs = net(inputs)\n",
    "\n",
    "    # 誤差計算\n",
    "    loss = criterion(outputs, labels)\n",
    "\n",
    "    # 勾配計算\n",
    "    loss.backward()\n",
    "    \n",
    "    # 重み調整\n",
    "    optimizer.step()\n",
    "\n",
    "    #予測値算出\n",
    "    predicted = torch.max(outputs, 1)[1]\n",
    "\n",
    "    # 訓練データに対する損失と精度の計算\n",
    "    train_loss = loss.item()\n",
    "    train_acc = (predicted == labels).sum()  / len(labels)\n",
    "\n",
    "    #予測フェーズ\n",
    "    with torch.no_grad():\n",
    "\n",
    "        # 順伝搬計算\n",
    "        outputs_test = net(inputs_test)\n",
    "\n",
    "        # 誤差計算\n",
    "        # loss_test = criterion(torch.log(outputs_test), labels_test)\n",
    "        loss_test = criterion(outputs_test, labels_test)\n",
    "\n",
    "        #予測値算出\n",
    "        predicted_test = torch.max(outputs_test, 1)[1]\n",
    "\n",
    "        # 検証データに対する損失と精度の計算\n",
    "        val_loss =  loss_test.item()\n",
    "        val_acc =  (predicted_test == labels_test).sum() / len(labels_test)\n",
    "    \n",
    "    if ( epoch % 10 == 0):\n",
    "        print (f'Epoch [{epoch}/{num_epochs}], loss: {train_loss:.5f} acc: {train_acc:.5f} val_loss: {val_loss:.5f}, val_acc: {val_acc:.5f}')\n",
    "        item = np.array([epoch , train_loss, train_acc, val_loss, val_acc])\n",
    "        history = np.vstack((history, item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "初期状態: 損失関数: 1.09158 精度: 0.26667\n",
      "最終状態: 損失関数: 0.13724 精度: 0.96000\n"
     ]
    }
   ],
   "source": [
    "#損失関数値と精度の確認\n",
    "\n",
    "print(f'初期状態: 損失関数: {history[0,3]:.5f} 精度: {history[0,4]:.5f}' )\n",
    "print(f'最終状態: 損失関数: {history[-1,3]:.5f} 精度: {history[-1,4]:.5f}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -5.1283  -0.0992  -2.4251]\n",
      " [ -4.9799  -0.021   -4.274 ]\n",
      " [ -0.0563  -2.9047 -16.2378]\n",
      " [-11.7813  -3.2099  -0.0412]\n",
      " [ -9.2329  -1.747   -0.1916]]\n",
      "[[0.0059 0.9056 0.0885]\n",
      " [0.0069 0.9792 0.0139]\n",
      " [0.9452 0.0548 0.    ]\n",
      " [0.     0.0404 0.9596]\n",
      " [0.0001 0.1743 0.8256]]\n"
     ]
    }
   ],
   "source": [
    "# パターン1モデルの出力結果\n",
    "w = outputs[:5,:].data\n",
    "print(w.numpy())\n",
    "\n",
    "# 確率値を得たい場合\n",
    "print(torch.exp(w).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### パターン2 モデルクラス側は素のsoftmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの定義\n",
    "# 2入力3出力のロジスティック回帰モデル\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, n_input, n_output):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(n_input, n_output)\n",
    "        # softmax関数の定義\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "                \n",
    "        # 初期値を全部1にする\n",
    "        # 「ディープラーニングの数学」と条件を合わせる目的        \n",
    "        self.l1.weight.data.fill_(1.0)\n",
    "        self.l1.bias.data.fill_(1.0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.l1(x)\n",
    "        x2 = self.softmax(x1)\n",
    "        return x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習率\n",
    "lr = 0.01\n",
    "\n",
    "# 初期化\n",
    "net = Net(n_input, n_output)\n",
    "\n",
    "# 最適化アルゴリズム: 勾配降下法\n",
    "optimizer = optim.SGD(net.parameters(), lr=lr)\n",
    "\n",
    "# 損失関数： NLLLoss\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# 繰り返し回数\n",
    "num_epochs = 10000\n",
    "\n",
    "# 評価結果記録用\n",
    "history = np.zeros((0,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/10000], loss: 1.09861 acc: 0.30667 val_loss: 1.09158, val_acc: 0.26667\n",
      "Epoch [10/10000], loss: 1.01848 acc: 0.40000 val_loss: 1.04171, val_acc: 0.26667\n",
      "Epoch [20/10000], loss: 0.96854 acc: 0.40000 val_loss: 0.98850, val_acc: 0.26667\n",
      "Epoch [30/10000], loss: 0.92459 acc: 0.65333 val_loss: 0.93996, val_acc: 0.57333\n",
      "Epoch [40/10000], loss: 0.88568 acc: 0.70667 val_loss: 0.89704, val_acc: 0.62667\n",
      "Epoch [50/10000], loss: 0.85120 acc: 0.70667 val_loss: 0.85918, val_acc: 0.62667\n",
      "Epoch [60/10000], loss: 0.82059 acc: 0.70667 val_loss: 0.82572, val_acc: 0.62667\n",
      "Epoch [70/10000], loss: 0.79335 acc: 0.72000 val_loss: 0.79607, val_acc: 0.62667\n",
      "Epoch [80/10000], loss: 0.76900 acc: 0.72000 val_loss: 0.76968, val_acc: 0.65333\n",
      "Epoch [90/10000], loss: 0.74717 acc: 0.72000 val_loss: 0.74610, val_acc: 0.65333\n",
      "Epoch [100/10000], loss: 0.72750 acc: 0.76000 val_loss: 0.72494, val_acc: 0.69333\n",
      "Epoch [110/10000], loss: 0.70970 acc: 0.77333 val_loss: 0.70585, val_acc: 0.74667\n",
      "Epoch [120/10000], loss: 0.69354 acc: 0.81333 val_loss: 0.68856, val_acc: 0.76000\n",
      "Epoch [130/10000], loss: 0.67878 acc: 0.84000 val_loss: 0.67283, val_acc: 0.76000\n",
      "Epoch [140/10000], loss: 0.66526 acc: 0.84000 val_loss: 0.65846, val_acc: 0.78667\n",
      "Epoch [150/10000], loss: 0.65283 acc: 0.86667 val_loss: 0.64528, val_acc: 0.78667\n",
      "Epoch [160/10000], loss: 0.64135 acc: 0.88000 val_loss: 0.63313, val_acc: 0.78667\n",
      "Epoch [170/10000], loss: 0.63070 acc: 0.89333 val_loss: 0.62190, val_acc: 0.81333\n",
      "Epoch [180/10000], loss: 0.62080 acc: 0.90667 val_loss: 0.61149, val_acc: 0.81333\n",
      "Epoch [190/10000], loss: 0.61157 acc: 0.90667 val_loss: 0.60179, val_acc: 0.84000\n",
      "Epoch [200/10000], loss: 0.60292 acc: 0.90667 val_loss: 0.59273, val_acc: 0.84000\n",
      "Epoch [210/10000], loss: 0.59481 acc: 0.90667 val_loss: 0.58425, val_acc: 0.88000\n",
      "Epoch [220/10000], loss: 0.58717 acc: 0.93333 val_loss: 0.57628, val_acc: 0.88000\n",
      "Epoch [230/10000], loss: 0.57996 acc: 0.93333 val_loss: 0.56877, val_acc: 0.89333\n",
      "Epoch [240/10000], loss: 0.57313 acc: 0.93333 val_loss: 0.56169, val_acc: 0.90667\n",
      "Epoch [250/10000], loss: 0.56666 acc: 0.93333 val_loss: 0.55498, val_acc: 0.90667\n",
      "Epoch [260/10000], loss: 0.56051 acc: 0.92000 val_loss: 0.54862, val_acc: 0.90667\n",
      "Epoch [270/10000], loss: 0.55465 acc: 0.92000 val_loss: 0.54257, val_acc: 0.90667\n",
      "Epoch [280/10000], loss: 0.54906 acc: 0.92000 val_loss: 0.53681, val_acc: 0.90667\n",
      "Epoch [290/10000], loss: 0.54371 acc: 0.92000 val_loss: 0.53131, val_acc: 0.90667\n",
      "Epoch [300/10000], loss: 0.53859 acc: 0.93333 val_loss: 0.52605, val_acc: 0.90667\n",
      "Epoch [310/10000], loss: 0.53368 acc: 0.93333 val_loss: 0.52102, val_acc: 0.90667\n",
      "Epoch [320/10000], loss: 0.52896 acc: 0.93333 val_loss: 0.51619, val_acc: 0.90667\n",
      "Epoch [330/10000], loss: 0.52442 acc: 0.93333 val_loss: 0.51155, val_acc: 0.90667\n",
      "Epoch [340/10000], loss: 0.52004 acc: 0.93333 val_loss: 0.50709, val_acc: 0.90667\n",
      "Epoch [350/10000], loss: 0.51582 acc: 0.93333 val_loss: 0.50280, val_acc: 0.90667\n",
      "Epoch [360/10000], loss: 0.51173 acc: 0.93333 val_loss: 0.49865, val_acc: 0.90667\n",
      "Epoch [370/10000], loss: 0.50779 acc: 0.93333 val_loss: 0.49465, val_acc: 0.90667\n",
      "Epoch [380/10000], loss: 0.50397 acc: 0.93333 val_loss: 0.49078, val_acc: 0.90667\n",
      "Epoch [390/10000], loss: 0.50026 acc: 0.93333 val_loss: 0.48703, val_acc: 0.90667\n",
      "Epoch [400/10000], loss: 0.49666 acc: 0.94667 val_loss: 0.48340, val_acc: 0.90667\n",
      "Epoch [410/10000], loss: 0.49317 acc: 0.94667 val_loss: 0.47988, val_acc: 0.90667\n",
      "Epoch [420/10000], loss: 0.48978 acc: 0.94667 val_loss: 0.47647, val_acc: 0.90667\n",
      "Epoch [430/10000], loss: 0.48647 acc: 0.96000 val_loss: 0.47315, val_acc: 0.90667\n",
      "Epoch [440/10000], loss: 0.48326 acc: 0.96000 val_loss: 0.46992, val_acc: 0.90667\n",
      "Epoch [450/10000], loss: 0.48012 acc: 0.96000 val_loss: 0.46678, val_acc: 0.90667\n",
      "Epoch [460/10000], loss: 0.47706 acc: 0.96000 val_loss: 0.46372, val_acc: 0.90667\n",
      "Epoch [470/10000], loss: 0.47408 acc: 0.96000 val_loss: 0.46073, val_acc: 0.90667\n",
      "Epoch [480/10000], loss: 0.47116 acc: 0.96000 val_loss: 0.45783, val_acc: 0.90667\n",
      "Epoch [490/10000], loss: 0.46831 acc: 0.96000 val_loss: 0.45499, val_acc: 0.90667\n",
      "Epoch [500/10000], loss: 0.46553 acc: 0.96000 val_loss: 0.45221, val_acc: 0.90667\n",
      "Epoch [510/10000], loss: 0.46280 acc: 0.96000 val_loss: 0.44950, val_acc: 0.90667\n",
      "Epoch [520/10000], loss: 0.46013 acc: 0.96000 val_loss: 0.44686, val_acc: 0.90667\n",
      "Epoch [530/10000], loss: 0.45752 acc: 0.96000 val_loss: 0.44426, val_acc: 0.90667\n",
      "Epoch [540/10000], loss: 0.45496 acc: 0.96000 val_loss: 0.44173, val_acc: 0.90667\n",
      "Epoch [550/10000], loss: 0.45245 acc: 0.96000 val_loss: 0.43924, val_acc: 0.90667\n",
      "Epoch [560/10000], loss: 0.44998 acc: 0.96000 val_loss: 0.43681, val_acc: 0.90667\n",
      "Epoch [570/10000], loss: 0.44757 acc: 0.96000 val_loss: 0.43442, val_acc: 0.90667\n",
      "Epoch [580/10000], loss: 0.44519 acc: 0.96000 val_loss: 0.43208, val_acc: 0.90667\n",
      "Epoch [590/10000], loss: 0.44286 acc: 0.96000 val_loss: 0.42979, val_acc: 0.92000\n",
      "Epoch [600/10000], loss: 0.44057 acc: 0.96000 val_loss: 0.42753, val_acc: 0.92000\n",
      "Epoch [610/10000], loss: 0.43832 acc: 0.96000 val_loss: 0.42532, val_acc: 0.92000\n",
      "Epoch [620/10000], loss: 0.43611 acc: 0.96000 val_loss: 0.42315, val_acc: 0.92000\n",
      "Epoch [630/10000], loss: 0.43393 acc: 0.96000 val_loss: 0.42101, val_acc: 0.92000\n",
      "Epoch [640/10000], loss: 0.43179 acc: 0.96000 val_loss: 0.41891, val_acc: 0.92000\n",
      "Epoch [650/10000], loss: 0.42968 acc: 0.96000 val_loss: 0.41685, val_acc: 0.92000\n",
      "Epoch [660/10000], loss: 0.42761 acc: 0.96000 val_loss: 0.41482, val_acc: 0.92000\n",
      "Epoch [670/10000], loss: 0.42556 acc: 0.96000 val_loss: 0.41282, val_acc: 0.92000\n",
      "Epoch [680/10000], loss: 0.42355 acc: 0.96000 val_loss: 0.41085, val_acc: 0.92000\n",
      "Epoch [690/10000], loss: 0.42157 acc: 0.96000 val_loss: 0.40892, val_acc: 0.92000\n",
      "Epoch [700/10000], loss: 0.41961 acc: 0.96000 val_loss: 0.40701, val_acc: 0.92000\n",
      "Epoch [710/10000], loss: 0.41768 acc: 0.96000 val_loss: 0.40513, val_acc: 0.92000\n",
      "Epoch [720/10000], loss: 0.41578 acc: 0.96000 val_loss: 0.40329, val_acc: 0.92000\n",
      "Epoch [730/10000], loss: 0.41391 acc: 0.96000 val_loss: 0.40146, val_acc: 0.92000\n",
      "Epoch [740/10000], loss: 0.41206 acc: 0.96000 val_loss: 0.39967, val_acc: 0.92000\n",
      "Epoch [750/10000], loss: 0.41024 acc: 0.96000 val_loss: 0.39789, val_acc: 0.92000\n",
      "Epoch [760/10000], loss: 0.40844 acc: 0.96000 val_loss: 0.39615, val_acc: 0.92000\n",
      "Epoch [770/10000], loss: 0.40666 acc: 0.96000 val_loss: 0.39443, val_acc: 0.93333\n",
      "Epoch [780/10000], loss: 0.40491 acc: 0.96000 val_loss: 0.39273, val_acc: 0.93333\n",
      "Epoch [790/10000], loss: 0.40317 acc: 0.96000 val_loss: 0.39105, val_acc: 0.93333\n",
      "Epoch [800/10000], loss: 0.40146 acc: 0.96000 val_loss: 0.38939, val_acc: 0.93333\n",
      "Epoch [810/10000], loss: 0.39977 acc: 0.96000 val_loss: 0.38776, val_acc: 0.93333\n",
      "Epoch [820/10000], loss: 0.39810 acc: 0.96000 val_loss: 0.38615, val_acc: 0.93333\n",
      "Epoch [830/10000], loss: 0.39646 acc: 0.96000 val_loss: 0.38456, val_acc: 0.93333\n",
      "Epoch [840/10000], loss: 0.39483 acc: 0.96000 val_loss: 0.38298, val_acc: 0.93333\n",
      "Epoch [850/10000], loss: 0.39321 acc: 0.97333 val_loss: 0.38143, val_acc: 0.94667\n",
      "Epoch [860/10000], loss: 0.39162 acc: 0.97333 val_loss: 0.37990, val_acc: 0.94667\n",
      "Epoch [870/10000], loss: 0.39005 acc: 0.97333 val_loss: 0.37838, val_acc: 0.94667\n",
      "Epoch [880/10000], loss: 0.38849 acc: 0.97333 val_loss: 0.37688, val_acc: 0.94667\n",
      "Epoch [890/10000], loss: 0.38695 acc: 0.97333 val_loss: 0.37540, val_acc: 0.94667\n",
      "Epoch [900/10000], loss: 0.38543 acc: 0.97333 val_loss: 0.37394, val_acc: 0.94667\n",
      "Epoch [910/10000], loss: 0.38392 acc: 0.97333 val_loss: 0.37249, val_acc: 0.94667\n",
      "Epoch [920/10000], loss: 0.38243 acc: 0.97333 val_loss: 0.37106, val_acc: 0.94667\n",
      "Epoch [930/10000], loss: 0.38096 acc: 0.97333 val_loss: 0.36965, val_acc: 0.94667\n",
      "Epoch [940/10000], loss: 0.37950 acc: 0.97333 val_loss: 0.36825, val_acc: 0.94667\n",
      "Epoch [950/10000], loss: 0.37806 acc: 0.97333 val_loss: 0.36686, val_acc: 0.94667\n",
      "Epoch [960/10000], loss: 0.37663 acc: 0.97333 val_loss: 0.36550, val_acc: 0.96000\n",
      "Epoch [970/10000], loss: 0.37522 acc: 0.97333 val_loss: 0.36414, val_acc: 0.96000\n",
      "Epoch [980/10000], loss: 0.37382 acc: 0.97333 val_loss: 0.36280, val_acc: 0.96000\n",
      "Epoch [990/10000], loss: 0.37243 acc: 0.97333 val_loss: 0.36148, val_acc: 0.96000\n",
      "Epoch [1000/10000], loss: 0.37106 acc: 0.97333 val_loss: 0.36017, val_acc: 0.96000\n",
      "Epoch [1010/10000], loss: 0.36970 acc: 0.97333 val_loss: 0.35887, val_acc: 0.96000\n",
      "Epoch [1020/10000], loss: 0.36836 acc: 0.97333 val_loss: 0.35759, val_acc: 0.96000\n",
      "Epoch [1030/10000], loss: 0.36703 acc: 0.97333 val_loss: 0.35631, val_acc: 0.96000\n",
      "Epoch [1040/10000], loss: 0.36571 acc: 0.97333 val_loss: 0.35506, val_acc: 0.96000\n",
      "Epoch [1050/10000], loss: 0.36440 acc: 0.97333 val_loss: 0.35381, val_acc: 0.96000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1060/10000], loss: 0.36311 acc: 0.97333 val_loss: 0.35258, val_acc: 0.96000\n",
      "Epoch [1070/10000], loss: 0.36183 acc: 0.97333 val_loss: 0.35135, val_acc: 0.96000\n",
      "Epoch [1080/10000], loss: 0.36056 acc: 0.97333 val_loss: 0.35014, val_acc: 0.96000\n",
      "Epoch [1090/10000], loss: 0.35930 acc: 0.97333 val_loss: 0.34895, val_acc: 0.96000\n",
      "Epoch [1100/10000], loss: 0.35805 acc: 0.97333 val_loss: 0.34776, val_acc: 0.96000\n",
      "Epoch [1110/10000], loss: 0.35682 acc: 0.97333 val_loss: 0.34659, val_acc: 0.96000\n",
      "Epoch [1120/10000], loss: 0.35559 acc: 0.97333 val_loss: 0.34542, val_acc: 0.96000\n",
      "Epoch [1130/10000], loss: 0.35438 acc: 0.97333 val_loss: 0.34427, val_acc: 0.96000\n",
      "Epoch [1140/10000], loss: 0.35318 acc: 0.97333 val_loss: 0.34313, val_acc: 0.96000\n",
      "Epoch [1150/10000], loss: 0.35199 acc: 0.97333 val_loss: 0.34199, val_acc: 0.96000\n",
      "Epoch [1160/10000], loss: 0.35081 acc: 0.97333 val_loss: 0.34087, val_acc: 0.96000\n",
      "Epoch [1170/10000], loss: 0.34964 acc: 0.97333 val_loss: 0.33976, val_acc: 0.96000\n",
      "Epoch [1180/10000], loss: 0.34848 acc: 0.97333 val_loss: 0.33866, val_acc: 0.96000\n",
      "Epoch [1190/10000], loss: 0.34732 acc: 0.97333 val_loss: 0.33757, val_acc: 0.96000\n",
      "Epoch [1200/10000], loss: 0.34618 acc: 0.97333 val_loss: 0.33649, val_acc: 0.96000\n",
      "Epoch [1210/10000], loss: 0.34505 acc: 0.97333 val_loss: 0.33542, val_acc: 0.96000\n",
      "Epoch [1220/10000], loss: 0.34393 acc: 0.97333 val_loss: 0.33435, val_acc: 0.96000\n",
      "Epoch [1230/10000], loss: 0.34282 acc: 0.97333 val_loss: 0.33330, val_acc: 0.96000\n",
      "Epoch [1240/10000], loss: 0.34172 acc: 0.97333 val_loss: 0.33226, val_acc: 0.96000\n",
      "Epoch [1250/10000], loss: 0.34062 acc: 0.97333 val_loss: 0.33122, val_acc: 0.96000\n",
      "Epoch [1260/10000], loss: 0.33954 acc: 0.97333 val_loss: 0.33020, val_acc: 0.96000\n",
      "Epoch [1270/10000], loss: 0.33846 acc: 0.97333 val_loss: 0.32918, val_acc: 0.96000\n",
      "Epoch [1280/10000], loss: 0.33740 acc: 0.97333 val_loss: 0.32817, val_acc: 0.96000\n",
      "Epoch [1290/10000], loss: 0.33634 acc: 0.97333 val_loss: 0.32717, val_acc: 0.96000\n",
      "Epoch [1300/10000], loss: 0.33529 acc: 0.97333 val_loss: 0.32618, val_acc: 0.96000\n",
      "Epoch [1310/10000], loss: 0.33425 acc: 0.97333 val_loss: 0.32520, val_acc: 0.96000\n",
      "Epoch [1320/10000], loss: 0.33321 acc: 0.97333 val_loss: 0.32422, val_acc: 0.96000\n",
      "Epoch [1330/10000], loss: 0.33219 acc: 0.97333 val_loss: 0.32325, val_acc: 0.96000\n",
      "Epoch [1340/10000], loss: 0.33117 acc: 0.97333 val_loss: 0.32229, val_acc: 0.96000\n",
      "Epoch [1350/10000], loss: 0.33016 acc: 0.97333 val_loss: 0.32134, val_acc: 0.96000\n",
      "Epoch [1360/10000], loss: 0.32916 acc: 0.97333 val_loss: 0.32040, val_acc: 0.96000\n",
      "Epoch [1370/10000], loss: 0.32817 acc: 0.97333 val_loss: 0.31946, val_acc: 0.96000\n",
      "Epoch [1380/10000], loss: 0.32719 acc: 0.97333 val_loss: 0.31853, val_acc: 0.96000\n",
      "Epoch [1390/10000], loss: 0.32621 acc: 0.97333 val_loss: 0.31761, val_acc: 0.96000\n",
      "Epoch [1400/10000], loss: 0.32524 acc: 0.97333 val_loss: 0.31670, val_acc: 0.96000\n",
      "Epoch [1410/10000], loss: 0.32428 acc: 0.97333 val_loss: 0.31579, val_acc: 0.96000\n",
      "Epoch [1420/10000], loss: 0.32332 acc: 0.97333 val_loss: 0.31489, val_acc: 0.96000\n",
      "Epoch [1430/10000], loss: 0.32237 acc: 0.97333 val_loss: 0.31400, val_acc: 0.96000\n",
      "Epoch [1440/10000], loss: 0.32143 acc: 0.97333 val_loss: 0.31312, val_acc: 0.96000\n",
      "Epoch [1450/10000], loss: 0.32050 acc: 0.97333 val_loss: 0.31224, val_acc: 0.96000\n",
      "Epoch [1460/10000], loss: 0.31957 acc: 0.97333 val_loss: 0.31137, val_acc: 0.96000\n",
      "Epoch [1470/10000], loss: 0.31865 acc: 0.97333 val_loss: 0.31050, val_acc: 0.96000\n",
      "Epoch [1480/10000], loss: 0.31774 acc: 0.97333 val_loss: 0.30964, val_acc: 0.96000\n",
      "Epoch [1490/10000], loss: 0.31683 acc: 0.97333 val_loss: 0.30879, val_acc: 0.96000\n",
      "Epoch [1500/10000], loss: 0.31593 acc: 0.97333 val_loss: 0.30795, val_acc: 0.96000\n",
      "Epoch [1510/10000], loss: 0.31504 acc: 0.97333 val_loss: 0.30711, val_acc: 0.96000\n",
      "Epoch [1520/10000], loss: 0.31415 acc: 0.97333 val_loss: 0.30628, val_acc: 0.96000\n",
      "Epoch [1530/10000], loss: 0.31327 acc: 0.97333 val_loss: 0.30545, val_acc: 0.96000\n",
      "Epoch [1540/10000], loss: 0.31240 acc: 0.97333 val_loss: 0.30463, val_acc: 0.96000\n",
      "Epoch [1550/10000], loss: 0.31153 acc: 0.97333 val_loss: 0.30382, val_acc: 0.96000\n",
      "Epoch [1560/10000], loss: 0.31067 acc: 0.97333 val_loss: 0.30301, val_acc: 0.96000\n",
      "Epoch [1570/10000], loss: 0.30981 acc: 0.97333 val_loss: 0.30221, val_acc: 0.96000\n",
      "Epoch [1580/10000], loss: 0.30896 acc: 0.97333 val_loss: 0.30141, val_acc: 0.96000\n",
      "Epoch [1590/10000], loss: 0.30812 acc: 0.97333 val_loss: 0.30062, val_acc: 0.96000\n",
      "Epoch [1600/10000], loss: 0.30728 acc: 0.97333 val_loss: 0.29984, val_acc: 0.96000\n",
      "Epoch [1610/10000], loss: 0.30645 acc: 0.97333 val_loss: 0.29906, val_acc: 0.96000\n",
      "Epoch [1620/10000], loss: 0.30562 acc: 0.97333 val_loss: 0.29828, val_acc: 0.96000\n",
      "Epoch [1630/10000], loss: 0.30480 acc: 0.97333 val_loss: 0.29752, val_acc: 0.96000\n",
      "Epoch [1640/10000], loss: 0.30399 acc: 0.97333 val_loss: 0.29675, val_acc: 0.96000\n",
      "Epoch [1650/10000], loss: 0.30318 acc: 0.97333 val_loss: 0.29600, val_acc: 0.96000\n",
      "Epoch [1660/10000], loss: 0.30237 acc: 0.97333 val_loss: 0.29525, val_acc: 0.96000\n",
      "Epoch [1670/10000], loss: 0.30158 acc: 0.97333 val_loss: 0.29450, val_acc: 0.96000\n",
      "Epoch [1680/10000], loss: 0.30078 acc: 0.97333 val_loss: 0.29376, val_acc: 0.96000\n",
      "Epoch [1690/10000], loss: 0.30000 acc: 0.97333 val_loss: 0.29302, val_acc: 0.96000\n",
      "Epoch [1700/10000], loss: 0.29922 acc: 0.97333 val_loss: 0.29229, val_acc: 0.96000\n",
      "Epoch [1710/10000], loss: 0.29844 acc: 0.97333 val_loss: 0.29157, val_acc: 0.96000\n",
      "Epoch [1720/10000], loss: 0.29767 acc: 0.97333 val_loss: 0.29085, val_acc: 0.96000\n",
      "Epoch [1730/10000], loss: 0.29690 acc: 0.97333 val_loss: 0.29013, val_acc: 0.96000\n",
      "Epoch [1740/10000], loss: 0.29614 acc: 0.97333 val_loss: 0.28942, val_acc: 0.96000\n",
      "Epoch [1750/10000], loss: 0.29538 acc: 0.97333 val_loss: 0.28872, val_acc: 0.96000\n",
      "Epoch [1760/10000], loss: 0.29463 acc: 0.97333 val_loss: 0.28801, val_acc: 0.96000\n",
      "Epoch [1770/10000], loss: 0.29389 acc: 0.97333 val_loss: 0.28732, val_acc: 0.96000\n",
      "Epoch [1780/10000], loss: 0.29315 acc: 0.97333 val_loss: 0.28663, val_acc: 0.96000\n",
      "Epoch [1790/10000], loss: 0.29241 acc: 0.97333 val_loss: 0.28594, val_acc: 0.96000\n",
      "Epoch [1800/10000], loss: 0.29168 acc: 0.97333 val_loss: 0.28526, val_acc: 0.96000\n",
      "Epoch [1810/10000], loss: 0.29095 acc: 0.97333 val_loss: 0.28458, val_acc: 0.96000\n",
      "Epoch [1820/10000], loss: 0.29023 acc: 0.97333 val_loss: 0.28391, val_acc: 0.96000\n",
      "Epoch [1830/10000], loss: 0.28951 acc: 0.97333 val_loss: 0.28324, val_acc: 0.96000\n",
      "Epoch [1840/10000], loss: 0.28880 acc: 0.97333 val_loss: 0.28258, val_acc: 0.96000\n",
      "Epoch [1850/10000], loss: 0.28809 acc: 0.97333 val_loss: 0.28192, val_acc: 0.96000\n",
      "Epoch [1860/10000], loss: 0.28739 acc: 0.97333 val_loss: 0.28126, val_acc: 0.96000\n",
      "Epoch [1870/10000], loss: 0.28669 acc: 0.97333 val_loss: 0.28061, val_acc: 0.96000\n",
      "Epoch [1880/10000], loss: 0.28599 acc: 0.97333 val_loss: 0.27996, val_acc: 0.96000\n",
      "Epoch [1890/10000], loss: 0.28530 acc: 0.97333 val_loss: 0.27932, val_acc: 0.96000\n",
      "Epoch [1900/10000], loss: 0.28462 acc: 0.97333 val_loss: 0.27868, val_acc: 0.96000\n",
      "Epoch [1910/10000], loss: 0.28394 acc: 0.97333 val_loss: 0.27805, val_acc: 0.96000\n",
      "Epoch [1920/10000], loss: 0.28326 acc: 0.97333 val_loss: 0.27742, val_acc: 0.96000\n",
      "Epoch [1930/10000], loss: 0.28258 acc: 0.97333 val_loss: 0.27679, val_acc: 0.96000\n",
      "Epoch [1940/10000], loss: 0.28192 acc: 0.97333 val_loss: 0.27617, val_acc: 0.96000\n",
      "Epoch [1950/10000], loss: 0.28125 acc: 0.97333 val_loss: 0.27555, val_acc: 0.96000\n",
      "Epoch [1960/10000], loss: 0.28059 acc: 0.97333 val_loss: 0.27494, val_acc: 0.96000\n",
      "Epoch [1970/10000], loss: 0.27993 acc: 0.97333 val_loss: 0.27433, val_acc: 0.96000\n",
      "Epoch [1980/10000], loss: 0.27928 acc: 0.97333 val_loss: 0.27372, val_acc: 0.96000\n",
      "Epoch [1990/10000], loss: 0.27863 acc: 0.97333 val_loss: 0.27312, val_acc: 0.96000\n",
      "Epoch [2000/10000], loss: 0.27799 acc: 0.97333 val_loss: 0.27252, val_acc: 0.96000\n",
      "Epoch [2010/10000], loss: 0.27735 acc: 0.97333 val_loss: 0.27193, val_acc: 0.96000\n",
      "Epoch [2020/10000], loss: 0.27671 acc: 0.97333 val_loss: 0.27134, val_acc: 0.96000\n",
      "Epoch [2030/10000], loss: 0.27608 acc: 0.97333 val_loss: 0.27075, val_acc: 0.96000\n",
      "Epoch [2040/10000], loss: 0.27545 acc: 0.97333 val_loss: 0.27016, val_acc: 0.96000\n",
      "Epoch [2050/10000], loss: 0.27482 acc: 0.97333 val_loss: 0.26958, val_acc: 0.96000\n",
      "Epoch [2060/10000], loss: 0.27420 acc: 0.97333 val_loss: 0.26901, val_acc: 0.96000\n",
      "Epoch [2070/10000], loss: 0.27358 acc: 0.97333 val_loss: 0.26843, val_acc: 0.96000\n",
      "Epoch [2080/10000], loss: 0.27297 acc: 0.97333 val_loss: 0.26786, val_acc: 0.96000\n",
      "Epoch [2090/10000], loss: 0.27236 acc: 0.97333 val_loss: 0.26730, val_acc: 0.96000\n",
      "Epoch [2100/10000], loss: 0.27175 acc: 0.97333 val_loss: 0.26674, val_acc: 0.96000\n",
      "Epoch [2110/10000], loss: 0.27115 acc: 0.97333 val_loss: 0.26618, val_acc: 0.96000\n",
      "Epoch [2120/10000], loss: 0.27055 acc: 0.97333 val_loss: 0.26562, val_acc: 0.96000\n",
      "Epoch [2130/10000], loss: 0.26995 acc: 0.97333 val_loss: 0.26507, val_acc: 0.96000\n",
      "Epoch [2140/10000], loss: 0.26936 acc: 0.97333 val_loss: 0.26452, val_acc: 0.96000\n",
      "Epoch [2150/10000], loss: 0.26877 acc: 0.97333 val_loss: 0.26397, val_acc: 0.96000\n",
      "Epoch [2160/10000], loss: 0.26818 acc: 0.97333 val_loss: 0.26343, val_acc: 0.96000\n",
      "Epoch [2170/10000], loss: 0.26760 acc: 0.97333 val_loss: 0.26289, val_acc: 0.96000\n",
      "Epoch [2180/10000], loss: 0.26702 acc: 0.97333 val_loss: 0.26236, val_acc: 0.96000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2190/10000], loss: 0.26644 acc: 0.97333 val_loss: 0.26182, val_acc: 0.96000\n",
      "Epoch [2200/10000], loss: 0.26587 acc: 0.97333 val_loss: 0.26129, val_acc: 0.96000\n",
      "Epoch [2210/10000], loss: 0.26530 acc: 0.97333 val_loss: 0.26077, val_acc: 0.96000\n",
      "Epoch [2220/10000], loss: 0.26473 acc: 0.97333 val_loss: 0.26024, val_acc: 0.96000\n",
      "Epoch [2230/10000], loss: 0.26417 acc: 0.97333 val_loss: 0.25972, val_acc: 0.96000\n",
      "Epoch [2240/10000], loss: 0.26361 acc: 0.97333 val_loss: 0.25921, val_acc: 0.96000\n",
      "Epoch [2250/10000], loss: 0.26305 acc: 0.97333 val_loss: 0.25869, val_acc: 0.96000\n",
      "Epoch [2260/10000], loss: 0.26250 acc: 0.97333 val_loss: 0.25818, val_acc: 0.96000\n",
      "Epoch [2270/10000], loss: 0.26195 acc: 0.97333 val_loss: 0.25767, val_acc: 0.96000\n",
      "Epoch [2280/10000], loss: 0.26140 acc: 0.97333 val_loss: 0.25717, val_acc: 0.96000\n",
      "Epoch [2290/10000], loss: 0.26086 acc: 0.97333 val_loss: 0.25666, val_acc: 0.96000\n",
      "Epoch [2300/10000], loss: 0.26032 acc: 0.97333 val_loss: 0.25616, val_acc: 0.96000\n",
      "Epoch [2310/10000], loss: 0.25978 acc: 0.97333 val_loss: 0.25567, val_acc: 0.96000\n",
      "Epoch [2320/10000], loss: 0.25924 acc: 0.97333 val_loss: 0.25517, val_acc: 0.96000\n",
      "Epoch [2330/10000], loss: 0.25871 acc: 0.97333 val_loss: 0.25468, val_acc: 0.96000\n",
      "Epoch [2340/10000], loss: 0.25818 acc: 0.97333 val_loss: 0.25419, val_acc: 0.96000\n",
      "Epoch [2350/10000], loss: 0.25766 acc: 0.97333 val_loss: 0.25371, val_acc: 0.96000\n",
      "Epoch [2360/10000], loss: 0.25713 acc: 0.97333 val_loss: 0.25322, val_acc: 0.96000\n",
      "Epoch [2370/10000], loss: 0.25661 acc: 0.97333 val_loss: 0.25274, val_acc: 0.96000\n",
      "Epoch [2380/10000], loss: 0.25609 acc: 0.97333 val_loss: 0.25227, val_acc: 0.96000\n",
      "Epoch [2390/10000], loss: 0.25558 acc: 0.97333 val_loss: 0.25179, val_acc: 0.96000\n",
      "Epoch [2400/10000], loss: 0.25507 acc: 0.97333 val_loss: 0.25132, val_acc: 0.96000\n",
      "Epoch [2410/10000], loss: 0.25456 acc: 0.97333 val_loss: 0.25085, val_acc: 0.96000\n",
      "Epoch [2420/10000], loss: 0.25405 acc: 0.97333 val_loss: 0.25038, val_acc: 0.96000\n",
      "Epoch [2430/10000], loss: 0.25355 acc: 0.97333 val_loss: 0.24992, val_acc: 0.96000\n",
      "Epoch [2440/10000], loss: 0.25304 acc: 0.97333 val_loss: 0.24946, val_acc: 0.96000\n",
      "Epoch [2450/10000], loss: 0.25255 acc: 0.97333 val_loss: 0.24900, val_acc: 0.96000\n",
      "Epoch [2460/10000], loss: 0.25205 acc: 0.97333 val_loss: 0.24854, val_acc: 0.96000\n",
      "Epoch [2470/10000], loss: 0.25156 acc: 0.97333 val_loss: 0.24809, val_acc: 0.96000\n",
      "Epoch [2480/10000], loss: 0.25107 acc: 0.97333 val_loss: 0.24764, val_acc: 0.96000\n",
      "Epoch [2490/10000], loss: 0.25058 acc: 0.97333 val_loss: 0.24719, val_acc: 0.96000\n",
      "Epoch [2500/10000], loss: 0.25009 acc: 0.97333 val_loss: 0.24674, val_acc: 0.96000\n",
      "Epoch [2510/10000], loss: 0.24961 acc: 0.97333 val_loss: 0.24630, val_acc: 0.96000\n",
      "Epoch [2520/10000], loss: 0.24913 acc: 0.97333 val_loss: 0.24585, val_acc: 0.96000\n",
      "Epoch [2530/10000], loss: 0.24865 acc: 0.97333 val_loss: 0.24541, val_acc: 0.96000\n",
      "Epoch [2540/10000], loss: 0.24818 acc: 0.97333 val_loss: 0.24498, val_acc: 0.96000\n",
      "Epoch [2550/10000], loss: 0.24770 acc: 0.97333 val_loss: 0.24454, val_acc: 0.96000\n",
      "Epoch [2560/10000], loss: 0.24723 acc: 0.97333 val_loss: 0.24411, val_acc: 0.96000\n",
      "Epoch [2570/10000], loss: 0.24676 acc: 0.97333 val_loss: 0.24368, val_acc: 0.96000\n",
      "Epoch [2580/10000], loss: 0.24630 acc: 0.98667 val_loss: 0.24325, val_acc: 0.96000\n",
      "Epoch [2590/10000], loss: 0.24584 acc: 0.98667 val_loss: 0.24283, val_acc: 0.96000\n",
      "Epoch [2600/10000], loss: 0.24537 acc: 0.98667 val_loss: 0.24240, val_acc: 0.96000\n",
      "Epoch [2610/10000], loss: 0.24492 acc: 0.98667 val_loss: 0.24198, val_acc: 0.96000\n",
      "Epoch [2620/10000], loss: 0.24446 acc: 0.98667 val_loss: 0.24156, val_acc: 0.96000\n",
      "Epoch [2630/10000], loss: 0.24401 acc: 0.98667 val_loss: 0.24115, val_acc: 0.96000\n",
      "Epoch [2640/10000], loss: 0.24355 acc: 0.98667 val_loss: 0.24073, val_acc: 0.96000\n",
      "Epoch [2650/10000], loss: 0.24311 acc: 0.98667 val_loss: 0.24032, val_acc: 0.96000\n",
      "Epoch [2660/10000], loss: 0.24266 acc: 0.98667 val_loss: 0.23991, val_acc: 0.96000\n",
      "Epoch [2670/10000], loss: 0.24221 acc: 0.98667 val_loss: 0.23950, val_acc: 0.96000\n",
      "Epoch [2680/10000], loss: 0.24177 acc: 0.98667 val_loss: 0.23909, val_acc: 0.96000\n",
      "Epoch [2690/10000], loss: 0.24133 acc: 0.98667 val_loss: 0.23869, val_acc: 0.96000\n",
      "Epoch [2700/10000], loss: 0.24089 acc: 0.98667 val_loss: 0.23829, val_acc: 0.96000\n",
      "Epoch [2710/10000], loss: 0.24046 acc: 0.98667 val_loss: 0.23789, val_acc: 0.96000\n",
      "Epoch [2720/10000], loss: 0.24002 acc: 0.98667 val_loss: 0.23749, val_acc: 0.96000\n",
      "Epoch [2730/10000], loss: 0.23959 acc: 0.98667 val_loss: 0.23710, val_acc: 0.96000\n",
      "Epoch [2740/10000], loss: 0.23916 acc: 0.98667 val_loss: 0.23670, val_acc: 0.96000\n",
      "Epoch [2750/10000], loss: 0.23874 acc: 0.98667 val_loss: 0.23631, val_acc: 0.96000\n",
      "Epoch [2760/10000], loss: 0.23831 acc: 0.98667 val_loss: 0.23592, val_acc: 0.96000\n",
      "Epoch [2770/10000], loss: 0.23789 acc: 0.98667 val_loss: 0.23553, val_acc: 0.96000\n",
      "Epoch [2780/10000], loss: 0.23747 acc: 0.98667 val_loss: 0.23515, val_acc: 0.96000\n",
      "Epoch [2790/10000], loss: 0.23705 acc: 0.98667 val_loss: 0.23476, val_acc: 0.96000\n",
      "Epoch [2800/10000], loss: 0.23663 acc: 0.98667 val_loss: 0.23438, val_acc: 0.96000\n",
      "Epoch [2810/10000], loss: 0.23622 acc: 0.98667 val_loss: 0.23400, val_acc: 0.96000\n",
      "Epoch [2820/10000], loss: 0.23580 acc: 0.98667 val_loss: 0.23363, val_acc: 0.96000\n",
      "Epoch [2830/10000], loss: 0.23539 acc: 0.98667 val_loss: 0.23325, val_acc: 0.96000\n",
      "Epoch [2840/10000], loss: 0.23498 acc: 0.98667 val_loss: 0.23288, val_acc: 0.96000\n",
      "Epoch [2850/10000], loss: 0.23458 acc: 0.98667 val_loss: 0.23250, val_acc: 0.96000\n",
      "Epoch [2860/10000], loss: 0.23417 acc: 0.98667 val_loss: 0.23213, val_acc: 0.96000\n",
      "Epoch [2870/10000], loss: 0.23377 acc: 0.98667 val_loss: 0.23176, val_acc: 0.96000\n",
      "Epoch [2880/10000], loss: 0.23337 acc: 0.98667 val_loss: 0.23140, val_acc: 0.96000\n",
      "Epoch [2890/10000], loss: 0.23297 acc: 0.98667 val_loss: 0.23103, val_acc: 0.96000\n",
      "Epoch [2900/10000], loss: 0.23257 acc: 0.98667 val_loss: 0.23067, val_acc: 0.96000\n",
      "Epoch [2910/10000], loss: 0.23218 acc: 0.98667 val_loss: 0.23031, val_acc: 0.96000\n",
      "Epoch [2920/10000], loss: 0.23178 acc: 0.98667 val_loss: 0.22995, val_acc: 0.96000\n",
      "Epoch [2930/10000], loss: 0.23139 acc: 0.98667 val_loss: 0.22959, val_acc: 0.96000\n",
      "Epoch [2940/10000], loss: 0.23100 acc: 0.98667 val_loss: 0.22923, val_acc: 0.96000\n",
      "Epoch [2950/10000], loss: 0.23061 acc: 0.98667 val_loss: 0.22888, val_acc: 0.96000\n",
      "Epoch [2960/10000], loss: 0.23023 acc: 0.98667 val_loss: 0.22853, val_acc: 0.96000\n",
      "Epoch [2970/10000], loss: 0.22984 acc: 0.98667 val_loss: 0.22818, val_acc: 0.96000\n",
      "Epoch [2980/10000], loss: 0.22946 acc: 0.98667 val_loss: 0.22783, val_acc: 0.96000\n",
      "Epoch [2990/10000], loss: 0.22908 acc: 0.98667 val_loss: 0.22748, val_acc: 0.96000\n",
      "Epoch [3000/10000], loss: 0.22870 acc: 0.98667 val_loss: 0.22713, val_acc: 0.96000\n",
      "Epoch [3010/10000], loss: 0.22832 acc: 0.98667 val_loss: 0.22679, val_acc: 0.96000\n",
      "Epoch [3020/10000], loss: 0.22795 acc: 0.98667 val_loss: 0.22645, val_acc: 0.96000\n",
      "Epoch [3030/10000], loss: 0.22757 acc: 0.98667 val_loss: 0.22610, val_acc: 0.96000\n",
      "Epoch [3040/10000], loss: 0.22720 acc: 0.98667 val_loss: 0.22577, val_acc: 0.96000\n",
      "Epoch [3050/10000], loss: 0.22683 acc: 0.98667 val_loss: 0.22543, val_acc: 0.96000\n",
      "Epoch [3060/10000], loss: 0.22646 acc: 0.98667 val_loss: 0.22509, val_acc: 0.96000\n",
      "Epoch [3070/10000], loss: 0.22610 acc: 0.98667 val_loss: 0.22476, val_acc: 0.96000\n",
      "Epoch [3080/10000], loss: 0.22573 acc: 0.98667 val_loss: 0.22442, val_acc: 0.96000\n",
      "Epoch [3090/10000], loss: 0.22537 acc: 0.98667 val_loss: 0.22409, val_acc: 0.96000\n",
      "Epoch [3100/10000], loss: 0.22501 acc: 0.98667 val_loss: 0.22376, val_acc: 0.96000\n",
      "Epoch [3110/10000], loss: 0.22465 acc: 0.98667 val_loss: 0.22343, val_acc: 0.96000\n",
      "Epoch [3120/10000], loss: 0.22429 acc: 0.98667 val_loss: 0.22311, val_acc: 0.96000\n",
      "Epoch [3130/10000], loss: 0.22393 acc: 0.98667 val_loss: 0.22278, val_acc: 0.96000\n",
      "Epoch [3140/10000], loss: 0.22357 acc: 0.98667 val_loss: 0.22246, val_acc: 0.96000\n",
      "Epoch [3150/10000], loss: 0.22322 acc: 0.98667 val_loss: 0.22214, val_acc: 0.96000\n",
      "Epoch [3160/10000], loss: 0.22287 acc: 0.98667 val_loss: 0.22181, val_acc: 0.96000\n",
      "Epoch [3170/10000], loss: 0.22252 acc: 0.98667 val_loss: 0.22150, val_acc: 0.96000\n",
      "Epoch [3180/10000], loss: 0.22217 acc: 0.98667 val_loss: 0.22118, val_acc: 0.96000\n",
      "Epoch [3190/10000], loss: 0.22182 acc: 0.98667 val_loss: 0.22086, val_acc: 0.96000\n",
      "Epoch [3200/10000], loss: 0.22148 acc: 0.98667 val_loss: 0.22055, val_acc: 0.96000\n",
      "Epoch [3210/10000], loss: 0.22113 acc: 0.98667 val_loss: 0.22023, val_acc: 0.96000\n",
      "Epoch [3220/10000], loss: 0.22079 acc: 0.98667 val_loss: 0.21992, val_acc: 0.96000\n",
      "Epoch [3230/10000], loss: 0.22045 acc: 0.98667 val_loss: 0.21961, val_acc: 0.96000\n",
      "Epoch [3240/10000], loss: 0.22011 acc: 0.98667 val_loss: 0.21930, val_acc: 0.96000\n",
      "Epoch [3250/10000], loss: 0.21977 acc: 0.98667 val_loss: 0.21899, val_acc: 0.96000\n",
      "Epoch [3260/10000], loss: 0.21943 acc: 0.98667 val_loss: 0.21869, val_acc: 0.96000\n",
      "Epoch [3270/10000], loss: 0.21910 acc: 0.98667 val_loss: 0.21838, val_acc: 0.96000\n",
      "Epoch [3280/10000], loss: 0.21876 acc: 0.98667 val_loss: 0.21808, val_acc: 0.96000\n",
      "Epoch [3290/10000], loss: 0.21843 acc: 0.98667 val_loss: 0.21778, val_acc: 0.96000\n",
      "Epoch [3300/10000], loss: 0.21810 acc: 0.98667 val_loss: 0.21747, val_acc: 0.96000\n",
      "Epoch [3310/10000], loss: 0.21777 acc: 0.98667 val_loss: 0.21717, val_acc: 0.96000\n",
      "Epoch [3320/10000], loss: 0.21744 acc: 0.98667 val_loss: 0.21688, val_acc: 0.96000\n",
      "Epoch [3330/10000], loss: 0.21711 acc: 0.98667 val_loss: 0.21658, val_acc: 0.96000\n",
      "Epoch [3340/10000], loss: 0.21679 acc: 0.98667 val_loss: 0.21628, val_acc: 0.96000\n",
      "Epoch [3350/10000], loss: 0.21646 acc: 0.98667 val_loss: 0.21599, val_acc: 0.96000\n",
      "Epoch [3360/10000], loss: 0.21614 acc: 0.98667 val_loss: 0.21570, val_acc: 0.96000\n",
      "Epoch [3370/10000], loss: 0.21582 acc: 0.98667 val_loss: 0.21540, val_acc: 0.96000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3380/10000], loss: 0.21550 acc: 0.98667 val_loss: 0.21511, val_acc: 0.96000\n",
      "Epoch [3390/10000], loss: 0.21518 acc: 0.98667 val_loss: 0.21483, val_acc: 0.96000\n",
      "Epoch [3400/10000], loss: 0.21487 acc: 0.98667 val_loss: 0.21454, val_acc: 0.96000\n",
      "Epoch [3410/10000], loss: 0.21455 acc: 0.98667 val_loss: 0.21425, val_acc: 0.96000\n",
      "Epoch [3420/10000], loss: 0.21424 acc: 0.98667 val_loss: 0.21397, val_acc: 0.96000\n",
      "Epoch [3430/10000], loss: 0.21392 acc: 0.98667 val_loss: 0.21368, val_acc: 0.96000\n",
      "Epoch [3440/10000], loss: 0.21361 acc: 0.98667 val_loss: 0.21340, val_acc: 0.96000\n",
      "Epoch [3450/10000], loss: 0.21330 acc: 0.98667 val_loss: 0.21312, val_acc: 0.96000\n",
      "Epoch [3460/10000], loss: 0.21299 acc: 0.98667 val_loss: 0.21284, val_acc: 0.96000\n",
      "Epoch [3470/10000], loss: 0.21268 acc: 0.98667 val_loss: 0.21256, val_acc: 0.96000\n",
      "Epoch [3480/10000], loss: 0.21238 acc: 0.98667 val_loss: 0.21228, val_acc: 0.96000\n",
      "Epoch [3490/10000], loss: 0.21207 acc: 0.98667 val_loss: 0.21200, val_acc: 0.96000\n",
      "Epoch [3500/10000], loss: 0.21177 acc: 0.98667 val_loss: 0.21173, val_acc: 0.96000\n",
      "Epoch [3510/10000], loss: 0.21146 acc: 0.98667 val_loss: 0.21145, val_acc: 0.96000\n",
      "Epoch [3520/10000], loss: 0.21116 acc: 0.98667 val_loss: 0.21118, val_acc: 0.96000\n",
      "Epoch [3530/10000], loss: 0.21086 acc: 0.98667 val_loss: 0.21091, val_acc: 0.96000\n",
      "Epoch [3540/10000], loss: 0.21056 acc: 0.98667 val_loss: 0.21064, val_acc: 0.96000\n",
      "Epoch [3550/10000], loss: 0.21026 acc: 0.98667 val_loss: 0.21037, val_acc: 0.96000\n",
      "Epoch [3560/10000], loss: 0.20997 acc: 0.98667 val_loss: 0.21010, val_acc: 0.96000\n",
      "Epoch [3570/10000], loss: 0.20967 acc: 0.98667 val_loss: 0.20983, val_acc: 0.96000\n",
      "Epoch [3580/10000], loss: 0.20938 acc: 0.98667 val_loss: 0.20956, val_acc: 0.96000\n",
      "Epoch [3590/10000], loss: 0.20909 acc: 0.98667 val_loss: 0.20930, val_acc: 0.96000\n",
      "Epoch [3600/10000], loss: 0.20879 acc: 0.98667 val_loss: 0.20903, val_acc: 0.96000\n",
      "Epoch [3610/10000], loss: 0.20850 acc: 0.98667 val_loss: 0.20877, val_acc: 0.96000\n",
      "Epoch [3620/10000], loss: 0.20821 acc: 0.98667 val_loss: 0.20851, val_acc: 0.96000\n",
      "Epoch [3630/10000], loss: 0.20793 acc: 0.98667 val_loss: 0.20825, val_acc: 0.96000\n",
      "Epoch [3640/10000], loss: 0.20764 acc: 0.98667 val_loss: 0.20799, val_acc: 0.96000\n",
      "Epoch [3650/10000], loss: 0.20735 acc: 0.98667 val_loss: 0.20773, val_acc: 0.96000\n",
      "Epoch [3660/10000], loss: 0.20707 acc: 0.98667 val_loss: 0.20747, val_acc: 0.96000\n",
      "Epoch [3670/10000], loss: 0.20678 acc: 0.98667 val_loss: 0.20721, val_acc: 0.96000\n",
      "Epoch [3680/10000], loss: 0.20650 acc: 0.98667 val_loss: 0.20696, val_acc: 0.96000\n",
      "Epoch [3690/10000], loss: 0.20622 acc: 0.98667 val_loss: 0.20670, val_acc: 0.96000\n",
      "Epoch [3700/10000], loss: 0.20594 acc: 0.98667 val_loss: 0.20645, val_acc: 0.96000\n",
      "Epoch [3710/10000], loss: 0.20566 acc: 0.98667 val_loss: 0.20620, val_acc: 0.96000\n",
      "Epoch [3720/10000], loss: 0.20538 acc: 0.98667 val_loss: 0.20595, val_acc: 0.96000\n",
      "Epoch [3730/10000], loss: 0.20511 acc: 0.98667 val_loss: 0.20570, val_acc: 0.96000\n",
      "Epoch [3740/10000], loss: 0.20483 acc: 0.98667 val_loss: 0.20545, val_acc: 0.96000\n",
      "Epoch [3750/10000], loss: 0.20455 acc: 0.98667 val_loss: 0.20520, val_acc: 0.96000\n",
      "Epoch [3760/10000], loss: 0.20428 acc: 0.98667 val_loss: 0.20495, val_acc: 0.96000\n",
      "Epoch [3770/10000], loss: 0.20401 acc: 0.98667 val_loss: 0.20471, val_acc: 0.96000\n",
      "Epoch [3780/10000], loss: 0.20374 acc: 0.98667 val_loss: 0.20446, val_acc: 0.96000\n",
      "Epoch [3790/10000], loss: 0.20347 acc: 0.98667 val_loss: 0.20422, val_acc: 0.96000\n",
      "Epoch [3800/10000], loss: 0.20320 acc: 0.98667 val_loss: 0.20397, val_acc: 0.96000\n",
      "Epoch [3810/10000], loss: 0.20293 acc: 0.98667 val_loss: 0.20373, val_acc: 0.96000\n",
      "Epoch [3820/10000], loss: 0.20266 acc: 0.98667 val_loss: 0.20349, val_acc: 0.96000\n",
      "Epoch [3830/10000], loss: 0.20239 acc: 0.98667 val_loss: 0.20325, val_acc: 0.96000\n",
      "Epoch [3840/10000], loss: 0.20213 acc: 0.98667 val_loss: 0.20301, val_acc: 0.96000\n",
      "Epoch [3850/10000], loss: 0.20186 acc: 0.98667 val_loss: 0.20277, val_acc: 0.96000\n",
      "Epoch [3860/10000], loss: 0.20160 acc: 0.98667 val_loss: 0.20253, val_acc: 0.96000\n",
      "Epoch [3870/10000], loss: 0.20134 acc: 0.98667 val_loss: 0.20230, val_acc: 0.96000\n",
      "Epoch [3880/10000], loss: 0.20108 acc: 0.98667 val_loss: 0.20206, val_acc: 0.96000\n",
      "Epoch [3890/10000], loss: 0.20082 acc: 0.98667 val_loss: 0.20183, val_acc: 0.96000\n",
      "Epoch [3900/10000], loss: 0.20056 acc: 0.98667 val_loss: 0.20159, val_acc: 0.96000\n",
      "Epoch [3910/10000], loss: 0.20030 acc: 0.98667 val_loss: 0.20136, val_acc: 0.96000\n",
      "Epoch [3920/10000], loss: 0.20004 acc: 0.98667 val_loss: 0.20113, val_acc: 0.96000\n",
      "Epoch [3930/10000], loss: 0.19979 acc: 0.98667 val_loss: 0.20090, val_acc: 0.96000\n",
      "Epoch [3940/10000], loss: 0.19953 acc: 0.98667 val_loss: 0.20067, val_acc: 0.96000\n",
      "Epoch [3950/10000], loss: 0.19928 acc: 0.98667 val_loss: 0.20044, val_acc: 0.96000\n",
      "Epoch [3960/10000], loss: 0.19902 acc: 0.98667 val_loss: 0.20021, val_acc: 0.96000\n",
      "Epoch [3970/10000], loss: 0.19877 acc: 0.98667 val_loss: 0.19998, val_acc: 0.96000\n",
      "Epoch [3980/10000], loss: 0.19852 acc: 0.98667 val_loss: 0.19976, val_acc: 0.96000\n",
      "Epoch [3990/10000], loss: 0.19827 acc: 0.98667 val_loss: 0.19953, val_acc: 0.96000\n",
      "Epoch [4000/10000], loss: 0.19802 acc: 0.98667 val_loss: 0.19931, val_acc: 0.96000\n",
      "Epoch [4010/10000], loss: 0.19777 acc: 0.98667 val_loss: 0.19908, val_acc: 0.96000\n",
      "Epoch [4020/10000], loss: 0.19752 acc: 0.98667 val_loss: 0.19886, val_acc: 0.96000\n",
      "Epoch [4030/10000], loss: 0.19728 acc: 0.98667 val_loss: 0.19864, val_acc: 0.96000\n",
      "Epoch [4040/10000], loss: 0.19703 acc: 0.98667 val_loss: 0.19842, val_acc: 0.96000\n",
      "Epoch [4050/10000], loss: 0.19679 acc: 0.98667 val_loss: 0.19820, val_acc: 0.96000\n",
      "Epoch [4060/10000], loss: 0.19654 acc: 0.98667 val_loss: 0.19798, val_acc: 0.96000\n",
      "Epoch [4070/10000], loss: 0.19630 acc: 0.98667 val_loss: 0.19776, val_acc: 0.96000\n",
      "Epoch [4080/10000], loss: 0.19606 acc: 0.98667 val_loss: 0.19754, val_acc: 0.96000\n",
      "Epoch [4090/10000], loss: 0.19582 acc: 0.98667 val_loss: 0.19732, val_acc: 0.96000\n",
      "Epoch [4100/10000], loss: 0.19557 acc: 0.98667 val_loss: 0.19711, val_acc: 0.96000\n",
      "Epoch [4110/10000], loss: 0.19534 acc: 0.98667 val_loss: 0.19689, val_acc: 0.96000\n",
      "Epoch [4120/10000], loss: 0.19510 acc: 0.98667 val_loss: 0.19668, val_acc: 0.96000\n",
      "Epoch [4130/10000], loss: 0.19486 acc: 0.98667 val_loss: 0.19646, val_acc: 0.96000\n",
      "Epoch [4140/10000], loss: 0.19462 acc: 0.98667 val_loss: 0.19625, val_acc: 0.96000\n",
      "Epoch [4150/10000], loss: 0.19439 acc: 0.98667 val_loss: 0.19604, val_acc: 0.96000\n",
      "Epoch [4160/10000], loss: 0.19415 acc: 0.98667 val_loss: 0.19583, val_acc: 0.96000\n",
      "Epoch [4170/10000], loss: 0.19392 acc: 0.98667 val_loss: 0.19562, val_acc: 0.96000\n",
      "Epoch [4180/10000], loss: 0.19368 acc: 0.98667 val_loss: 0.19541, val_acc: 0.96000\n",
      "Epoch [4190/10000], loss: 0.19345 acc: 0.98667 val_loss: 0.19520, val_acc: 0.96000\n",
      "Epoch [4200/10000], loss: 0.19322 acc: 0.98667 val_loss: 0.19499, val_acc: 0.96000\n",
      "Epoch [4210/10000], loss: 0.19299 acc: 0.98667 val_loss: 0.19478, val_acc: 0.96000\n",
      "Epoch [4220/10000], loss: 0.19276 acc: 0.98667 val_loss: 0.19457, val_acc: 0.96000\n",
      "Epoch [4230/10000], loss: 0.19253 acc: 0.98667 val_loss: 0.19437, val_acc: 0.96000\n",
      "Epoch [4240/10000], loss: 0.19230 acc: 0.98667 val_loss: 0.19416, val_acc: 0.96000\n",
      "Epoch [4250/10000], loss: 0.19207 acc: 0.98667 val_loss: 0.19396, val_acc: 0.96000\n",
      "Epoch [4260/10000], loss: 0.19184 acc: 0.98667 val_loss: 0.19376, val_acc: 0.96000\n",
      "Epoch [4270/10000], loss: 0.19162 acc: 0.98667 val_loss: 0.19355, val_acc: 0.96000\n",
      "Epoch [4280/10000], loss: 0.19139 acc: 0.98667 val_loss: 0.19335, val_acc: 0.96000\n",
      "Epoch [4290/10000], loss: 0.19117 acc: 0.98667 val_loss: 0.19315, val_acc: 0.96000\n",
      "Epoch [4300/10000], loss: 0.19094 acc: 0.98667 val_loss: 0.19295, val_acc: 0.96000\n",
      "Epoch [4310/10000], loss: 0.19072 acc: 0.98667 val_loss: 0.19275, val_acc: 0.96000\n",
      "Epoch [4320/10000], loss: 0.19050 acc: 0.98667 val_loss: 0.19255, val_acc: 0.96000\n",
      "Epoch [4330/10000], loss: 0.19028 acc: 0.98667 val_loss: 0.19235, val_acc: 0.96000\n",
      "Epoch [4340/10000], loss: 0.19006 acc: 0.98667 val_loss: 0.19215, val_acc: 0.96000\n",
      "Epoch [4350/10000], loss: 0.18984 acc: 0.98667 val_loss: 0.19196, val_acc: 0.96000\n",
      "Epoch [4360/10000], loss: 0.18962 acc: 0.98667 val_loss: 0.19176, val_acc: 0.96000\n",
      "Epoch [4370/10000], loss: 0.18940 acc: 0.98667 val_loss: 0.19156, val_acc: 0.96000\n",
      "Epoch [4380/10000], loss: 0.18918 acc: 0.98667 val_loss: 0.19137, val_acc: 0.96000\n",
      "Epoch [4390/10000], loss: 0.18897 acc: 0.98667 val_loss: 0.19118, val_acc: 0.96000\n",
      "Epoch [4400/10000], loss: 0.18875 acc: 0.98667 val_loss: 0.19098, val_acc: 0.96000\n",
      "Epoch [4410/10000], loss: 0.18853 acc: 0.98667 val_loss: 0.19079, val_acc: 0.96000\n",
      "Epoch [4420/10000], loss: 0.18832 acc: 0.98667 val_loss: 0.19060, val_acc: 0.96000\n",
      "Epoch [4430/10000], loss: 0.18811 acc: 0.98667 val_loss: 0.19041, val_acc: 0.96000\n",
      "Epoch [4440/10000], loss: 0.18789 acc: 0.98667 val_loss: 0.19021, val_acc: 0.96000\n",
      "Epoch [4450/10000], loss: 0.18768 acc: 0.98667 val_loss: 0.19002, val_acc: 0.96000\n",
      "Epoch [4460/10000], loss: 0.18747 acc: 0.98667 val_loss: 0.18984, val_acc: 0.96000\n",
      "Epoch [4470/10000], loss: 0.18726 acc: 0.98667 val_loss: 0.18965, val_acc: 0.96000\n",
      "Epoch [4480/10000], loss: 0.18705 acc: 0.98667 val_loss: 0.18946, val_acc: 0.96000\n",
      "Epoch [4490/10000], loss: 0.18684 acc: 0.98667 val_loss: 0.18927, val_acc: 0.96000\n",
      "Epoch [4500/10000], loss: 0.18663 acc: 0.98667 val_loss: 0.18908, val_acc: 0.96000\n",
      "Epoch [4510/10000], loss: 0.18642 acc: 0.98667 val_loss: 0.18890, val_acc: 0.96000\n",
      "Epoch [4520/10000], loss: 0.18622 acc: 0.98667 val_loss: 0.18871, val_acc: 0.96000\n",
      "Epoch [4530/10000], loss: 0.18601 acc: 0.98667 val_loss: 0.18853, val_acc: 0.96000\n",
      "Epoch [4540/10000], loss: 0.18580 acc: 0.98667 val_loss: 0.18834, val_acc: 0.96000\n",
      "Epoch [4550/10000], loss: 0.18560 acc: 0.98667 val_loss: 0.18816, val_acc: 0.96000\n",
      "Epoch [4560/10000], loss: 0.18539 acc: 0.98667 val_loss: 0.18798, val_acc: 0.96000\n",
      "Epoch [4570/10000], loss: 0.18519 acc: 0.98667 val_loss: 0.18780, val_acc: 0.96000\n",
      "Epoch [4580/10000], loss: 0.18499 acc: 0.98667 val_loss: 0.18761, val_acc: 0.96000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4590/10000], loss: 0.18478 acc: 0.98667 val_loss: 0.18743, val_acc: 0.96000\n",
      "Epoch [4600/10000], loss: 0.18458 acc: 0.98667 val_loss: 0.18725, val_acc: 0.96000\n",
      "Epoch [4610/10000], loss: 0.18438 acc: 0.98667 val_loss: 0.18707, val_acc: 0.96000\n",
      "Epoch [4620/10000], loss: 0.18418 acc: 0.98667 val_loss: 0.18690, val_acc: 0.96000\n",
      "Epoch [4630/10000], loss: 0.18398 acc: 0.98667 val_loss: 0.18672, val_acc: 0.96000\n",
      "Epoch [4640/10000], loss: 0.18378 acc: 0.98667 val_loss: 0.18654, val_acc: 0.96000\n",
      "Epoch [4650/10000], loss: 0.18358 acc: 0.98667 val_loss: 0.18636, val_acc: 0.96000\n",
      "Epoch [4660/10000], loss: 0.18339 acc: 0.98667 val_loss: 0.18619, val_acc: 0.96000\n",
      "Epoch [4670/10000], loss: 0.18319 acc: 0.98667 val_loss: 0.18601, val_acc: 0.96000\n",
      "Epoch [4680/10000], loss: 0.18299 acc: 0.98667 val_loss: 0.18583, val_acc: 0.96000\n",
      "Epoch [4690/10000], loss: 0.18280 acc: 0.98667 val_loss: 0.18566, val_acc: 0.96000\n",
      "Epoch [4700/10000], loss: 0.18260 acc: 0.98667 val_loss: 0.18549, val_acc: 0.96000\n",
      "Epoch [4710/10000], loss: 0.18241 acc: 0.98667 val_loss: 0.18531, val_acc: 0.96000\n",
      "Epoch [4720/10000], loss: 0.18221 acc: 0.98667 val_loss: 0.18514, val_acc: 0.96000\n",
      "Epoch [4730/10000], loss: 0.18202 acc: 0.98667 val_loss: 0.18497, val_acc: 0.96000\n",
      "Epoch [4740/10000], loss: 0.18183 acc: 0.98667 val_loss: 0.18479, val_acc: 0.96000\n",
      "Epoch [4750/10000], loss: 0.18164 acc: 0.98667 val_loss: 0.18462, val_acc: 0.96000\n",
      "Epoch [4760/10000], loss: 0.18144 acc: 0.98667 val_loss: 0.18445, val_acc: 0.96000\n",
      "Epoch [4770/10000], loss: 0.18125 acc: 0.98667 val_loss: 0.18428, val_acc: 0.96000\n",
      "Epoch [4780/10000], loss: 0.18106 acc: 0.98667 val_loss: 0.18411, val_acc: 0.96000\n",
      "Epoch [4790/10000], loss: 0.18087 acc: 0.98667 val_loss: 0.18394, val_acc: 0.96000\n",
      "Epoch [4800/10000], loss: 0.18068 acc: 0.98667 val_loss: 0.18378, val_acc: 0.96000\n",
      "Epoch [4810/10000], loss: 0.18050 acc: 0.98667 val_loss: 0.18361, val_acc: 0.96000\n",
      "Epoch [4820/10000], loss: 0.18031 acc: 0.98667 val_loss: 0.18344, val_acc: 0.96000\n",
      "Epoch [4830/10000], loss: 0.18012 acc: 0.98667 val_loss: 0.18328, val_acc: 0.96000\n",
      "Epoch [4840/10000], loss: 0.17994 acc: 0.98667 val_loss: 0.18311, val_acc: 0.96000\n",
      "Epoch [4850/10000], loss: 0.17975 acc: 0.98667 val_loss: 0.18294, val_acc: 0.96000\n",
      "Epoch [4860/10000], loss: 0.17956 acc: 0.98667 val_loss: 0.18278, val_acc: 0.96000\n",
      "Epoch [4870/10000], loss: 0.17938 acc: 0.98667 val_loss: 0.18261, val_acc: 0.96000\n",
      "Epoch [4880/10000], loss: 0.17920 acc: 0.98667 val_loss: 0.18245, val_acc: 0.96000\n",
      "Epoch [4890/10000], loss: 0.17901 acc: 0.98667 val_loss: 0.18229, val_acc: 0.96000\n",
      "Epoch [4900/10000], loss: 0.17883 acc: 0.98667 val_loss: 0.18212, val_acc: 0.96000\n",
      "Epoch [4910/10000], loss: 0.17865 acc: 0.98667 val_loss: 0.18196, val_acc: 0.96000\n",
      "Epoch [4920/10000], loss: 0.17846 acc: 0.98667 val_loss: 0.18180, val_acc: 0.96000\n",
      "Epoch [4930/10000], loss: 0.17828 acc: 0.98667 val_loss: 0.18164, val_acc: 0.96000\n",
      "Epoch [4940/10000], loss: 0.17810 acc: 0.98667 val_loss: 0.18148, val_acc: 0.96000\n",
      "Epoch [4950/10000], loss: 0.17792 acc: 0.98667 val_loss: 0.18132, val_acc: 0.96000\n",
      "Epoch [4960/10000], loss: 0.17774 acc: 0.98667 val_loss: 0.18116, val_acc: 0.96000\n",
      "Epoch [4970/10000], loss: 0.17756 acc: 0.98667 val_loss: 0.18100, val_acc: 0.96000\n",
      "Epoch [4980/10000], loss: 0.17739 acc: 0.98667 val_loss: 0.18084, val_acc: 0.96000\n",
      "Epoch [4990/10000], loss: 0.17721 acc: 0.98667 val_loss: 0.18068, val_acc: 0.96000\n",
      "Epoch [5000/10000], loss: 0.17703 acc: 0.98667 val_loss: 0.18053, val_acc: 0.96000\n",
      "Epoch [5010/10000], loss: 0.17685 acc: 0.98667 val_loss: 0.18037, val_acc: 0.96000\n",
      "Epoch [5020/10000], loss: 0.17668 acc: 0.98667 val_loss: 0.18021, val_acc: 0.96000\n",
      "Epoch [5030/10000], loss: 0.17650 acc: 0.98667 val_loss: 0.18006, val_acc: 0.96000\n",
      "Epoch [5040/10000], loss: 0.17633 acc: 0.98667 val_loss: 0.17990, val_acc: 0.96000\n",
      "Epoch [5050/10000], loss: 0.17615 acc: 0.98667 val_loss: 0.17975, val_acc: 0.96000\n",
      "Epoch [5060/10000], loss: 0.17598 acc: 0.98667 val_loss: 0.17959, val_acc: 0.96000\n",
      "Epoch [5070/10000], loss: 0.17581 acc: 0.98667 val_loss: 0.17944, val_acc: 0.96000\n",
      "Epoch [5080/10000], loss: 0.17563 acc: 0.98667 val_loss: 0.17928, val_acc: 0.96000\n",
      "Epoch [5090/10000], loss: 0.17546 acc: 0.98667 val_loss: 0.17913, val_acc: 0.96000\n",
      "Epoch [5100/10000], loss: 0.17529 acc: 0.98667 val_loss: 0.17898, val_acc: 0.96000\n",
      "Epoch [5110/10000], loss: 0.17512 acc: 0.98667 val_loss: 0.17883, val_acc: 0.96000\n",
      "Epoch [5120/10000], loss: 0.17495 acc: 0.98667 val_loss: 0.17867, val_acc: 0.96000\n",
      "Epoch [5130/10000], loss: 0.17478 acc: 0.98667 val_loss: 0.17852, val_acc: 0.96000\n",
      "Epoch [5140/10000], loss: 0.17461 acc: 0.98667 val_loss: 0.17837, val_acc: 0.96000\n",
      "Epoch [5150/10000], loss: 0.17444 acc: 0.98667 val_loss: 0.17822, val_acc: 0.96000\n",
      "Epoch [5160/10000], loss: 0.17427 acc: 0.98667 val_loss: 0.17807, val_acc: 0.96000\n",
      "Epoch [5170/10000], loss: 0.17410 acc: 0.98667 val_loss: 0.17792, val_acc: 0.96000\n",
      "Epoch [5180/10000], loss: 0.17393 acc: 0.98667 val_loss: 0.17778, val_acc: 0.96000\n",
      "Epoch [5190/10000], loss: 0.17377 acc: 0.98667 val_loss: 0.17763, val_acc: 0.96000\n",
      "Epoch [5200/10000], loss: 0.17360 acc: 0.98667 val_loss: 0.17748, val_acc: 0.96000\n",
      "Epoch [5210/10000], loss: 0.17343 acc: 0.98667 val_loss: 0.17733, val_acc: 0.96000\n",
      "Epoch [5220/10000], loss: 0.17327 acc: 0.98667 val_loss: 0.17719, val_acc: 0.96000\n",
      "Epoch [5230/10000], loss: 0.17310 acc: 0.98667 val_loss: 0.17704, val_acc: 0.96000\n",
      "Epoch [5240/10000], loss: 0.17294 acc: 0.98667 val_loss: 0.17689, val_acc: 0.96000\n",
      "Epoch [5250/10000], loss: 0.17277 acc: 0.98667 val_loss: 0.17675, val_acc: 0.96000\n",
      "Epoch [5260/10000], loss: 0.17261 acc: 0.98667 val_loss: 0.17660, val_acc: 0.96000\n",
      "Epoch [5270/10000], loss: 0.17245 acc: 0.98667 val_loss: 0.17646, val_acc: 0.96000\n",
      "Epoch [5280/10000], loss: 0.17229 acc: 0.98667 val_loss: 0.17631, val_acc: 0.96000\n",
      "Epoch [5290/10000], loss: 0.17212 acc: 0.98667 val_loss: 0.17617, val_acc: 0.96000\n",
      "Epoch [5300/10000], loss: 0.17196 acc: 0.98667 val_loss: 0.17603, val_acc: 0.96000\n",
      "Epoch [5310/10000], loss: 0.17180 acc: 0.98667 val_loss: 0.17589, val_acc: 0.96000\n",
      "Epoch [5320/10000], loss: 0.17164 acc: 0.98667 val_loss: 0.17574, val_acc: 0.96000\n",
      "Epoch [5330/10000], loss: 0.17148 acc: 0.98667 val_loss: 0.17560, val_acc: 0.96000\n",
      "Epoch [5340/10000], loss: 0.17132 acc: 0.98667 val_loss: 0.17546, val_acc: 0.96000\n",
      "Epoch [5350/10000], loss: 0.17116 acc: 0.98667 val_loss: 0.17532, val_acc: 0.96000\n",
      "Epoch [5360/10000], loss: 0.17100 acc: 0.98667 val_loss: 0.17518, val_acc: 0.96000\n",
      "Epoch [5370/10000], loss: 0.17084 acc: 0.98667 val_loss: 0.17504, val_acc: 0.96000\n",
      "Epoch [5380/10000], loss: 0.17068 acc: 0.98667 val_loss: 0.17490, val_acc: 0.96000\n",
      "Epoch [5390/10000], loss: 0.17053 acc: 0.98667 val_loss: 0.17476, val_acc: 0.96000\n",
      "Epoch [5400/10000], loss: 0.17037 acc: 0.98667 val_loss: 0.17462, val_acc: 0.96000\n",
      "Epoch [5410/10000], loss: 0.17021 acc: 0.98667 val_loss: 0.17448, val_acc: 0.96000\n",
      "Epoch [5420/10000], loss: 0.17006 acc: 0.98667 val_loss: 0.17434, val_acc: 0.96000\n",
      "Epoch [5430/10000], loss: 0.16990 acc: 0.98667 val_loss: 0.17421, val_acc: 0.96000\n",
      "Epoch [5440/10000], loss: 0.16975 acc: 0.98667 val_loss: 0.17407, val_acc: 0.96000\n",
      "Epoch [5450/10000], loss: 0.16959 acc: 0.98667 val_loss: 0.17393, val_acc: 0.96000\n",
      "Epoch [5460/10000], loss: 0.16944 acc: 0.98667 val_loss: 0.17380, val_acc: 0.96000\n",
      "Epoch [5470/10000], loss: 0.16928 acc: 0.98667 val_loss: 0.17366, val_acc: 0.96000\n",
      "Epoch [5480/10000], loss: 0.16913 acc: 0.98667 val_loss: 0.17352, val_acc: 0.96000\n",
      "Epoch [5490/10000], loss: 0.16898 acc: 0.98667 val_loss: 0.17339, val_acc: 0.96000\n",
      "Epoch [5500/10000], loss: 0.16883 acc: 0.98667 val_loss: 0.17325, val_acc: 0.96000\n",
      "Epoch [5510/10000], loss: 0.16867 acc: 0.98667 val_loss: 0.17312, val_acc: 0.96000\n",
      "Epoch [5520/10000], loss: 0.16852 acc: 0.98667 val_loss: 0.17299, val_acc: 0.96000\n",
      "Epoch [5530/10000], loss: 0.16837 acc: 0.98667 val_loss: 0.17285, val_acc: 0.96000\n",
      "Epoch [5540/10000], loss: 0.16822 acc: 0.98667 val_loss: 0.17272, val_acc: 0.96000\n",
      "Epoch [5550/10000], loss: 0.16807 acc: 0.98667 val_loss: 0.17259, val_acc: 0.96000\n",
      "Epoch [5560/10000], loss: 0.16792 acc: 0.98667 val_loss: 0.17246, val_acc: 0.96000\n",
      "Epoch [5570/10000], loss: 0.16777 acc: 0.98667 val_loss: 0.17232, val_acc: 0.96000\n",
      "Epoch [5580/10000], loss: 0.16762 acc: 0.98667 val_loss: 0.17219, val_acc: 0.96000\n",
      "Epoch [5590/10000], loss: 0.16747 acc: 0.98667 val_loss: 0.17206, val_acc: 0.96000\n",
      "Epoch [5600/10000], loss: 0.16732 acc: 0.98667 val_loss: 0.17193, val_acc: 0.96000\n",
      "Epoch [5610/10000], loss: 0.16718 acc: 0.98667 val_loss: 0.17180, val_acc: 0.96000\n",
      "Epoch [5620/10000], loss: 0.16703 acc: 0.98667 val_loss: 0.17167, val_acc: 0.96000\n",
      "Epoch [5630/10000], loss: 0.16688 acc: 0.98667 val_loss: 0.17154, val_acc: 0.96000\n",
      "Epoch [5640/10000], loss: 0.16674 acc: 0.98667 val_loss: 0.17141, val_acc: 0.96000\n",
      "Epoch [5650/10000], loss: 0.16659 acc: 0.98667 val_loss: 0.17128, val_acc: 0.96000\n",
      "Epoch [5660/10000], loss: 0.16644 acc: 0.98667 val_loss: 0.17115, val_acc: 0.96000\n",
      "Epoch [5670/10000], loss: 0.16630 acc: 0.98667 val_loss: 0.17103, val_acc: 0.96000\n",
      "Epoch [5680/10000], loss: 0.16615 acc: 0.98667 val_loss: 0.17090, val_acc: 0.96000\n",
      "Epoch [5690/10000], loss: 0.16601 acc: 0.98667 val_loss: 0.17077, val_acc: 0.96000\n",
      "Epoch [5700/10000], loss: 0.16587 acc: 0.98667 val_loss: 0.17064, val_acc: 0.96000\n",
      "Epoch [5710/10000], loss: 0.16572 acc: 0.98667 val_loss: 0.17052, val_acc: 0.96000\n",
      "Epoch [5720/10000], loss: 0.16558 acc: 0.98667 val_loss: 0.17039, val_acc: 0.96000\n",
      "Epoch [5730/10000], loss: 0.16544 acc: 0.98667 val_loss: 0.17027, val_acc: 0.96000\n",
      "Epoch [5740/10000], loss: 0.16529 acc: 0.98667 val_loss: 0.17014, val_acc: 0.96000\n",
      "Epoch [5750/10000], loss: 0.16515 acc: 0.98667 val_loss: 0.17001, val_acc: 0.96000\n",
      "Epoch [5760/10000], loss: 0.16501 acc: 0.98667 val_loss: 0.16989, val_acc: 0.96000\n",
      "Epoch [5770/10000], loss: 0.16487 acc: 0.98667 val_loss: 0.16977, val_acc: 0.96000\n",
      "Epoch [5780/10000], loss: 0.16473 acc: 0.98667 val_loss: 0.16964, val_acc: 0.96000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5790/10000], loss: 0.16459 acc: 0.98667 val_loss: 0.16952, val_acc: 0.96000\n",
      "Epoch [5800/10000], loss: 0.16445 acc: 0.98667 val_loss: 0.16940, val_acc: 0.96000\n",
      "Epoch [5810/10000], loss: 0.16431 acc: 0.98667 val_loss: 0.16927, val_acc: 0.96000\n",
      "Epoch [5820/10000], loss: 0.16417 acc: 0.98667 val_loss: 0.16915, val_acc: 0.96000\n",
      "Epoch [5830/10000], loss: 0.16403 acc: 0.98667 val_loss: 0.16903, val_acc: 0.96000\n",
      "Epoch [5840/10000], loss: 0.16389 acc: 0.98667 val_loss: 0.16891, val_acc: 0.96000\n",
      "Epoch [5850/10000], loss: 0.16375 acc: 0.98667 val_loss: 0.16878, val_acc: 0.96000\n",
      "Epoch [5860/10000], loss: 0.16361 acc: 0.98667 val_loss: 0.16866, val_acc: 0.96000\n",
      "Epoch [5870/10000], loss: 0.16348 acc: 0.98667 val_loss: 0.16854, val_acc: 0.96000\n",
      "Epoch [5880/10000], loss: 0.16334 acc: 0.98667 val_loss: 0.16842, val_acc: 0.96000\n",
      "Epoch [5890/10000], loss: 0.16320 acc: 0.98667 val_loss: 0.16830, val_acc: 0.96000\n",
      "Epoch [5900/10000], loss: 0.16307 acc: 0.98667 val_loss: 0.16818, val_acc: 0.96000\n",
      "Epoch [5910/10000], loss: 0.16293 acc: 0.98667 val_loss: 0.16806, val_acc: 0.96000\n",
      "Epoch [5920/10000], loss: 0.16280 acc: 0.98667 val_loss: 0.16794, val_acc: 0.96000\n",
      "Epoch [5930/10000], loss: 0.16266 acc: 0.98667 val_loss: 0.16782, val_acc: 0.96000\n",
      "Epoch [5940/10000], loss: 0.16253 acc: 0.98667 val_loss: 0.16771, val_acc: 0.96000\n",
      "Epoch [5950/10000], loss: 0.16239 acc: 0.98667 val_loss: 0.16759, val_acc: 0.96000\n",
      "Epoch [5960/10000], loss: 0.16226 acc: 0.98667 val_loss: 0.16747, val_acc: 0.96000\n",
      "Epoch [5970/10000], loss: 0.16212 acc: 0.98667 val_loss: 0.16735, val_acc: 0.96000\n",
      "Epoch [5980/10000], loss: 0.16199 acc: 0.98667 val_loss: 0.16724, val_acc: 0.96000\n",
      "Epoch [5990/10000], loss: 0.16186 acc: 0.98667 val_loss: 0.16712, val_acc: 0.96000\n",
      "Epoch [6000/10000], loss: 0.16172 acc: 0.98667 val_loss: 0.16700, val_acc: 0.96000\n",
      "Epoch [6010/10000], loss: 0.16159 acc: 0.98667 val_loss: 0.16689, val_acc: 0.96000\n",
      "Epoch [6020/10000], loss: 0.16146 acc: 0.98667 val_loss: 0.16677, val_acc: 0.96000\n",
      "Epoch [6030/10000], loss: 0.16133 acc: 0.98667 val_loss: 0.16665, val_acc: 0.96000\n",
      "Epoch [6040/10000], loss: 0.16120 acc: 0.98667 val_loss: 0.16654, val_acc: 0.96000\n",
      "Epoch [6050/10000], loss: 0.16107 acc: 0.98667 val_loss: 0.16642, val_acc: 0.96000\n",
      "Epoch [6060/10000], loss: 0.16094 acc: 0.98667 val_loss: 0.16631, val_acc: 0.96000\n",
      "Epoch [6070/10000], loss: 0.16080 acc: 0.98667 val_loss: 0.16620, val_acc: 0.96000\n",
      "Epoch [6080/10000], loss: 0.16067 acc: 0.98667 val_loss: 0.16608, val_acc: 0.96000\n",
      "Epoch [6090/10000], loss: 0.16055 acc: 0.98667 val_loss: 0.16597, val_acc: 0.96000\n",
      "Epoch [6100/10000], loss: 0.16042 acc: 0.98667 val_loss: 0.16585, val_acc: 0.96000\n",
      "Epoch [6110/10000], loss: 0.16029 acc: 0.98667 val_loss: 0.16574, val_acc: 0.96000\n",
      "Epoch [6120/10000], loss: 0.16016 acc: 0.98667 val_loss: 0.16563, val_acc: 0.96000\n",
      "Epoch [6130/10000], loss: 0.16003 acc: 0.98667 val_loss: 0.16552, val_acc: 0.96000\n",
      "Epoch [6140/10000], loss: 0.15990 acc: 0.98667 val_loss: 0.16540, val_acc: 0.96000\n",
      "Epoch [6150/10000], loss: 0.15978 acc: 0.98667 val_loss: 0.16529, val_acc: 0.96000\n",
      "Epoch [6160/10000], loss: 0.15965 acc: 0.98667 val_loss: 0.16518, val_acc: 0.96000\n",
      "Epoch [6170/10000], loss: 0.15952 acc: 0.98667 val_loss: 0.16507, val_acc: 0.96000\n",
      "Epoch [6180/10000], loss: 0.15939 acc: 0.98667 val_loss: 0.16496, val_acc: 0.96000\n",
      "Epoch [6190/10000], loss: 0.15927 acc: 0.98667 val_loss: 0.16485, val_acc: 0.96000\n",
      "Epoch [6200/10000], loss: 0.15914 acc: 0.98667 val_loss: 0.16474, val_acc: 0.96000\n",
      "Epoch [6210/10000], loss: 0.15902 acc: 0.98667 val_loss: 0.16463, val_acc: 0.96000\n",
      "Epoch [6220/10000], loss: 0.15889 acc: 0.98667 val_loss: 0.16452, val_acc: 0.96000\n",
      "Epoch [6230/10000], loss: 0.15877 acc: 0.98667 val_loss: 0.16441, val_acc: 0.96000\n",
      "Epoch [6240/10000], loss: 0.15864 acc: 0.98667 val_loss: 0.16430, val_acc: 0.96000\n",
      "Epoch [6250/10000], loss: 0.15852 acc: 0.98667 val_loss: 0.16419, val_acc: 0.96000\n",
      "Epoch [6260/10000], loss: 0.15839 acc: 0.98667 val_loss: 0.16408, val_acc: 0.96000\n",
      "Epoch [6270/10000], loss: 0.15827 acc: 0.98667 val_loss: 0.16398, val_acc: 0.96000\n",
      "Epoch [6280/10000], loss: 0.15815 acc: 0.98667 val_loss: 0.16387, val_acc: 0.96000\n",
      "Epoch [6290/10000], loss: 0.15802 acc: 0.98667 val_loss: 0.16376, val_acc: 0.96000\n",
      "Epoch [6300/10000], loss: 0.15790 acc: 0.98667 val_loss: 0.16365, val_acc: 0.96000\n",
      "Epoch [6310/10000], loss: 0.15778 acc: 0.98667 val_loss: 0.16355, val_acc: 0.96000\n",
      "Epoch [6320/10000], loss: 0.15766 acc: 0.98667 val_loss: 0.16344, val_acc: 0.96000\n",
      "Epoch [6330/10000], loss: 0.15754 acc: 0.98667 val_loss: 0.16333, val_acc: 0.96000\n",
      "Epoch [6340/10000], loss: 0.15741 acc: 0.98667 val_loss: 0.16323, val_acc: 0.96000\n",
      "Epoch [6350/10000], loss: 0.15729 acc: 0.98667 val_loss: 0.16312, val_acc: 0.96000\n",
      "Epoch [6360/10000], loss: 0.15717 acc: 0.98667 val_loss: 0.16302, val_acc: 0.96000\n",
      "Epoch [6370/10000], loss: 0.15705 acc: 0.98667 val_loss: 0.16291, val_acc: 0.96000\n",
      "Epoch [6380/10000], loss: 0.15693 acc: 0.98667 val_loss: 0.16281, val_acc: 0.96000\n",
      "Epoch [6390/10000], loss: 0.15681 acc: 0.98667 val_loss: 0.16270, val_acc: 0.96000\n",
      "Epoch [6400/10000], loss: 0.15669 acc: 0.98667 val_loss: 0.16260, val_acc: 0.96000\n",
      "Epoch [6410/10000], loss: 0.15657 acc: 0.98667 val_loss: 0.16249, val_acc: 0.96000\n",
      "Epoch [6420/10000], loss: 0.15645 acc: 0.98667 val_loss: 0.16239, val_acc: 0.96000\n",
      "Epoch [6430/10000], loss: 0.15634 acc: 0.98667 val_loss: 0.16228, val_acc: 0.96000\n",
      "Epoch [6440/10000], loss: 0.15622 acc: 0.98667 val_loss: 0.16218, val_acc: 0.96000\n",
      "Epoch [6450/10000], loss: 0.15610 acc: 0.98667 val_loss: 0.16208, val_acc: 0.96000\n",
      "Epoch [6460/10000], loss: 0.15598 acc: 0.98667 val_loss: 0.16198, val_acc: 0.96000\n",
      "Epoch [6470/10000], loss: 0.15586 acc: 0.98667 val_loss: 0.16187, val_acc: 0.96000\n",
      "Epoch [6480/10000], loss: 0.15575 acc: 0.98667 val_loss: 0.16177, val_acc: 0.96000\n",
      "Epoch [6490/10000], loss: 0.15563 acc: 0.98667 val_loss: 0.16167, val_acc: 0.96000\n",
      "Epoch [6500/10000], loss: 0.15551 acc: 0.98667 val_loss: 0.16157, val_acc: 0.96000\n",
      "Epoch [6510/10000], loss: 0.15540 acc: 0.98667 val_loss: 0.16147, val_acc: 0.96000\n",
      "Epoch [6520/10000], loss: 0.15528 acc: 0.98667 val_loss: 0.16136, val_acc: 0.96000\n",
      "Epoch [6530/10000], loss: 0.15516 acc: 0.98667 val_loss: 0.16126, val_acc: 0.96000\n",
      "Epoch [6540/10000], loss: 0.15505 acc: 0.98667 val_loss: 0.16116, val_acc: 0.96000\n",
      "Epoch [6550/10000], loss: 0.15493 acc: 0.98667 val_loss: 0.16106, val_acc: 0.96000\n",
      "Epoch [6560/10000], loss: 0.15482 acc: 0.98667 val_loss: 0.16096, val_acc: 0.96000\n",
      "Epoch [6570/10000], loss: 0.15470 acc: 0.98667 val_loss: 0.16086, val_acc: 0.96000\n",
      "Epoch [6580/10000], loss: 0.15459 acc: 0.98667 val_loss: 0.16076, val_acc: 0.96000\n",
      "Epoch [6590/10000], loss: 0.15448 acc: 0.98667 val_loss: 0.16066, val_acc: 0.96000\n",
      "Epoch [6600/10000], loss: 0.15436 acc: 0.98667 val_loss: 0.16056, val_acc: 0.96000\n",
      "Epoch [6610/10000], loss: 0.15425 acc: 0.98667 val_loss: 0.16047, val_acc: 0.96000\n",
      "Epoch [6620/10000], loss: 0.15414 acc: 0.98667 val_loss: 0.16037, val_acc: 0.96000\n",
      "Epoch [6630/10000], loss: 0.15402 acc: 0.98667 val_loss: 0.16027, val_acc: 0.96000\n",
      "Epoch [6640/10000], loss: 0.15391 acc: 0.98667 val_loss: 0.16017, val_acc: 0.96000\n",
      "Epoch [6650/10000], loss: 0.15380 acc: 0.98667 val_loss: 0.16007, val_acc: 0.96000\n",
      "Epoch [6660/10000], loss: 0.15369 acc: 0.98667 val_loss: 0.15998, val_acc: 0.96000\n",
      "Epoch [6670/10000], loss: 0.15357 acc: 0.98667 val_loss: 0.15988, val_acc: 0.96000\n",
      "Epoch [6680/10000], loss: 0.15346 acc: 0.98667 val_loss: 0.15978, val_acc: 0.96000\n",
      "Epoch [6690/10000], loss: 0.15335 acc: 0.98667 val_loss: 0.15968, val_acc: 0.96000\n",
      "Epoch [6700/10000], loss: 0.15324 acc: 0.98667 val_loss: 0.15959, val_acc: 0.96000\n",
      "Epoch [6710/10000], loss: 0.15313 acc: 0.98667 val_loss: 0.15949, val_acc: 0.96000\n",
      "Epoch [6720/10000], loss: 0.15302 acc: 0.98667 val_loss: 0.15939, val_acc: 0.96000\n",
      "Epoch [6730/10000], loss: 0.15291 acc: 0.98667 val_loss: 0.15930, val_acc: 0.96000\n",
      "Epoch [6740/10000], loss: 0.15280 acc: 0.98667 val_loss: 0.15920, val_acc: 0.96000\n",
      "Epoch [6750/10000], loss: 0.15269 acc: 0.98667 val_loss: 0.15911, val_acc: 0.96000\n",
      "Epoch [6760/10000], loss: 0.15258 acc: 0.98667 val_loss: 0.15901, val_acc: 0.96000\n",
      "Epoch [6770/10000], loss: 0.15247 acc: 0.98667 val_loss: 0.15892, val_acc: 0.96000\n",
      "Epoch [6780/10000], loss: 0.15236 acc: 0.98667 val_loss: 0.15882, val_acc: 0.96000\n",
      "Epoch [6790/10000], loss: 0.15225 acc: 0.98667 val_loss: 0.15873, val_acc: 0.96000\n",
      "Epoch [6800/10000], loss: 0.15215 acc: 0.98667 val_loss: 0.15863, val_acc: 0.96000\n",
      "Epoch [6810/10000], loss: 0.15204 acc: 0.98667 val_loss: 0.15854, val_acc: 0.96000\n",
      "Epoch [6820/10000], loss: 0.15193 acc: 0.98667 val_loss: 0.15845, val_acc: 0.96000\n",
      "Epoch [6830/10000], loss: 0.15182 acc: 0.98667 val_loss: 0.15835, val_acc: 0.96000\n",
      "Epoch [6840/10000], loss: 0.15171 acc: 0.98667 val_loss: 0.15826, val_acc: 0.96000\n",
      "Epoch [6850/10000], loss: 0.15161 acc: 0.98667 val_loss: 0.15817, val_acc: 0.96000\n",
      "Epoch [6860/10000], loss: 0.15150 acc: 0.98667 val_loss: 0.15807, val_acc: 0.96000\n",
      "Epoch [6870/10000], loss: 0.15139 acc: 0.98667 val_loss: 0.15798, val_acc: 0.96000\n",
      "Epoch [6880/10000], loss: 0.15129 acc: 0.98667 val_loss: 0.15789, val_acc: 0.96000\n",
      "Epoch [6890/10000], loss: 0.15118 acc: 0.98667 val_loss: 0.15780, val_acc: 0.96000\n",
      "Epoch [6900/10000], loss: 0.15108 acc: 0.98667 val_loss: 0.15771, val_acc: 0.96000\n",
      "Epoch [6910/10000], loss: 0.15097 acc: 0.98667 val_loss: 0.15761, val_acc: 0.96000\n",
      "Epoch [6920/10000], loss: 0.15086 acc: 0.98667 val_loss: 0.15752, val_acc: 0.96000\n",
      "Epoch [6930/10000], loss: 0.15076 acc: 0.98667 val_loss: 0.15743, val_acc: 0.96000\n",
      "Epoch [6940/10000], loss: 0.15065 acc: 0.98667 val_loss: 0.15734, val_acc: 0.96000\n",
      "Epoch [6950/10000], loss: 0.15055 acc: 0.98667 val_loss: 0.15725, val_acc: 0.96000\n",
      "Epoch [6960/10000], loss: 0.15045 acc: 0.98667 val_loss: 0.15716, val_acc: 0.96000\n",
      "Epoch [6970/10000], loss: 0.15034 acc: 0.98667 val_loss: 0.15707, val_acc: 0.96000\n",
      "Epoch [6980/10000], loss: 0.15024 acc: 0.98667 val_loss: 0.15698, val_acc: 0.96000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6990/10000], loss: 0.15013 acc: 0.98667 val_loss: 0.15689, val_acc: 0.96000\n",
      "Epoch [7000/10000], loss: 0.15003 acc: 0.98667 val_loss: 0.15680, val_acc: 0.96000\n",
      "Epoch [7010/10000], loss: 0.14993 acc: 0.98667 val_loss: 0.15671, val_acc: 0.96000\n",
      "Epoch [7020/10000], loss: 0.14983 acc: 0.98667 val_loss: 0.15662, val_acc: 0.96000\n",
      "Epoch [7030/10000], loss: 0.14972 acc: 0.98667 val_loss: 0.15653, val_acc: 0.96000\n",
      "Epoch [7040/10000], loss: 0.14962 acc: 0.98667 val_loss: 0.15644, val_acc: 0.96000\n",
      "Epoch [7050/10000], loss: 0.14952 acc: 0.98667 val_loss: 0.15636, val_acc: 0.96000\n",
      "Epoch [7060/10000], loss: 0.14942 acc: 0.98667 val_loss: 0.15627, val_acc: 0.96000\n",
      "Epoch [7070/10000], loss: 0.14931 acc: 0.98667 val_loss: 0.15618, val_acc: 0.96000\n",
      "Epoch [7080/10000], loss: 0.14921 acc: 0.98667 val_loss: 0.15609, val_acc: 0.96000\n",
      "Epoch [7090/10000], loss: 0.14911 acc: 0.98667 val_loss: 0.15600, val_acc: 0.96000\n",
      "Epoch [7100/10000], loss: 0.14901 acc: 0.98667 val_loss: 0.15592, val_acc: 0.96000\n",
      "Epoch [7110/10000], loss: 0.14891 acc: 0.98667 val_loss: 0.15583, val_acc: 0.96000\n",
      "Epoch [7120/10000], loss: 0.14881 acc: 0.98667 val_loss: 0.15574, val_acc: 0.96000\n",
      "Epoch [7130/10000], loss: 0.14871 acc: 0.98667 val_loss: 0.15565, val_acc: 0.96000\n",
      "Epoch [7140/10000], loss: 0.14861 acc: 0.98667 val_loss: 0.15557, val_acc: 0.96000\n",
      "Epoch [7150/10000], loss: 0.14851 acc: 0.98667 val_loss: 0.15548, val_acc: 0.96000\n",
      "Epoch [7160/10000], loss: 0.14841 acc: 0.98667 val_loss: 0.15540, val_acc: 0.96000\n",
      "Epoch [7170/10000], loss: 0.14831 acc: 0.98667 val_loss: 0.15531, val_acc: 0.96000\n",
      "Epoch [7180/10000], loss: 0.14821 acc: 0.98667 val_loss: 0.15522, val_acc: 0.96000\n",
      "Epoch [7190/10000], loss: 0.14811 acc: 0.98667 val_loss: 0.15514, val_acc: 0.96000\n",
      "Epoch [7200/10000], loss: 0.14801 acc: 0.98667 val_loss: 0.15505, val_acc: 0.96000\n",
      "Epoch [7210/10000], loss: 0.14792 acc: 0.98667 val_loss: 0.15497, val_acc: 0.96000\n",
      "Epoch [7220/10000], loss: 0.14782 acc: 0.98667 val_loss: 0.15488, val_acc: 0.96000\n",
      "Epoch [7230/10000], loss: 0.14772 acc: 0.98667 val_loss: 0.15480, val_acc: 0.96000\n",
      "Epoch [7240/10000], loss: 0.14762 acc: 0.98667 val_loss: 0.15471, val_acc: 0.96000\n",
      "Epoch [7250/10000], loss: 0.14752 acc: 0.98667 val_loss: 0.15463, val_acc: 0.96000\n",
      "Epoch [7260/10000], loss: 0.14743 acc: 0.98667 val_loss: 0.15455, val_acc: 0.96000\n",
      "Epoch [7270/10000], loss: 0.14733 acc: 0.98667 val_loss: 0.15446, val_acc: 0.96000\n",
      "Epoch [7280/10000], loss: 0.14723 acc: 0.98667 val_loss: 0.15438, val_acc: 0.96000\n",
      "Epoch [7290/10000], loss: 0.14714 acc: 0.98667 val_loss: 0.15429, val_acc: 0.96000\n",
      "Epoch [7300/10000], loss: 0.14704 acc: 0.98667 val_loss: 0.15421, val_acc: 0.96000\n",
      "Epoch [7310/10000], loss: 0.14694 acc: 0.98667 val_loss: 0.15413, val_acc: 0.96000\n",
      "Epoch [7320/10000], loss: 0.14685 acc: 0.98667 val_loss: 0.15404, val_acc: 0.96000\n",
      "Epoch [7330/10000], loss: 0.14675 acc: 0.98667 val_loss: 0.15396, val_acc: 0.96000\n",
      "Epoch [7340/10000], loss: 0.14666 acc: 0.98667 val_loss: 0.15388, val_acc: 0.96000\n",
      "Epoch [7350/10000], loss: 0.14656 acc: 0.98667 val_loss: 0.15380, val_acc: 0.96000\n",
      "Epoch [7360/10000], loss: 0.14646 acc: 0.98667 val_loss: 0.15371, val_acc: 0.96000\n",
      "Epoch [7370/10000], loss: 0.14637 acc: 0.98667 val_loss: 0.15363, val_acc: 0.96000\n",
      "Epoch [7380/10000], loss: 0.14627 acc: 0.98667 val_loss: 0.15355, val_acc: 0.96000\n",
      "Epoch [7390/10000], loss: 0.14618 acc: 0.98667 val_loss: 0.15347, val_acc: 0.96000\n",
      "Epoch [7400/10000], loss: 0.14609 acc: 0.98667 val_loss: 0.15339, val_acc: 0.96000\n",
      "Epoch [7410/10000], loss: 0.14599 acc: 0.98667 val_loss: 0.15331, val_acc: 0.96000\n",
      "Epoch [7420/10000], loss: 0.14590 acc: 0.98667 val_loss: 0.15323, val_acc: 0.96000\n",
      "Epoch [7430/10000], loss: 0.14580 acc: 0.98667 val_loss: 0.15315, val_acc: 0.96000\n",
      "Epoch [7440/10000], loss: 0.14571 acc: 0.98667 val_loss: 0.15306, val_acc: 0.96000\n",
      "Epoch [7450/10000], loss: 0.14562 acc: 0.98667 val_loss: 0.15298, val_acc: 0.96000\n",
      "Epoch [7460/10000], loss: 0.14552 acc: 0.98667 val_loss: 0.15290, val_acc: 0.96000\n",
      "Epoch [7470/10000], loss: 0.14543 acc: 0.98667 val_loss: 0.15282, val_acc: 0.96000\n",
      "Epoch [7480/10000], loss: 0.14534 acc: 0.98667 val_loss: 0.15274, val_acc: 0.96000\n",
      "Epoch [7490/10000], loss: 0.14525 acc: 0.98667 val_loss: 0.15266, val_acc: 0.96000\n",
      "Epoch [7500/10000], loss: 0.14515 acc: 0.98667 val_loss: 0.15258, val_acc: 0.96000\n",
      "Epoch [7510/10000], loss: 0.14506 acc: 0.98667 val_loss: 0.15250, val_acc: 0.96000\n",
      "Epoch [7520/10000], loss: 0.14497 acc: 0.98667 val_loss: 0.15243, val_acc: 0.96000\n",
      "Epoch [7530/10000], loss: 0.14488 acc: 0.98667 val_loss: 0.15235, val_acc: 0.96000\n",
      "Epoch [7540/10000], loss: 0.14479 acc: 0.98667 val_loss: 0.15227, val_acc: 0.96000\n",
      "Epoch [7550/10000], loss: 0.14470 acc: 0.98667 val_loss: 0.15219, val_acc: 0.96000\n",
      "Epoch [7560/10000], loss: 0.14460 acc: 0.98667 val_loss: 0.15211, val_acc: 0.96000\n",
      "Epoch [7570/10000], loss: 0.14451 acc: 0.98667 val_loss: 0.15203, val_acc: 0.96000\n",
      "Epoch [7580/10000], loss: 0.14442 acc: 0.98667 val_loss: 0.15195, val_acc: 0.96000\n",
      "Epoch [7590/10000], loss: 0.14433 acc: 0.98667 val_loss: 0.15188, val_acc: 0.96000\n",
      "Epoch [7600/10000], loss: 0.14424 acc: 0.98667 val_loss: 0.15180, val_acc: 0.96000\n",
      "Epoch [7610/10000], loss: 0.14415 acc: 0.98667 val_loss: 0.15172, val_acc: 0.96000\n",
      "Epoch [7620/10000], loss: 0.14406 acc: 0.98667 val_loss: 0.15164, val_acc: 0.96000\n",
      "Epoch [7630/10000], loss: 0.14397 acc: 0.98667 val_loss: 0.15157, val_acc: 0.96000\n",
      "Epoch [7640/10000], loss: 0.14388 acc: 0.98667 val_loss: 0.15149, val_acc: 0.96000\n",
      "Epoch [7650/10000], loss: 0.14379 acc: 0.98667 val_loss: 0.15141, val_acc: 0.96000\n",
      "Epoch [7660/10000], loss: 0.14370 acc: 0.98667 val_loss: 0.15134, val_acc: 0.96000\n",
      "Epoch [7670/10000], loss: 0.14362 acc: 0.98667 val_loss: 0.15126, val_acc: 0.96000\n",
      "Epoch [7680/10000], loss: 0.14353 acc: 0.98667 val_loss: 0.15118, val_acc: 0.96000\n",
      "Epoch [7690/10000], loss: 0.14344 acc: 0.98667 val_loss: 0.15111, val_acc: 0.96000\n",
      "Epoch [7700/10000], loss: 0.14335 acc: 0.98667 val_loss: 0.15103, val_acc: 0.96000\n",
      "Epoch [7710/10000], loss: 0.14326 acc: 0.98667 val_loss: 0.15096, val_acc: 0.96000\n",
      "Epoch [7720/10000], loss: 0.14317 acc: 0.98667 val_loss: 0.15088, val_acc: 0.96000\n",
      "Epoch [7730/10000], loss: 0.14309 acc: 0.98667 val_loss: 0.15081, val_acc: 0.96000\n",
      "Epoch [7740/10000], loss: 0.14300 acc: 0.98667 val_loss: 0.15073, val_acc: 0.96000\n",
      "Epoch [7750/10000], loss: 0.14291 acc: 0.98667 val_loss: 0.15065, val_acc: 0.96000\n",
      "Epoch [7760/10000], loss: 0.14282 acc: 0.98667 val_loss: 0.15058, val_acc: 0.96000\n",
      "Epoch [7770/10000], loss: 0.14274 acc: 0.98667 val_loss: 0.15050, val_acc: 0.96000\n",
      "Epoch [7780/10000], loss: 0.14265 acc: 0.98667 val_loss: 0.15043, val_acc: 0.96000\n",
      "Epoch [7790/10000], loss: 0.14256 acc: 0.98667 val_loss: 0.15036, val_acc: 0.96000\n",
      "Epoch [7800/10000], loss: 0.14248 acc: 0.98667 val_loss: 0.15028, val_acc: 0.96000\n",
      "Epoch [7810/10000], loss: 0.14239 acc: 0.98667 val_loss: 0.15021, val_acc: 0.96000\n",
      "Epoch [7820/10000], loss: 0.14230 acc: 0.98667 val_loss: 0.15013, val_acc: 0.96000\n",
      "Epoch [7830/10000], loss: 0.14222 acc: 0.98667 val_loss: 0.15006, val_acc: 0.96000\n",
      "Epoch [7840/10000], loss: 0.14213 acc: 0.98667 val_loss: 0.14999, val_acc: 0.96000\n",
      "Epoch [7850/10000], loss: 0.14205 acc: 0.98667 val_loss: 0.14991, val_acc: 0.96000\n",
      "Epoch [7860/10000], loss: 0.14196 acc: 0.98667 val_loss: 0.14984, val_acc: 0.96000\n",
      "Epoch [7870/10000], loss: 0.14188 acc: 0.98667 val_loss: 0.14977, val_acc: 0.96000\n",
      "Epoch [7880/10000], loss: 0.14179 acc: 0.98667 val_loss: 0.14969, val_acc: 0.96000\n",
      "Epoch [7890/10000], loss: 0.14171 acc: 0.98667 val_loss: 0.14962, val_acc: 0.96000\n",
      "Epoch [7900/10000], loss: 0.14162 acc: 0.98667 val_loss: 0.14955, val_acc: 0.96000\n",
      "Epoch [7910/10000], loss: 0.14154 acc: 0.98667 val_loss: 0.14948, val_acc: 0.96000\n",
      "Epoch [7920/10000], loss: 0.14145 acc: 0.98667 val_loss: 0.14940, val_acc: 0.96000\n",
      "Epoch [7930/10000], loss: 0.14137 acc: 0.98667 val_loss: 0.14933, val_acc: 0.96000\n",
      "Epoch [7940/10000], loss: 0.14128 acc: 0.98667 val_loss: 0.14926, val_acc: 0.96000\n",
      "Epoch [7950/10000], loss: 0.14120 acc: 0.98667 val_loss: 0.14919, val_acc: 0.96000\n",
      "Epoch [7960/10000], loss: 0.14112 acc: 0.98667 val_loss: 0.14912, val_acc: 0.96000\n",
      "Epoch [7970/10000], loss: 0.14103 acc: 0.98667 val_loss: 0.14904, val_acc: 0.96000\n",
      "Epoch [7980/10000], loss: 0.14095 acc: 0.98667 val_loss: 0.14897, val_acc: 0.96000\n",
      "Epoch [7990/10000], loss: 0.14087 acc: 0.98667 val_loss: 0.14890, val_acc: 0.96000\n",
      "Epoch [8000/10000], loss: 0.14078 acc: 0.98667 val_loss: 0.14883, val_acc: 0.96000\n",
      "Epoch [8010/10000], loss: 0.14070 acc: 0.98667 val_loss: 0.14876, val_acc: 0.96000\n",
      "Epoch [8020/10000], loss: 0.14062 acc: 0.98667 val_loss: 0.14869, val_acc: 0.96000\n",
      "Epoch [8030/10000], loss: 0.14054 acc: 0.98667 val_loss: 0.14862, val_acc: 0.96000\n",
      "Epoch [8040/10000], loss: 0.14045 acc: 0.98667 val_loss: 0.14855, val_acc: 0.96000\n",
      "Epoch [8050/10000], loss: 0.14037 acc: 0.98667 val_loss: 0.14848, val_acc: 0.96000\n",
      "Epoch [8060/10000], loss: 0.14029 acc: 0.98667 val_loss: 0.14841, val_acc: 0.96000\n",
      "Epoch [8070/10000], loss: 0.14021 acc: 0.98667 val_loss: 0.14834, val_acc: 0.96000\n",
      "Epoch [8080/10000], loss: 0.14013 acc: 0.98667 val_loss: 0.14827, val_acc: 0.96000\n",
      "Epoch [8090/10000], loss: 0.14004 acc: 0.98667 val_loss: 0.14820, val_acc: 0.96000\n",
      "Epoch [8100/10000], loss: 0.13996 acc: 0.98667 val_loss: 0.14813, val_acc: 0.96000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8110/10000], loss: 0.13988 acc: 0.98667 val_loss: 0.14806, val_acc: 0.96000\n",
      "Epoch [8120/10000], loss: 0.13980 acc: 0.98667 val_loss: 0.14799, val_acc: 0.96000\n",
      "Epoch [8130/10000], loss: 0.13972 acc: 0.98667 val_loss: 0.14792, val_acc: 0.96000\n",
      "Epoch [8140/10000], loss: 0.13964 acc: 0.98667 val_loss: 0.14785, val_acc: 0.96000\n",
      "Epoch [8150/10000], loss: 0.13956 acc: 0.98667 val_loss: 0.14778, val_acc: 0.96000\n",
      "Epoch [8160/10000], loss: 0.13948 acc: 0.98667 val_loss: 0.14771, val_acc: 0.96000\n",
      "Epoch [8170/10000], loss: 0.13940 acc: 0.98667 val_loss: 0.14765, val_acc: 0.96000\n",
      "Epoch [8180/10000], loss: 0.13932 acc: 0.98667 val_loss: 0.14758, val_acc: 0.96000\n",
      "Epoch [8190/10000], loss: 0.13924 acc: 0.98667 val_loss: 0.14751, val_acc: 0.96000\n",
      "Epoch [8200/10000], loss: 0.13916 acc: 0.98667 val_loss: 0.14744, val_acc: 0.96000\n",
      "Epoch [8210/10000], loss: 0.13908 acc: 0.98667 val_loss: 0.14737, val_acc: 0.96000\n",
      "Epoch [8220/10000], loss: 0.13900 acc: 0.98667 val_loss: 0.14731, val_acc: 0.96000\n",
      "Epoch [8230/10000], loss: 0.13892 acc: 0.98667 val_loss: 0.14724, val_acc: 0.96000\n",
      "Epoch [8240/10000], loss: 0.13884 acc: 0.98667 val_loss: 0.14717, val_acc: 0.96000\n",
      "Epoch [8250/10000], loss: 0.13876 acc: 0.98667 val_loss: 0.14710, val_acc: 0.96000\n",
      "Epoch [8260/10000], loss: 0.13869 acc: 0.98667 val_loss: 0.14704, val_acc: 0.96000\n",
      "Epoch [8270/10000], loss: 0.13861 acc: 0.98667 val_loss: 0.14697, val_acc: 0.96000\n",
      "Epoch [8280/10000], loss: 0.13853 acc: 0.98667 val_loss: 0.14690, val_acc: 0.96000\n",
      "Epoch [8290/10000], loss: 0.13845 acc: 0.98667 val_loss: 0.14684, val_acc: 0.96000\n",
      "Epoch [8300/10000], loss: 0.13837 acc: 0.98667 val_loss: 0.14677, val_acc: 0.96000\n",
      "Epoch [8310/10000], loss: 0.13829 acc: 0.98667 val_loss: 0.14670, val_acc: 0.96000\n",
      "Epoch [8320/10000], loss: 0.13822 acc: 0.98667 val_loss: 0.14664, val_acc: 0.96000\n",
      "Epoch [8330/10000], loss: 0.13814 acc: 0.98667 val_loss: 0.14657, val_acc: 0.96000\n",
      "Epoch [8340/10000], loss: 0.13806 acc: 0.98667 val_loss: 0.14650, val_acc: 0.96000\n",
      "Epoch [8350/10000], loss: 0.13798 acc: 0.98667 val_loss: 0.14644, val_acc: 0.96000\n",
      "Epoch [8360/10000], loss: 0.13791 acc: 0.98667 val_loss: 0.14637, val_acc: 0.96000\n",
      "Epoch [8370/10000], loss: 0.13783 acc: 0.98667 val_loss: 0.14631, val_acc: 0.96000\n",
      "Epoch [8380/10000], loss: 0.13775 acc: 0.98667 val_loss: 0.14624, val_acc: 0.96000\n",
      "Epoch [8390/10000], loss: 0.13768 acc: 0.98667 val_loss: 0.14618, val_acc: 0.96000\n",
      "Epoch [8400/10000], loss: 0.13760 acc: 0.98667 val_loss: 0.14611, val_acc: 0.96000\n",
      "Epoch [8410/10000], loss: 0.13752 acc: 0.98667 val_loss: 0.14605, val_acc: 0.96000\n",
      "Epoch [8420/10000], loss: 0.13745 acc: 0.98667 val_loss: 0.14598, val_acc: 0.96000\n",
      "Epoch [8430/10000], loss: 0.13737 acc: 0.98667 val_loss: 0.14592, val_acc: 0.96000\n",
      "Epoch [8440/10000], loss: 0.13730 acc: 0.98667 val_loss: 0.14585, val_acc: 0.96000\n",
      "Epoch [8450/10000], loss: 0.13722 acc: 0.98667 val_loss: 0.14579, val_acc: 0.96000\n",
      "Epoch [8460/10000], loss: 0.13714 acc: 0.98667 val_loss: 0.14572, val_acc: 0.96000\n",
      "Epoch [8470/10000], loss: 0.13707 acc: 0.98667 val_loss: 0.14566, val_acc: 0.96000\n",
      "Epoch [8480/10000], loss: 0.13699 acc: 0.98667 val_loss: 0.14559, val_acc: 0.96000\n",
      "Epoch [8490/10000], loss: 0.13692 acc: 0.98667 val_loss: 0.14553, val_acc: 0.96000\n",
      "Epoch [8500/10000], loss: 0.13684 acc: 0.98667 val_loss: 0.14547, val_acc: 0.96000\n",
      "Epoch [8510/10000], loss: 0.13677 acc: 0.98667 val_loss: 0.14540, val_acc: 0.96000\n",
      "Epoch [8520/10000], loss: 0.13669 acc: 0.98667 val_loss: 0.14534, val_acc: 0.96000\n",
      "Epoch [8530/10000], loss: 0.13662 acc: 0.98667 val_loss: 0.14528, val_acc: 0.96000\n",
      "Epoch [8540/10000], loss: 0.13654 acc: 0.98667 val_loss: 0.14521, val_acc: 0.96000\n",
      "Epoch [8550/10000], loss: 0.13647 acc: 0.98667 val_loss: 0.14515, val_acc: 0.96000\n",
      "Epoch [8560/10000], loss: 0.13640 acc: 0.98667 val_loss: 0.14509, val_acc: 0.96000\n",
      "Epoch [8570/10000], loss: 0.13632 acc: 0.98667 val_loss: 0.14502, val_acc: 0.96000\n",
      "Epoch [8580/10000], loss: 0.13625 acc: 0.98667 val_loss: 0.14496, val_acc: 0.96000\n",
      "Epoch [8590/10000], loss: 0.13617 acc: 0.98667 val_loss: 0.14490, val_acc: 0.96000\n",
      "Epoch [8600/10000], loss: 0.13610 acc: 0.98667 val_loss: 0.14483, val_acc: 0.96000\n",
      "Epoch [8610/10000], loss: 0.13603 acc: 0.98667 val_loss: 0.14477, val_acc: 0.96000\n",
      "Epoch [8620/10000], loss: 0.13595 acc: 0.98667 val_loss: 0.14471, val_acc: 0.96000\n",
      "Epoch [8630/10000], loss: 0.13588 acc: 0.98667 val_loss: 0.14465, val_acc: 0.96000\n",
      "Epoch [8640/10000], loss: 0.13581 acc: 0.98667 val_loss: 0.14459, val_acc: 0.96000\n",
      "Epoch [8650/10000], loss: 0.13574 acc: 0.98667 val_loss: 0.14452, val_acc: 0.96000\n",
      "Epoch [8660/10000], loss: 0.13566 acc: 0.98667 val_loss: 0.14446, val_acc: 0.96000\n",
      "Epoch [8670/10000], loss: 0.13559 acc: 0.98667 val_loss: 0.14440, val_acc: 0.96000\n",
      "Epoch [8680/10000], loss: 0.13552 acc: 0.98667 val_loss: 0.14434, val_acc: 0.96000\n",
      "Epoch [8690/10000], loss: 0.13545 acc: 0.98667 val_loss: 0.14428, val_acc: 0.96000\n",
      "Epoch [8700/10000], loss: 0.13537 acc: 0.98667 val_loss: 0.14422, val_acc: 0.96000\n",
      "Epoch [8710/10000], loss: 0.13530 acc: 0.98667 val_loss: 0.14415, val_acc: 0.96000\n",
      "Epoch [8720/10000], loss: 0.13523 acc: 0.98667 val_loss: 0.14409, val_acc: 0.96000\n",
      "Epoch [8730/10000], loss: 0.13516 acc: 0.98667 val_loss: 0.14403, val_acc: 0.96000\n",
      "Epoch [8740/10000], loss: 0.13509 acc: 0.98667 val_loss: 0.14397, val_acc: 0.96000\n",
      "Epoch [8750/10000], loss: 0.13501 acc: 0.98667 val_loss: 0.14391, val_acc: 0.96000\n",
      "Epoch [8760/10000], loss: 0.13494 acc: 0.98667 val_loss: 0.14385, val_acc: 0.96000\n",
      "Epoch [8770/10000], loss: 0.13487 acc: 0.98667 val_loss: 0.14379, val_acc: 0.96000\n",
      "Epoch [8780/10000], loss: 0.13480 acc: 0.98667 val_loss: 0.14373, val_acc: 0.96000\n",
      "Epoch [8790/10000], loss: 0.13473 acc: 0.98667 val_loss: 0.14367, val_acc: 0.96000\n",
      "Epoch [8800/10000], loss: 0.13466 acc: 0.98667 val_loss: 0.14361, val_acc: 0.96000\n",
      "Epoch [8810/10000], loss: 0.13459 acc: 0.98667 val_loss: 0.14355, val_acc: 0.96000\n",
      "Epoch [8820/10000], loss: 0.13452 acc: 0.98667 val_loss: 0.14349, val_acc: 0.96000\n",
      "Epoch [8830/10000], loss: 0.13445 acc: 0.98667 val_loss: 0.14343, val_acc: 0.96000\n",
      "Epoch [8840/10000], loss: 0.13438 acc: 0.98667 val_loss: 0.14337, val_acc: 0.96000\n",
      "Epoch [8850/10000], loss: 0.13431 acc: 0.98667 val_loss: 0.14331, val_acc: 0.96000\n",
      "Epoch [8860/10000], loss: 0.13424 acc: 0.98667 val_loss: 0.14325, val_acc: 0.96000\n",
      "Epoch [8870/10000], loss: 0.13417 acc: 0.98667 val_loss: 0.14319, val_acc: 0.96000\n",
      "Epoch [8880/10000], loss: 0.13410 acc: 0.98667 val_loss: 0.14313, val_acc: 0.96000\n",
      "Epoch [8890/10000], loss: 0.13403 acc: 0.98667 val_loss: 0.14308, val_acc: 0.96000\n",
      "Epoch [8900/10000], loss: 0.13396 acc: 0.98667 val_loss: 0.14302, val_acc: 0.96000\n",
      "Epoch [8910/10000], loss: 0.13389 acc: 0.98667 val_loss: 0.14296, val_acc: 0.96000\n",
      "Epoch [8920/10000], loss: 0.13382 acc: 0.98667 val_loss: 0.14290, val_acc: 0.96000\n",
      "Epoch [8930/10000], loss: 0.13375 acc: 0.98667 val_loss: 0.14284, val_acc: 0.96000\n",
      "Epoch [8940/10000], loss: 0.13368 acc: 0.98667 val_loss: 0.14278, val_acc: 0.96000\n",
      "Epoch [8950/10000], loss: 0.13361 acc: 0.98667 val_loss: 0.14272, val_acc: 0.96000\n",
      "Epoch [8960/10000], loss: 0.13354 acc: 0.98667 val_loss: 0.14267, val_acc: 0.96000\n",
      "Epoch [8970/10000], loss: 0.13347 acc: 0.98667 val_loss: 0.14261, val_acc: 0.96000\n",
      "Epoch [8980/10000], loss: 0.13341 acc: 0.98667 val_loss: 0.14255, val_acc: 0.96000\n",
      "Epoch [8990/10000], loss: 0.13334 acc: 0.98667 val_loss: 0.14249, val_acc: 0.96000\n",
      "Epoch [9000/10000], loss: 0.13327 acc: 0.98667 val_loss: 0.14243, val_acc: 0.96000\n",
      "Epoch [9010/10000], loss: 0.13320 acc: 0.98667 val_loss: 0.14238, val_acc: 0.96000\n",
      "Epoch [9020/10000], loss: 0.13313 acc: 0.98667 val_loss: 0.14232, val_acc: 0.96000\n",
      "Epoch [9030/10000], loss: 0.13307 acc: 0.98667 val_loss: 0.14226, val_acc: 0.96000\n",
      "Epoch [9040/10000], loss: 0.13300 acc: 0.98667 val_loss: 0.14220, val_acc: 0.96000\n",
      "Epoch [9050/10000], loss: 0.13293 acc: 0.98667 val_loss: 0.14215, val_acc: 0.96000\n",
      "Epoch [9060/10000], loss: 0.13286 acc: 0.98667 val_loss: 0.14209, val_acc: 0.96000\n",
      "Epoch [9070/10000], loss: 0.13280 acc: 0.98667 val_loss: 0.14203, val_acc: 0.96000\n",
      "Epoch [9080/10000], loss: 0.13273 acc: 0.98667 val_loss: 0.14198, val_acc: 0.96000\n",
      "Epoch [9090/10000], loss: 0.13266 acc: 0.98667 val_loss: 0.14192, val_acc: 0.96000\n",
      "Epoch [9100/10000], loss: 0.13259 acc: 0.98667 val_loss: 0.14186, val_acc: 0.96000\n",
      "Epoch [9110/10000], loss: 0.13253 acc: 0.98667 val_loss: 0.14181, val_acc: 0.96000\n",
      "Epoch [9120/10000], loss: 0.13246 acc: 0.98667 val_loss: 0.14175, val_acc: 0.96000\n",
      "Epoch [9130/10000], loss: 0.13239 acc: 0.98667 val_loss: 0.14169, val_acc: 0.96000\n",
      "Epoch [9140/10000], loss: 0.13233 acc: 0.98667 val_loss: 0.14164, val_acc: 0.96000\n",
      "Epoch [9150/10000], loss: 0.13226 acc: 0.98667 val_loss: 0.14158, val_acc: 0.96000\n",
      "Epoch [9160/10000], loss: 0.13220 acc: 0.98667 val_loss: 0.14153, val_acc: 0.96000\n",
      "Epoch [9170/10000], loss: 0.13213 acc: 0.98667 val_loss: 0.14147, val_acc: 0.96000\n",
      "Epoch [9180/10000], loss: 0.13206 acc: 0.98667 val_loss: 0.14141, val_acc: 0.96000\n",
      "Epoch [9190/10000], loss: 0.13200 acc: 0.98667 val_loss: 0.14136, val_acc: 0.96000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9200/10000], loss: 0.13193 acc: 0.98667 val_loss: 0.14130, val_acc: 0.96000\n",
      "Epoch [9210/10000], loss: 0.13187 acc: 0.98667 val_loss: 0.14125, val_acc: 0.96000\n",
      "Epoch [9220/10000], loss: 0.13180 acc: 0.98667 val_loss: 0.14119, val_acc: 0.96000\n",
      "Epoch [9230/10000], loss: 0.13174 acc: 0.98667 val_loss: 0.14114, val_acc: 0.96000\n",
      "Epoch [9240/10000], loss: 0.13167 acc: 0.98667 val_loss: 0.14108, val_acc: 0.96000\n",
      "Epoch [9250/10000], loss: 0.13160 acc: 0.98667 val_loss: 0.14103, val_acc: 0.96000\n",
      "Epoch [9260/10000], loss: 0.13154 acc: 0.98667 val_loss: 0.14097, val_acc: 0.96000\n",
      "Epoch [9270/10000], loss: 0.13147 acc: 0.98667 val_loss: 0.14092, val_acc: 0.96000\n",
      "Epoch [9280/10000], loss: 0.13141 acc: 0.98667 val_loss: 0.14086, val_acc: 0.96000\n",
      "Epoch [9290/10000], loss: 0.13135 acc: 0.98667 val_loss: 0.14081, val_acc: 0.96000\n",
      "Epoch [9300/10000], loss: 0.13128 acc: 0.98667 val_loss: 0.14075, val_acc: 0.96000\n",
      "Epoch [9310/10000], loss: 0.13122 acc: 0.98667 val_loss: 0.14070, val_acc: 0.96000\n",
      "Epoch [9320/10000], loss: 0.13115 acc: 0.98667 val_loss: 0.14065, val_acc: 0.96000\n",
      "Epoch [9330/10000], loss: 0.13109 acc: 0.98667 val_loss: 0.14059, val_acc: 0.96000\n",
      "Epoch [9340/10000], loss: 0.13102 acc: 0.98667 val_loss: 0.14054, val_acc: 0.96000\n",
      "Epoch [9350/10000], loss: 0.13096 acc: 0.98667 val_loss: 0.14048, val_acc: 0.96000\n",
      "Epoch [9360/10000], loss: 0.13090 acc: 0.98667 val_loss: 0.14043, val_acc: 0.96000\n",
      "Epoch [9370/10000], loss: 0.13083 acc: 0.98667 val_loss: 0.14038, val_acc: 0.96000\n",
      "Epoch [9380/10000], loss: 0.13077 acc: 0.98667 val_loss: 0.14032, val_acc: 0.96000\n",
      "Epoch [9390/10000], loss: 0.13070 acc: 0.98667 val_loss: 0.14027, val_acc: 0.96000\n",
      "Epoch [9400/10000], loss: 0.13064 acc: 0.98667 val_loss: 0.14022, val_acc: 0.96000\n",
      "Epoch [9410/10000], loss: 0.13058 acc: 0.98667 val_loss: 0.14016, val_acc: 0.96000\n",
      "Epoch [9420/10000], loss: 0.13051 acc: 0.98667 val_loss: 0.14011, val_acc: 0.96000\n",
      "Epoch [9430/10000], loss: 0.13045 acc: 0.98667 val_loss: 0.14006, val_acc: 0.96000\n",
      "Epoch [9440/10000], loss: 0.13039 acc: 0.98667 val_loss: 0.14000, val_acc: 0.96000\n",
      "Epoch [9450/10000], loss: 0.13033 acc: 0.98667 val_loss: 0.13995, val_acc: 0.96000\n",
      "Epoch [9460/10000], loss: 0.13026 acc: 0.98667 val_loss: 0.13990, val_acc: 0.96000\n",
      "Epoch [9470/10000], loss: 0.13020 acc: 0.98667 val_loss: 0.13984, val_acc: 0.96000\n",
      "Epoch [9480/10000], loss: 0.13014 acc: 0.98667 val_loss: 0.13979, val_acc: 0.96000\n",
      "Epoch [9490/10000], loss: 0.13008 acc: 0.98667 val_loss: 0.13974, val_acc: 0.96000\n",
      "Epoch [9500/10000], loss: 0.13001 acc: 0.98667 val_loss: 0.13969, val_acc: 0.96000\n",
      "Epoch [9510/10000], loss: 0.12995 acc: 0.98667 val_loss: 0.13963, val_acc: 0.96000\n",
      "Epoch [9520/10000], loss: 0.12989 acc: 0.98667 val_loss: 0.13958, val_acc: 0.96000\n",
      "Epoch [9530/10000], loss: 0.12983 acc: 0.98667 val_loss: 0.13953, val_acc: 0.96000\n",
      "Epoch [9540/10000], loss: 0.12976 acc: 0.98667 val_loss: 0.13948, val_acc: 0.96000\n",
      "Epoch [9550/10000], loss: 0.12970 acc: 0.98667 val_loss: 0.13943, val_acc: 0.96000\n",
      "Epoch [9560/10000], loss: 0.12964 acc: 0.98667 val_loss: 0.13937, val_acc: 0.96000\n",
      "Epoch [9570/10000], loss: 0.12958 acc: 0.98667 val_loss: 0.13932, val_acc: 0.96000\n",
      "Epoch [9580/10000], loss: 0.12952 acc: 0.98667 val_loss: 0.13927, val_acc: 0.96000\n",
      "Epoch [9590/10000], loss: 0.12946 acc: 0.98667 val_loss: 0.13922, val_acc: 0.96000\n",
      "Epoch [9600/10000], loss: 0.12940 acc: 0.98667 val_loss: 0.13917, val_acc: 0.96000\n",
      "Epoch [9610/10000], loss: 0.12933 acc: 0.98667 val_loss: 0.13912, val_acc: 0.96000\n",
      "Epoch [9620/10000], loss: 0.12927 acc: 0.98667 val_loss: 0.13907, val_acc: 0.96000\n",
      "Epoch [9630/10000], loss: 0.12921 acc: 0.98667 val_loss: 0.13901, val_acc: 0.96000\n",
      "Epoch [9640/10000], loss: 0.12915 acc: 0.98667 val_loss: 0.13896, val_acc: 0.96000\n",
      "Epoch [9650/10000], loss: 0.12909 acc: 0.98667 val_loss: 0.13891, val_acc: 0.96000\n",
      "Epoch [9660/10000], loss: 0.12903 acc: 0.98667 val_loss: 0.13886, val_acc: 0.96000\n",
      "Epoch [9670/10000], loss: 0.12897 acc: 0.98667 val_loss: 0.13881, val_acc: 0.96000\n",
      "Epoch [9680/10000], loss: 0.12891 acc: 0.98667 val_loss: 0.13876, val_acc: 0.96000\n",
      "Epoch [9690/10000], loss: 0.12885 acc: 0.98667 val_loss: 0.13871, val_acc: 0.96000\n",
      "Epoch [9700/10000], loss: 0.12879 acc: 0.98667 val_loss: 0.13866, val_acc: 0.96000\n",
      "Epoch [9710/10000], loss: 0.12873 acc: 0.98667 val_loss: 0.13861, val_acc: 0.96000\n",
      "Epoch [9720/10000], loss: 0.12867 acc: 0.98667 val_loss: 0.13856, val_acc: 0.96000\n",
      "Epoch [9730/10000], loss: 0.12861 acc: 0.98667 val_loss: 0.13851, val_acc: 0.96000\n",
      "Epoch [9740/10000], loss: 0.12855 acc: 0.98667 val_loss: 0.13846, val_acc: 0.96000\n",
      "Epoch [9750/10000], loss: 0.12849 acc: 0.98667 val_loss: 0.13841, val_acc: 0.96000\n",
      "Epoch [9760/10000], loss: 0.12843 acc: 0.98667 val_loss: 0.13836, val_acc: 0.96000\n",
      "Epoch [9770/10000], loss: 0.12837 acc: 0.98667 val_loss: 0.13831, val_acc: 0.96000\n",
      "Epoch [9780/10000], loss: 0.12831 acc: 0.98667 val_loss: 0.13826, val_acc: 0.96000\n",
      "Epoch [9790/10000], loss: 0.12825 acc: 0.98667 val_loss: 0.13821, val_acc: 0.96000\n",
      "Epoch [9800/10000], loss: 0.12819 acc: 0.98667 val_loss: 0.13816, val_acc: 0.96000\n",
      "Epoch [9810/10000], loss: 0.12813 acc: 0.98667 val_loss: 0.13811, val_acc: 0.96000\n",
      "Epoch [9820/10000], loss: 0.12808 acc: 0.98667 val_loss: 0.13806, val_acc: 0.96000\n",
      "Epoch [9830/10000], loss: 0.12802 acc: 0.98667 val_loss: 0.13801, val_acc: 0.96000\n",
      "Epoch [9840/10000], loss: 0.12796 acc: 0.98667 val_loss: 0.13796, val_acc: 0.96000\n",
      "Epoch [9850/10000], loss: 0.12790 acc: 0.98667 val_loss: 0.13791, val_acc: 0.96000\n",
      "Epoch [9860/10000], loss: 0.12784 acc: 0.98667 val_loss: 0.13786, val_acc: 0.96000\n",
      "Epoch [9870/10000], loss: 0.12778 acc: 0.98667 val_loss: 0.13782, val_acc: 0.96000\n",
      "Epoch [9880/10000], loss: 0.12772 acc: 0.98667 val_loss: 0.13777, val_acc: 0.96000\n",
      "Epoch [9890/10000], loss: 0.12767 acc: 0.98667 val_loss: 0.13772, val_acc: 0.96000\n",
      "Epoch [9900/10000], loss: 0.12761 acc: 0.98667 val_loss: 0.13767, val_acc: 0.96000\n",
      "Epoch [9910/10000], loss: 0.12755 acc: 0.98667 val_loss: 0.13762, val_acc: 0.96000\n",
      "Epoch [9920/10000], loss: 0.12749 acc: 0.98667 val_loss: 0.13757, val_acc: 0.96000\n",
      "Epoch [9930/10000], loss: 0.12743 acc: 0.98667 val_loss: 0.13752, val_acc: 0.96000\n",
      "Epoch [9940/10000], loss: 0.12738 acc: 0.98667 val_loss: 0.13748, val_acc: 0.96000\n",
      "Epoch [9950/10000], loss: 0.12732 acc: 0.98667 val_loss: 0.13743, val_acc: 0.96000\n",
      "Epoch [9960/10000], loss: 0.12726 acc: 0.98667 val_loss: 0.13738, val_acc: 0.96000\n",
      "Epoch [9970/10000], loss: 0.12720 acc: 0.98667 val_loss: 0.13733, val_acc: 0.96000\n",
      "Epoch [9980/10000], loss: 0.12715 acc: 0.98667 val_loss: 0.13728, val_acc: 0.96000\n",
      "Epoch [9990/10000], loss: 0.12709 acc: 0.98667 val_loss: 0.13724, val_acc: 0.96000\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "\n",
    "    # 学習フェーズ\n",
    "    \n",
    "    #勾配の初期化\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 順伝搬計算\n",
    "    outputs = net(inputs)\n",
    "    \n",
    "    # ここで対数関数にかける\n",
    "    outputs2 = torch.log(outputs)\n",
    "\n",
    "    # 誤差計算\n",
    "    loss = criterion(outputs2, labels)\n",
    "\n",
    "    # 勾配計算\n",
    "    loss.backward()\n",
    "    \n",
    "    # 重み調整\n",
    "    optimizer.step()\n",
    "\n",
    "    #予測値算出\n",
    "    predicted = torch.max(outputs, 1)[1]\n",
    "\n",
    "    # 訓練データに対する損失と精度の計算\n",
    "    train_loss = loss.item()\n",
    "    train_acc = (predicted == labels).sum()  / len(labels)\n",
    "\n",
    "    #予測フェーズ\n",
    "    with torch.no_grad():\n",
    "\n",
    "        # 順伝搬計算\n",
    "        outputs_test = net(inputs_test)\n",
    "        \n",
    "        # ここで対数関数にかける\n",
    "        outputs2_test = torch.log(outputs_test)\n",
    "\n",
    "        # 誤差計算\n",
    "        loss_test = criterion(outputs2_test, labels_test)\n",
    "\n",
    "        #予測値算出\n",
    "        predicted_test = torch.max(outputs_test, 1)[1]\n",
    "\n",
    "        # 検証データに対する損失と精度の計算\n",
    "        val_loss =  loss_test.item()\n",
    "        val_acc =  (predicted_test == labels_test).sum() / len(labels_test)\n",
    "    \n",
    "    if ( epoch % 10 == 0):\n",
    "        print (f'Epoch [{epoch}/{num_epochs}], loss: {train_loss:.5f} acc: {train_acc:.5f} val_loss: {val_loss:.5f}, val_acc: {val_acc:.5f}')\n",
    "        item = np.array([epoch , train_loss, train_acc, val_loss, val_acc])\n",
    "        history = np.vstack((history, item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "初期状態: 損失関数: 1.09158 精度: 0.26667\n",
      "最終状態: 損失関数: 0.13724 精度: 0.96000\n"
     ]
    }
   ],
   "source": [
    "#損失関数値と精度の確認\n",
    "\n",
    "print(f'初期状態: 損失関数: {history[0,3]:.5f} 精度: {history[0,4]:.5f}' )\n",
    "print(f'最終状態: 損失関数: {history[-1,3]:.5f} 精度: {history[-1,4]:.5f}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0059 0.9056 0.0885]\n",
      " [0.0069 0.9792 0.0139]\n",
      " [0.9452 0.0548 0.    ]\n",
      " [0.     0.0404 0.9596]\n",
      " [0.0001 0.1743 0.8256]]\n"
     ]
    }
   ],
   "source": [
    "w = outputs[:5,:].data.numpy()\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
